{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb363d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_drowsiness_lstm.py\n",
    "import os, re, json, math, random, shutil\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef4e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본값 설정\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"EAR\",\n",
    "    \"MAR\",\n",
    "    \"yawn_rate_per_min\",\n",
    "    \"blink_rate_per_min\",\n",
    "    \"avg_blink_dur_sec\",\n",
    "    \"longest_eye_closure_sec\",\n",
    "]\n",
    "\n",
    "# level: -1,0,1,2,3  -> 총 5클래스. (-1 포함)\n",
    "CLS_LEVELS = [-1, 0, 1, 2, 3]\n",
    "LEVEL_TO_INDEX = {lvl: i for i, lvl in enumerate(CLS_LEVELS)}\n",
    "INDEX_TO_LEVEL = {i: lvl for lvl, i in LEVEL_TO_INDEX.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97edd48b",
   "metadata": {},
   "source": [
    "#### 유형 데이타셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0912354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이타셋 구성을 위한 기본 함수들..\n",
    "\n",
    "def _safe_symlink(src: Path, dst: Path):\n",
    "    # 숨김 파일(. , ._ 시작)은 무시\n",
    "    if src.name.startswith(\".\") or src.name.startswith(\"._\"):\n",
    "        return\n",
    "\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        if dst.exists() or dst.is_symlink():\n",
    "            dst.unlink()\n",
    "        os.symlink(src.resolve(), dst)\n",
    "    except Exception:\n",
    "        # 윈도우/권한 이슈 대비: 복사로 폴백\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "def scan_pairs(data_dir: Path) -> List[Tuple[Path, Path]]:\n",
    "    \"\"\"\n",
    "    data_dir 아래의 CSV/JSON 쌍을 찾아 반환.\n",
    "    파일명(확장자 제외)이 일치하면 쌍으로 간주.\n",
    "    \"\"\"\n",
    "    csvs = {}\n",
    "    jsons = {}\n",
    "    for p in data_dir.glob(\"./*\"):\n",
    "        if p.is_file():\n",
    "            stem = p.stem  # 파일명(확장자 제외)\n",
    "            if p.suffix.lower() == \".csv\":\n",
    "                csvs[stem] = p\n",
    "            elif p.suffix.lower() == \".json\":\n",
    "                jsons[stem] = p\n",
    "    pairs = []\n",
    "    for stem, csv_path in csvs.items():\n",
    "        if stem in jsons:\n",
    "            pairs.append((csv_path, jsons[stem]))\n",
    "    return sorted(pairs)\n",
    "\n",
    "def split_and_link(pairs: List[Tuple[Path, Path]], out_dir: Path, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    쌍 목록을 8:2로 분할하고, out_dir/{train,val}에 심볼릭링크(또는 복사) 생성.\n",
    "    \"\"\"\n",
    "    random.shuffle(pairs)\n",
    "    n_total = len(pairs)\n",
    "    n_train = int(round(n_total * train_ratio))\n",
    "    train_pairs = pairs[:n_train]\n",
    "    val_pairs = pairs[n_train:]\n",
    "\n",
    "    for split_name, subset in [(\"train\", train_pairs), (\"val\", val_pairs)]:\n",
    "        for csv_path, json_path in subset:\n",
    "            rel = csv_path.name  # 파일명만 사용\n",
    "            dst_csv = out_dir / split_name / rel\n",
    "            dst_json = out_dir / split_name / json_path.name\n",
    "            _safe_symlink(csv_path, dst_csv)\n",
    "            _safe_symlink(json_path, dst_json)\n",
    "    return train_pairs, val_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a639253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각자 데이터셋 디렉토리 설정\n",
    "data_root = \"./dataset/\"\n",
    "prepared_dir = \"prepared-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8508439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path(data_root).expanduser().resolve()\n",
    "prep_dir = Path(prepared_dir).resolve()\n",
    "# prep_train_dir = Path(prep_train_dir).expanduser().resolve()\n",
    "# prep_val_dir = Path(prep_val_dir).expanduser().resolve()\n",
    "prep_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43468f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pairs = scan_pairs(prep_train_dir)\n",
    "# val_pairs = scan_pairs(prep_val_dir)\n",
    "# print(f\"학습: {len(train_pairs)} / 검증: {len(val_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a325c2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 파일쌍: 204\n",
      "학습: 163 / 검증: 41\n"
     ]
    }
   ],
   "source": [
    "# 스캔 & 분할 & 링크\n",
    "pairs = scan_pairs(data_root)\n",
    "print(f\"총 파일쌍: {len(pairs)}\")\n",
    "train_pairs, val_pairs = split_and_link(pairs, prep_dir, train_ratio=0.8)\n",
    "print(f\"학습: {len(train_pairs)} / 검증: {len(val_pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b42a096",
   "metadata": {},
   "source": [
    "#### 라벨 관련 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "825de889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 라벨 JSON 해석 (유연 파서)\n",
    "# -------------------------\n",
    "def parse_label_json(json_path: Path) -> List[Tuple[int, int, int]]:\n",
    "    \"\"\"\n",
    "    라벨 JSON을 다양한 스키마로 수용하여 [(start, end, level), ...] 리스트로 변환.\n",
    "    - end는 inclusive로 간주 (start <= frame <= end)\n",
    "    - 인식 실패 시 빈 리스트\n",
    "    \"\"\"\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    segs = []\n",
    "\n",
    "    def norm_one(d):\n",
    "        # 키 변형 수용\n",
    "        if isinstance(d, dict):\n",
    "            # 유형 1: 명시 키\n",
    "            s = d.get(\"start_frame\", d.get(\"frame_start\", d.get(\"start\")))\n",
    "            e = d.get(\"end_frame\", d.get(\"frame_end\", d.get(\"end\")))\n",
    "            lvl = d.get(\"level\", d.get(\"lvl\", d.get(\"label\", d.get(\"state\"))))\n",
    "            if s is not None and e is not None and lvl is not None:\n",
    "                return int(s), int(e), int(lvl)\n",
    "            # 유형 2: frames: [s, e]\n",
    "            if \"frames\" in d and isinstance(d[\"frames\"], (list, tuple)) and len(d[\"frames\"]) >= 2:\n",
    "                s, e = d[\"frames\"][:2]\n",
    "                lvl = int(d.get(\"level\", d.get(\"label\", -1)))\n",
    "                return int(s), int(e), int(lvl)\n",
    "        return None\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            r = norm_one(item)\n",
    "            if r: segs.append(r)\n",
    "    elif isinstance(data, dict):\n",
    "        # 유형 3: {\"segments\":[{...}, ...]}\n",
    "        if \"segments\" in data and isinstance(data[\"segments\"], list):\n",
    "            for item in data[\"segments\"]:\n",
    "                r = norm_one(item)\n",
    "                if r: segs.append(r)\n",
    "        # 유형 4: {\"ranges\": {\"100-200\": 2, ...}}\n",
    "        elif \"ranges\" in data and isinstance(data[\"ranges\"], dict):\n",
    "            for k, v in data[\"ranges\"].items():\n",
    "                m = re.match(r\"^\\s*(\\d+)\\s*[-:]\\s*(\\d+)\\s*$\", str(k))\n",
    "                if m:\n",
    "                    s, e = int(m.group(1)), int(m.group(2))\n",
    "                    segs.append((s, e, int(v)))\n",
    "        # 유형 5: {\"100-200\": 1, \"201-260\": 2}\n",
    "        else:\n",
    "            for k, v in data.items():\n",
    "                m = re.match(r\"^\\s*(\\d+)\\s*[-:]\\s*(\\d+)\\s*$\", str(k))\n",
    "                if m:\n",
    "                    s, e = int(m.group(1)), int(m.group(2))\n",
    "                    segs.append((s, e, int(v)))\n",
    "\n",
    "    # 정렬 & 병합은 생략(중복은 뒤값 우선)\n",
    "    segs.sort(key=lambda x: (x[0], x[1]))\n",
    "    return segs\n",
    "\n",
    "def build_frame_labels(max_frame: int, segments: List[Tuple[int,int,int]], default_level=-1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    0..max_frame 범위에 대해 프레임별 level 배열 만들기.\n",
    "    \"\"\"\n",
    "    labels = np.full((max_frame+1,), default_level, dtype=np.int32)\n",
    "    for s, e, lvl in segments:\n",
    "        s = max(0, s); e = min(max_frame, e)\n",
    "        if e >= s:\n",
    "            labels[s:e+1] = int(lvl)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3cd46",
   "metadata": {},
   "source": [
    "#### CSV 로딩 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa238cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_fps_from_csv(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    CSV의 frame과 time_sec로 FPS 추정.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(\"frame\")\n",
    "    if \"time_sec\" in df.columns and df[\"time_sec\"].max() > 0:\n",
    "        f_span = float(df[\"frame\"].iloc[-1] - df[\"frame\"].iloc[0])\n",
    "        t_span = float(df[\"time_sec\"].iloc[-1] - df[\"time_sec\"].iloc[0])\n",
    "        if t_span > 0 and f_span > 0:\n",
    "            return max(1.0, round(f_span / t_span, 2))\n",
    "    # fallback: frame 차분의 중앙값을 1프레임으로 간주\n",
    "    return 30.0  # 보수적 기본값\n",
    "\n",
    "def load_csv(csv_path: Path) -> pd.DataFrame:\n",
    "    encodings_to_try = [\"utf-8\", \"cp949\", \"euc-kr\"]\n",
    "\n",
    "    if csv_path.name.startswith(\".\") or csv_path.name.startswith(\"._\"):\n",
    "        return pd.DataFrame()  # 빈 데이터프레임 반환 (혹은 None 처리 가능)\n",
    "\n",
    "    print(\"current csv_path:\", csv_path)\n",
    "    \n",
    "    last_err = None\n",
    "    for enc in encodings_to_try:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path, encoding=enc)\n",
    "            break\n",
    "        except UnicodeDecodeError as e:\n",
    "            last_err = e\n",
    "    else:\n",
    "        # 모든 인코딩 실패 시 에러\n",
    "        raise last_err\n",
    "\n",
    "    # 필수 컬럼 체크\n",
    "    must = [\"frame\", \"time_sec\"] + FEATURE_COLS\n",
    "    missing = [c for c in must if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"[{csv_path.name}] 누락 컬럼: {missing}\")\n",
    "\n",
    "    df = df.sort_values(\"frame\").reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a3da86",
   "metadata": {},
   "source": [
    "#### 윈도윙 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b84ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows_for_pair(\n",
    "    csv_path: Path, json_path: Path,\n",
    "    window_sec=5.0, hop_sec=1.0,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    하나의 (CSV, JSON) 쌍에서 (X, y) 윈도우 생성\n",
    "    - X: (num_win, seq_len, num_feat)\n",
    "    - y: (num_win,)  # 윈도우 대표 레벨 (다수결)\n",
    "    \"\"\"\n",
    "    df = load_csv(csv_path)\n",
    "\n",
    "    fps = infer_fps_from_csv(df)\n",
    "    win = max(1, int(round(window_sec * fps)))\n",
    "    hop = max(1, int(round(hop_sec * fps)))\n",
    "\n",
    "    # 프레임별 라벨\n",
    "    segs = parse_label_json(json_path)\n",
    "    max_frame = int(df[\"frame\"].max())\n",
    "    frame_labels = build_frame_labels(max_frame, segs, default_level=-1)\n",
    "\n",
    "    # 특성 행렬\n",
    "    feats = df[FEATURE_COLS].astype(float).copy()\n",
    "    # NaN 보정(앞채움→뒤채움→0)\n",
    "    feats = feats.ffill().bfill().fillna(0.0)\n",
    "    feat_np = feats.to_numpy(dtype=np.float32)\n",
    "    frames = df[\"frame\"].to_numpy(dtype=np.int32)\n",
    "\n",
    "    # 프레임 인덱스 → 라벨 매핑\n",
    "    label_by_row = np.array([frame_labels[f] if f <= max_frame else -1 for f in frames], dtype=np.int32)\n",
    "\n",
    "    X_list, y_list = [], []\n",
    "    start = 0\n",
    "    last_start = len(df) - win\n",
    "    while start <= last_start:\n",
    "        end = start + win\n",
    "        seq = feat_np[start:end, :]  # (win, feat)\n",
    "        seq_labels = label_by_row[start:end]  # (win,)\n",
    "\n",
    "        # 윈도우 대표 라벨: 다수결(동점이면 마지막 프레임값)\n",
    "        cnt = Counter(seq_labels.tolist())\n",
    "        most = max(cnt.items(), key=lambda kv: (kv[1], kv[0]))[0]\n",
    "        y = most\n",
    "\n",
    "        X_list.append(seq)\n",
    "        y_list.append(y)\n",
    "        start += hop\n",
    "\n",
    "    if not X_list:\n",
    "        return np.empty((0, win, len(FEATURE_COLS)), dtype=np.float32), np.empty((0,), dtype=np.int32)\n",
    "\n",
    "    X = np.stack(X_list, axis=0).astype(np.float32)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1a943b",
   "metadata": {},
   "source": [
    "#### numpy 데이타셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "023acaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sec = 10.\n",
    "hop_sec = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "189073d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_numpy_dataset(pairs: List[Tuple[Path,Path]], window_sec=5.0, hop_sec=1.0):\n",
    "    Xs, ys = [], []\n",
    "    for csv_path, json_path in pairs:\n",
    "        Xi, yi = make_windows_for_pair(csv_path, json_path, window_sec, hop_sec)\n",
    "        if len(Xi) > 0:\n",
    "            Xs.append(Xi); ys.append(yi)\n",
    "    if not Xs:\n",
    "        raise RuntimeError(\"윈도우가 생성되지 않았습니다. 입력 파일/라벨을 확인하세요.\")\n",
    "\n",
    "    max_len = max(X.shape[1] for X in Xs)\n",
    "    Xs_padded = [\n",
    "        np.pad(X, ((0,0),(0,max_len-X.shape[1]),(0,0)), mode=\"constant\")\n",
    "        if X.shape[1] < max_len else X\n",
    "        for X in Xs\n",
    "    ]\n",
    "    \n",
    "    X = np.concatenate(Xs_padded, axis=0)\n",
    "    y = np.concatenate(ys, axis=0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e012be06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\20-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\27-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\10-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\12-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\19-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\43-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gA_2_s5_2019-03-13T09;19;23+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\37-FemaleNoGlasses-Talking&Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\25-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\45-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\33-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\28-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\21-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gB_8_s5_2019-03-13T14;10;09+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\2-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\31-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gA_5_s5_2019-03-13T09;06;49+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\17-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\46-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\1-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\36-FemaleNoGlasses-Talking&Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gB_7_s5_2019-03-13T13;55;52+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\40-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\27-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\18-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\39-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\44-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\27-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\10-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\19-FemaleNoGlasses-Talking&Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\13-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gC_11_s5_2019-03-12T09;08;15+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\23-MaleGlassesBeard-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\28-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\33-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\44-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\11-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\12-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\2-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gC_15_s5_2019-03-12T11;03;23+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\41-FemaleGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\26-FemaleGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\2-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\35-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\24-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\13-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\1-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\47-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\11-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\5-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\37-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\23-MaleGlassesBeard-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\14-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\33-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\42-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\27-FemaleNoGlasses-Talking&Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\24-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\31-FemaleGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\6-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gB_9_s5_2019-03-07T16;31;48+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\32-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\27-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\36-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\5-FemaleGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\17-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\35-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\35-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\4-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\30-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\4-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\35-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\14-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\12-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\7-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\7-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\37-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\24-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\41-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\34-FemaleNoGlasses-Talking&Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\20-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\33-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\3-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\22-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\40-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\29-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\36-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\38-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\36-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\4-FemaleGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\18-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\36-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\39-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\28-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\7-FemaleGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\23-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\28-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\30-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\31-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\43-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\26-FemaleGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\16-FemaleGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\9-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\35-FemaleNoGlasses-Talking&Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\21-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\5-FemaleGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\31-FemaleGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\10-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\31-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\17-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\9-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\30-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\30-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\6-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\37-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\47-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gC_14_s5_2019-03-12T09;18;58+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\38-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\43-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\27-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\34-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\18-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\20-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\6-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\39-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gA_4_s5_2019-03-13T10;56;52+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\38-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\8-FemaleGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\2-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\13-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\25-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\22-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\29-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\3-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\19-MaleGlassesmoustache-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\3-FemaleGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\34-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\7-FemaleGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\43-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\15-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\8-MaleGlassesBeard-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\40-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\26-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\23-FemaleNoGlasses-Talking&Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\42-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\13-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\21-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\3-FemaleGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\26-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\39-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\14-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\3-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\17-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\38-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\34-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\12-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\24-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\8-FemaleGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\29-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\29-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\15-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\3-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\9-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gB_10_s5_2019-03-12T10;35;20+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\28-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\8-MaleGlassesBeard-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\19-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\5-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\28-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gB_6_s5_2019-03-13T13;37;11+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\19-MaleGlassesmoustache-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\1-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\25-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\40-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\34-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\22-MaleGlassesmoustache-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\31-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gA_3_s5_2019-03-13T09;36;25+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\46-MaleGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\21-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\4-FemaleGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gC_13_s5_2019-03-12T10;03;00+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\41-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\37-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\23-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\22-MaleGlassesmoustache-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\15-FemaleGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\11-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\11-FemaleNoGlasses-Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\32-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\41-FemaleGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\15-FemaleGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\39-FemaleNoGlasses-Talking&Yawning-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gC_12_s5_2019-03-14T09;56;52+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\6-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\16-FemaleGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\9-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\18-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\23-FemaleNoGlasses-Normal-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\23-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\25-MaleGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\gA_1_s5_2019-03-14T14;26;17+01;00_rgb_face-labeled.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\10-MaleNoGlasses-Yawning-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\16-MaleNoGlasses-Normal-label.csv\n",
      "current csv_path: D:\\파이널 프로젝트 데이터\\dataset\\45-MaleNoGlasses-Normal-label.csv\n"
     ]
    }
   ],
   "source": [
    "# 넘파이 데이터셋\n",
    "Xtr, ytr = build_numpy_dataset(train_pairs, window_sec, hop_sec)\n",
    "Xva, yva = build_numpy_dataset(val_pairs, window_sec, hop_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e84422e",
   "metadata": {},
   "source": [
    "#### 스케일링.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8b46e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_standardizer(X: np.ndarray):\n",
    "    \"\"\"\n",
    "    채널별 표준화 스케일러(평균/표준편차) 반환.\n",
    "    \"\"\"\n",
    "    # X shape: (N, T, C)\n",
    "    mean = X.reshape(-1, X.shape[-1]).mean(axis=0)\n",
    "    std = X.reshape(-1, X.shape[-1]).std(axis=0)\n",
    "    std = np.where(std < 1e-8, 1.0, std)\n",
    "    return mean.astype(np.float32), std.astype(np.float32)\n",
    "\n",
    "def apply_standardizer(X: np.ndarray, mean: np.ndarray, std: np.ndarray):\n",
    "    return (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f3068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링 (학습 기반)\n",
    "mean, std = fit_standardizer(Xtr)\n",
    "Xtr_scaled = apply_standardizer(Xtr, mean, std)\n",
    "Xva_scaled = apply_standardizer(Xva, mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8b893",
   "metadata": {},
   "source": [
    "### 산출물 검증 파트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08c7b9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "npz = np.load(\"scaler_mean_std.npz\")\n",
    "npz_mean = npz['mean']\n",
    "npz_std = npz['std']\n",
    "npz.close()\n",
    "\n",
    "print(npz_mean == mean)\n",
    "print(npz_std == std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "319be8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_Xtr = apply_standardizer(Xtr, npz_mean, npz_std)\n",
    "npz_Xva = apply_standardizer(Xva, npz_mean, npz_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f58f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_dataset(X: np.ndarray, y: np.ndarray, batch=64, shuffle=True):\n",
    "    # y를 인덱스로 변환(-1..3 → 0..4)\n",
    "    y_idx = np.array([LEVEL_TO_INDEX[int(v)] for v in y], dtype=np.int32)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y_idx))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(min(len(X), 10000), seed=RANDOM_SEED)\n",
    "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "923f2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Dataset\n",
    "batch = 64\n",
    "\n",
    "ds_tr = to_tf_dataset(npz_Xtr, ytr, batch=batch, shuffle=True)\n",
    "ds_va = to_tf_dataset(npz_Xva, yva, batch=batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c51faf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] loss=0.6963, acc=0.7313\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"best_lstm.keras\")\n",
    "loaded_eval_res = loaded_model.evaluate(ds_va, verbose=0)\n",
    "print(f\"[VAL] loss={loaded_eval_res[0]:.4f}, acc={loaded_eval_res[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2821dbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">138,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │            \u001b[38;5;34m12\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m138,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">933,557</span> (3.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m933,557\u001b[0m (3.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">311,185</span> (1.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m311,185\u001b[0m (1.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">622,372</span> (2.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m622,372\u001b[0m (2.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "928bc2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.68      0.62       121\n",
      "           1       0.69      0.66      0.67       220\n",
      "           2       0.48      0.48      0.48       239\n",
      "           3       0.87      0.85      0.86       678\n",
      "\n",
      "    accuracy                           0.73      1258\n",
      "   macro avg       0.65      0.67      0.66      1258\n",
      "weighted avg       0.74      0.73      0.73      1258\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 82   5  34   0]\n",
      " [ 27 146  22  25]\n",
      " [ 12  54 115  58]\n",
      " [ 24   8  69 577]]\n"
     ]
    }
   ],
   "source": [
    "# 예측 샘플 & 혼동행렬\n",
    "y_true = np.array([y for _, y in ds_va.unbatch().as_numpy_iterator()])\n",
    "# y_true = np.concatenate([y for _, y in ds_va.unbatch().as_numpy_iterator()], axis=0)\n",
    "y_pred = []\n",
    "for xb, _ in ds_va:\n",
    "    pb = loaded_model.predict(xb, verbose=0)\n",
    "    y_pred.append(np.argmax(pb, axis=1))\n",
    "y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "# 간단 리포트\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "labels = sorted(set(y_true) | set(y_pred))  # 실제 등장한 클래스\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    labels=labels,\n",
    "    target_names=[str(INDEX_TO_LEVEL[i]) for i in labels]\n",
    "))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
