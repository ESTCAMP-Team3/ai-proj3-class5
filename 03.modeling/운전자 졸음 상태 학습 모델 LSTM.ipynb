{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958ca220",
   "metadata": {},
   "source": [
    "# ※현재는 1차 모델링 코드로, 확정된 코드들이 아닙니다.\n",
    "## 1차 코드는 모델 설계까지만 구현되어있습니다.   모델 평가나 성능 확인은 추후에 추가할 예정..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021fdccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc44771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 유틸\n",
    "# ------------------------------\n",
    "def load_csv_features_labels(csv_path: str):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # 숫자형만 입력특징으로 사용. (frame, drowsiness_* 제외)\n",
    "    drop_cols = set([\"drowsiness_level\", \"drowsiness_label\", \"label_name\"])  # label_name은 문자열\n",
    "    num_cols = [c for c in df.columns \n",
    "                if c not in drop_cols and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    # frame은 시간/인덱스 성격이라 보통 제외 권장 (원하면 포함 가능)\n",
    "    if \"frame\" in num_cols:\n",
    "        num_cols.remove(\"frame\")\n",
    "    X = df[num_cols].to_numpy(dtype=np.float32)\n",
    "    y = df[\"drowsiness_level\"].astype(int).to_numpy()\n",
    "    frames = df[\"frame\"].astype(int).to_numpy() if \"frame\" in df.columns else np.arange(len(df))\n",
    "    meta = {\"feature_names\": num_cols}\n",
    "    return X, y, frames, meta\n",
    "\n",
    "def load_segments_json(json_path: str):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        js = json.load(f)\n",
    "    fps = js[\"dataset\"].get(\"fps\", 30.0)  # 예: 29.76\n",
    "    segments = js[\"segments\"]\n",
    "    # [start,end) half-open\n",
    "    return fps, segments\n",
    "\n",
    "def make_windows_from_segments(\n",
    "    X: np.ndarray, y: np.ndarray, frames: np.ndarray, segments: List[Dict],\n",
    "    win_len: int, stride: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    1차(약라벨)용: 각 세그먼트 안에서만 윈도우 슬라이딩. label=-1(전이/무시) 제외.\n",
    "    세그먼트 라벨을 그대로 윈도우 라벨로 사용.\n",
    "    \"\"\"\n",
    "    Xw, yw = [], []\n",
    "    frame_to_index = {int(fr): i for i, fr in enumerate(frames)}\n",
    "    for seg in segments:\n",
    "        lab = int(seg[\"label\"])\n",
    "        if lab == -1:  # 전이/무시 제외\n",
    "            continue\n",
    "        s, e = int(seg[\"start\"]), int(seg[\"end\"])   # [s, e)\n",
    "        # 세그먼트 내부에서만 윈도우 가능 (e - s >= win_len)\n",
    "        if e - s < win_len: \n",
    "            continue\n",
    "        # 슬라이딩\n",
    "        f = s\n",
    "        while f + win_len <= e:\n",
    "            # 프레임 -> 인덱스 매핑(연속 프레임 가정)\n",
    "            # 일부 프레임 누락이 있다면 try/except로 skip 처리\n",
    "            try:\n",
    "                start_idx = frame_to_index[f]\n",
    "                end_idx   = frame_to_index[f + win_len - 1] + 1\n",
    "                x_win = X[start_idx:end_idx]\n",
    "                if x_win.shape[0] == win_len:\n",
    "                    Xw.append(x_win)\n",
    "                    yw.append(lab)\n",
    "            except KeyError:\n",
    "                pass\n",
    "            f += stride\n",
    "    if len(Xw) == 0:\n",
    "        return np.empty((0, win_len, X.shape[1]), dtype=np.float32), np.empty((0,), dtype=np.int32)\n",
    "    return np.stack(Xw), np.array(yw, dtype=np.int32)\n",
    "\n",
    "def make_windows_from_frames_majority(\n",
    "    X: np.ndarray, y: np.ndarray, frames: np.ndarray, \n",
    "    win_len: int, stride: int, majority_thr: float = 0.5\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    2차(정밀라벨)용: 전체 프레임에서 윈도우를 만들고 \n",
    "    윈도우 안 프레임 라벨의 다수결로 윈도우 라벨 결정.\n",
    "    majority_thr는 최다 라벨 비율의 최소 기준(0.5~0.7 권장).\n",
    "    \"\"\"\n",
    "    Xw, yw = [], []\n",
    "    n = len(frames)\n",
    "    start_idx = 0\n",
    "    while start_idx + win_len <= n:\n",
    "        end_idx = start_idx + win_len\n",
    "        y_win = y[start_idx:end_idx]\n",
    "        # 다수결\n",
    "        vals, cnts = np.unique(y_win, return_counts=True)\n",
    "        maj_lab = int(vals[np.argmax(cnts)])\n",
    "        maj_ratio = float(np.max(cnts)) / win_len\n",
    "        if maj_ratio >= majority_thr:\n",
    "            Xw.append(X[start_idx:end_idx])\n",
    "            yw.append(maj_lab)\n",
    "        start_idx += stride\n",
    "    if len(Xw) == 0:\n",
    "        return np.empty((0, win_len, X.shape[1]), dtype=np.float32), np.empty((0,), dtype=np.int32)\n",
    "    return np.stack(Xw), np.array(yw, dtype=np.int32)\n",
    "\n",
    "def split_by_time(Xw: np.ndarray, yw: np.ndarray, train=0.7, val=0.15):\n",
    "    \"\"\"윈도우 순서를 유지한 채 시계열 분할(시간 누수 방지).\"\"\"\n",
    "    n = len(Xw)\n",
    "    n_train = int(n * train)\n",
    "    n_val   = int(n * val)\n",
    "    X_tr, y_tr = Xw[:n_train], yw[:n_train]\n",
    "    X_va, y_va = Xw[n_train:n_train+n_val], yw[n_train:n_train+n_val]\n",
    "    X_te, y_te = Xw[n_train+n_val:], yw[n_train+n_val:]\n",
    "    return (X_tr, y_tr), (X_va, y_va), (X_te, y_te)\n",
    "\n",
    "def compute_class_weights(y: np.ndarray, n_classes=4):\n",
    "    from collections import Counter\n",
    "    cnt = Counter(y.tolist())\n",
    "    total = sum(cnt.values())\n",
    "    weights = {i: total / (n_classes * cnt.get(i, 1)) for i in range(n_classes)}\n",
    "    return weights\n",
    "\n",
    "def standardize_fit(X: np.ndarray):\n",
    "    mean = X.mean(axis=(0,1), keepdims=True)\n",
    "    std  = X.std(axis=(0,1), keepdims=True) + 1e-8\n",
    "    return mean, std\n",
    "\n",
    "def standardize_apply(X: np.ndarray, mean, std):\n",
    "    return (X - mean) / std\n",
    "\n",
    "def make_tf_dataset(X, y, batch=64, shuffle=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(X), reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def build_lstm_model(input_shape, n_classes=4):\n",
    "    inp = tf.keras.Input(shape=input_shape)  # (win_len, n_features)\n",
    "    x = tf.keras.layers.Masking(mask_value=0.0)(inp)\n",
    "    x = tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(128, return_sequences=False)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    out = tf.keras.layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(inp, out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ddd533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 경로 설정\n",
    "# ------------------------------\n",
    "PATH_CSV  = \"/mnt/data/gC_15_s5_2019-03-12T11;03;23+01;00_rgb_face-labeled.csv\"\n",
    "PATH_JSON = \"/mnt/data/gC_15_s5_2019-03-12T11;03;23+01;00_rgb_face-labeled.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7768f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 실행\n",
    "# ------------------------------\n",
    "\n",
    "# 0) 데이터 로드\n",
    "X_all, y_all, frames_all, meta = load_csv_features_labels(PATH_CSV)\n",
    "fps, segments = load_segments_json(PATH_JSON)   # fps≈29.76, segments는 [start,end)  :contentReference[oaicite:1]{index=1}\n",
    "\n",
    "# 1) 윈도우 파라미터 (10초)\n",
    "win_sec = 10.0\n",
    "stride_sec_stage1 = 2.0   # 약라벨은 비교적 큰 stride로도 충분\n",
    "stride_sec_stage2 = 1.0   # 정밀 단계는 더 촘촘히\n",
    "win_len   = int(round(fps * win_sec))\n",
    "stride_w1 = max(1, int(round(fps * stride_sec_stage1)))\n",
    "stride_w2 = max(1, int(round(fps * stride_sec_stage2)))\n",
    "\n",
    "print(f\"fps={fps:.2f}, win_len(frames)={win_len}, stride_stage1={stride_w1}, stride_stage2={stride_w2}\")\n",
    "\n",
    "# 2) 1차: JSON 세그먼트 기반 약라벨 윈도우\n",
    "Xw_weak, yw_weak = make_windows_from_segments(\n",
    "    X_all, y_all, frames_all, segments, win_len=win_len, stride=stride_w1\n",
    ")\n",
    "print(\"Stage1 weak windows:\", Xw_weak.shape, yw_weak.shape, \"labels:\", np.unique(yw_weak, return_counts=True))\n",
    "\n",
    "# 3) 2차: CSV 정밀라벨 기반 윈도우 (다수결)\n",
    "Xw_strong, yw_strong = make_windows_from_frames_majority(\n",
    "    X_all, y_all, frames_all, win_len=win_len, stride=stride_w2, majority_thr=0.6\n",
    ")\n",
    "print(\"Stage2 strong windows:\", Xw_strong.shape, yw_strong.shape, \"labels:\", np.unique(yw_strong, return_counts=True))\n",
    "\n",
    "# 4) 표준화(학습세트 통계에 맞춰)\n",
    "#   - Stage1: weak train 세트로 fit\n",
    "#   - Stage2: strong train 세트로 다시 미세조정에서만 재-fit(선택사항). \n",
    "#     여기서는 Stage1 통계를 그대로 사용하여 일관성 유지.\n",
    "(Xw1_tr, yw1_tr), (Xw1_va, yw1_va), (Xw1_te, yw1_te) = split_by_time(Xw_weak, yw_weak, train=0.8, val=0.1)\n",
    "mean1, std1 = standardize_fit(Xw1_tr)\n",
    "Xw1_tr = standardize_apply(Xw1_tr, mean1, std1)\n",
    "Xw1_va = standardize_apply(Xw1_va, mean1, std1)\n",
    "Xw1_te = standardize_apply(Xw1_te, mean1, std1)\n",
    "\n",
    "# Stage2도 동일 통계 사용(권장). 만약 재-fit 원하면 mean2,std2로 교체 가능.\n",
    "(Xw2_tr, yw2_tr), (Xw2_va, yw2_va), (Xw2_te, yw2_te) = split_by_time(Xw_strong, yw_strong, train=0.8, val=0.1)\n",
    "Xw2_tr = standardize_apply(Xw2_tr, mean1, std1)\n",
    "Xw2_va = standardize_apply(Xw2_va, mean1, std1)\n",
    "Xw2_te = standardize_apply(Xw2_te, mean1, std1)\n",
    "\n",
    "# 5) tf.data\n",
    "train1 = make_tf_dataset(Xw1_tr, yw1_tr, batch=64, shuffle=True)\n",
    "valid1 = make_tf_dataset(Xw1_va, yw1_va, batch=64, shuffle=False)\n",
    "test1  = make_tf_dataset(Xw1_te, yw1_te, batch=64, shuffle=False)\n",
    "\n",
    "train2 = make_tf_dataset(Xw2_tr, yw2_tr, batch=64, shuffle=True)\n",
    "valid2 = make_tf_dataset(Xw2_va, yw2_va, batch=64, shuffle=False)\n",
    "test2  = make_tf_dataset(Xw2_te, yw2_te, batch=64, shuffle=False)\n",
    "\n",
    "# 6) 모델\n",
    "n_classes = 4\n",
    "input_shape = (win_len, X_all.shape[1])\n",
    "model = build_lstm_model(input_shape, n_classes=n_classes)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 콜백\n",
    "ckpt1 = tf.keras.callbacks.ModelCheckpoint(\"stage1_pretrained.keras\", save_best_only=True, monitor=\"val_accuracy\", mode=\"max\")\n",
    "es1   = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_accuracy\", mode=\"max\")\n",
    "\n",
    "# 클래스 불균형 보정(약라벨 분포 기준)\n",
    "class_weights1 = compute_class_weights(yw1_tr, n_classes=n_classes)\n",
    "\n",
    "# 7) 1차 학습 (약라벨)\n",
    "hist1 = model.fit(train1, validation_data=valid1, epochs=50, callbacks=[ckpt1, es1],\n",
    "                  class_weight=class_weights1, verbose=2)\n",
    "\n",
    "print(\"Stage1 (weak) eval:\", model.evaluate(test1, verbose=0))\n",
    "\n",
    "# 8) 2차 학습: 정밀라벨로 미세조정\n",
    "#    - 더 낮은 학습률, 새 체크포인트\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(3e-4),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "ckpt2 = tf.keras.callbacks.ModelCheckpoint(\"stage2_finetuned.keras\", save_best_only=True, monitor=\"val_accuracy\", mode=\"max\")\n",
    "es2   = tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True, monitor=\"val_accuracy\", mode=\"max\")\n",
    "class_weights2 = compute_class_weights(yw2_tr, n_classes=n_classes)\n",
    "\n",
    "hist2 = model.fit(train2, validation_data=valid2, epochs=50, callbacks=[ckpt2, es2],\n",
    "                  class_weight=class_weights2, verbose=2)\n",
    "\n",
    "print(\"Stage2 (strong) eval:\", model.evaluate(test2, verbose=0))\n",
    "\n",
    "# 9) 저장\n",
    "model.save(\"drowsiness_lstm_final.keras\")\n",
    "np.savez(\"standardizer_stage1_stats.npz\", mean=mean1, std=std1, win_len=win_len)\n",
    "print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
