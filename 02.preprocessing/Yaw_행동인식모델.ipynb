{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a301f8c",
   "metadata": {},
   "source": [
    "# YawDD 특화 코드  \n",
    "# dataset 경로, 출력 파일 이름만 수정하면 다른 데이터셋에 대해서도 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d983b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91fc970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1-FemaleNoGlasses-Normal.avi', '10-FemaleNoGlasses-Normal.avi', '11-FemaleNoGlasses-Normal.avi', '12-FemaleNoGlasses-Normal.avi', '13-FemaleNoGlasses-Normal.avi', '14-FemaleNoGlasses-Normal.avi', '15-FemaleGlasses-Normal.avi', '16-FemaleGlasses-Normal.avi', '17-FemaleNoGlasses-Normal.avi', '18-FemaleNoGlasses-Normal.avi', '19-FemaleNoGlasses-Normal.avi', '2-FemaleNoGlasses-Normal.avi', '20-FemaleNoGlasses-Normal.avi', '21-FemaleNoGlasses-Normal.avi', '22-FemaleNoGlasses-Normal.avi', '23-FemaleNoGlasses-Normal.avi', '24-FemaleNoGlasses-Normal.avi', '25-FemaleNoGlasses-Normal.avi', '26-FemaleGlasses-Normal.avi', '27-FemaleNoGlasses-Normal.avi', '28-FemaleNoGlasses-Normal.avi', '29-FemaleNoGlasses-Normal.avi', '3-FemaleGlasses-Normal.avi', '30-FemaleNoGlasses-Normal.avi', '31-FemaleGlasses-Normal.avi', '31-FemaleNoGlasses-Normal.avi', '33-FemaleNoGlasses-Normal.avi', '34-FemaleNoGlasses-Normal.avi', '35-FemaleNoGlasses-Normal.avi', '36-FemaleNoGlasses-Normal.avi', '37-FemaleNoGlasses-Normal.avi', '38-FemaleNoGlasses-Normal.avi', '39-FemaleNoGlasses-Normal.avi', '4-FemaleGlasses-Normal.avi', '40-FemaleNoGlasses-Normal.avi', '41-FemaleGlasses-Normal.avi', '43-FemaleNoGlasses-Normal.avi', '5-FemaleGlasses-Normal.avi', '6-FemaleNoGlasses-Normal.avi', '7-FemaleGlasses-Normal.avi', '8-FemaleGlasses-Normal.avi', '9-FemaleNoGlasses-Normal.avi']\n",
      "['1-FemaleNoGlasses-Talking.avi', '10-FemaleNoGlasses-Talking.avi', '11-FemaleNoGlasses-Talking.avi', '12-FemaleNoGlasses-Talking.avi', '13-FemaleNoGlasses-Talking.avi', '14-FemaleNoGlasses-Talking.avi', '15-FemaleGlasses-Talking.avi', '16-FemaleGlasses-Talking.avi', '17-FemaleNoGlasses-Talking.avi', '18-FemaleNoGlasses-Talking.avi', '19-FemaleNoGlasses-Talking.avi', '2-FemaleNoGlasses-Talking.avi', '20-FemaleNoGlasses-Talking.avi', '21-FemaleNoGlasses-Talking.avi', '22-FemaleNoGlasses-Talking.avi', '23-FemaleNoGlasses-Talking.avi', '24-FemaleNoGlasses-Talking.avi', '26-FemaleGlasses-Talking.avi', '28-FemaleNoGlasses-Talking.avi', '29-FemaleNoGlasses-Talking.avi', '3-FemaleGlasses-Talking.avi', '30-FemaleNoGlasses-Talking.avi', '31-FemaleGlasses-Talking.avi', '31-FemaleNoGlasses-Talking.avi', '33-FemaleNoGlasses-Talking.avi', '34-FemaleNoGlasses-Talking.avi', '35-FemaleNoGlasses-Talking.avi', '36-FemaleNoGlasses-Talking.avi', '37-FemaleNoGlasses-Talking.avi', '38-FemaleNoGlasses-Talking.avi', '39-FemaleNoGlasses-Talking.avi', '4-FemaleGlasses-Talking.avi', '40-FemaleNoGlasses-Talking.avi', '41-FemaleGlasses-Talking.avi', '43-FemaleNoGlasses-Talking.avi', '5-FemaleGlasses-Talking.avi', '6-FemaleNoGlasses-Talking.avi', '7-FemaleGlasses-Talking.avi', '8-FemaleGlasses-Talking.avi', '9-FemaleNoGlasses-Talking.avi']\n",
      "['1-FemaleNoGlasses-Yawning.avi', '10-FemaleNoGlasses-Yawning.avi', '11-FemaleNoGlasses-Yawning.avi', '12-FemaleNoGlasses-Yawning.avi', '13-FemaleNoGlasses-Yawning.avi', '14-FemaleNoGlasses-Yawning.avi', '15-FemaleGlasses-Yawning.avi', '16-FemaleGlasses-Yawning.avi', '17-FemaleNoGlasses-Yawning.avi', '18-FemaleNoGlasses-Yawning.avi', '19-FemaleNoGlasses-Talking&Yawning.avi', '19-FemaleNoGlasses-Yawning.avi', '2-FemaleNoGlasses-Yawning.avi', '20-FemaleNoGlasses-Yawning.avi', '21-FemaleNoGlasses-Yawning.avi', '22-FemaleNoGlasses-Yawning.avi', '23-FemaleNoGlasses-Talking&Yawning.avi', '23-FemaleNoGlasses-Yawning.avi', '24-FemaleNoGlasses-Yawning.avi', '25-FemaleNoGlasses-Yawning.avi', '26-FemaleGlasses-Yawning.avi', '27-FemaleNoGlasses-Talking&Yawning.avi', '28-FemaleNoGlasses-Yawning.avi', '29-FemaleNoGlasses-Yawning.avi', '3-FemaleGlasses-Yawning.avi', '30-FemaleNoGlasses-Yawning.avi', '31-FemaleGlasses-Yawning.avi', '31-FemaleNoGlasses-Yawning.avi', '33-FemaleNoGlasses-Yawning.avi', '34-FemaleNoGlasses-Talking&Yawning.avi', '34-FemaleNoGlasses-Yawning.avi', '35-FemaleNoGlasses-Talking&Yawning.avi', '35-FemaleNoGlasses-Yawning.avi', '36-FemaleNoGlasses-Talking&Yawning.avi', '36-FemaleNoGlasses-Yawning.avi', '37-FemaleNoGlasses-Talking&Yawning.avi', '37-FemaleNoGlasses-Yawning.avi', '38-FemaleNoGlasses-Yawning.avi', '39-FemaleNoGlasses-Talking&Yawning.avi', '39-FemaleNoGlasses-Yawning.avi', '4-FemaleGlasses-Yawning.avi', '40-FemaleNoGlasses-Yawning.avi', '41-FemaleGlasses-Yawning.avi', '43-FemaleNoGlasses-Yawning.avi', '5-FemaleGlasses-Yawning.avi', '6-FemaleNoGlasses-Yawning.avi', '7-FemaleGlasses-Yawning.avi', '8-FemaleGlasses-Yawning.avi', '9-FemaleNoGlasses-Yawning.avi']\n"
     ]
    }
   ],
   "source": [
    "Normal_file_paths, Normal_file_names = [], []\n",
    "Talking_file_paths, Talking_file_names = [], []\n",
    "Yawning_file_paths, Yawning_file_names = [], []\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    for fname in files:\n",
    "        if fname.endswith(\"Normal.avi\"):\n",
    "            Normal_file_paths.append(os.path.join(root, fname))\n",
    "            Normal_file_names.append(fname)\n",
    "        if fname.endswith(\"Talking.avi\"):\n",
    "            Talking_file_paths.append(os.path.join(root, fname))\n",
    "            Talking_file_names.append(fname)\n",
    "        if fname.endswith(\"Yawning.avi\"):\n",
    "            Yawning_file_paths.append(os.path.join(root, fname))\n",
    "            Yawning_file_names.append(fname)\n",
    "\n",
    "print(Normal_file_names)\n",
    "print(Talking_file_names)\n",
    "print(Yawning_file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304910d7",
   "metadata": {},
   "source": [
    "# 각종 변수 선언 파트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4618f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "CALIB_SECONDS = 2.0       # 초기 캘리브레이션 구간(초)\n",
    "FPS_FALLBACK = 30.0       # FPS 정보가 없을 때 기본값\n",
    "SMOOTH_WIN = 5            # EAR/MAR 이동평균 윈도우\n",
    "BLINK_MAX_FRAMES = 8      # blink로 볼 수 있는 최대 닫힘 프레임 길이\n",
    "YAWN_MIN_FRAMES = 30      # 하품으로 간주할 최소 프레임 길이\n",
    "HAND_MOUTH_DIST_PX = 80   # 손가락 포인트와 입 중심 간 근접 판정 거리(픽셀)\n",
    "\n",
    "# 상태 머신 임계치 비율 (캘리브레이션 결과에 곱해 사용)\n",
    "EYE_CLOSE_RATIO = 0.85    # 눈감김 임계치: EAR_low = median(EAR_calib)*EYE_CLOSE_RATIO\n",
    "EYE_OPEN_RATIO  = 1.05    # 눈뜸 임계치: EAR_high = median(EAR_calib)*EYE_OPEN_RATIO\n",
    "MOUTH_YAWN_RATIO = 1.25   # 하품 임계치: MAR_high = median(MAR_calib)*MOUTH_YAWN_RATIO\n",
    "\n",
    "# 졸림 지표 윈도우(초)\n",
    "PERCLOS_WIN_SEC = 10.0\n",
    "RATE_WIN_SEC = 20.0\n",
    "\n",
    "# 졸림 임계값(튜닝 가능)\n",
    "PERCLOS_T1, PERCLOS_T2, PERCLOS_T3 = 0.20, 0.40, 0.60\n",
    "YAWN_T1, YAWN_T2, YAWN_T3 = 2.0, 4.0, 6.0           # per minute\n",
    "BLINK_DUR_T1, BLINK_DUR_T2, BLINK_DUR_T3 = 0.25, 0.35, 0.50  # seconds\n",
    "LONG_EC_T1, LONG_EC_T2, LONG_EC_T3 = 0.5, 0.8, 1.0            # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13200b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FaceMesh / Hands 초기화\n",
    "mp_face = mp.solutions.face_mesh\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "mp_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# FaceMesh 눈/입 계산용 랜드마크 인덱스 (MediaPipe FaceMesh)\n",
    "# EAR: (상하 거리 합) / (좌우 거리)  -- 관례적 정의\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]   # [left, top1, top2, right, bottom1, bottom2]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "# MAR: (상하 거리) / (좌우 거리)\n",
    "MOUTH_HORZ = (61, 291)    # 좌우 외측 입꼬리\n",
    "MOUTH_VERT = (13, 14)     # 상하(안쪽 입술 중앙)\n",
    "\n",
    "# 상태 관련 버퍼\n",
    "ear_buf = deque(maxlen=SMOOTH_WIN)\n",
    "mar_buf = deque(maxlen=SMOOTH_WIN)\n",
    "\n",
    "# 상태 머신 상수 (눈 + 하품)\n",
    "EYE_OPEN, EYE_CLOSE, EYE_OPENING, EYE_CLOSING, EYE_BLINK = range(5)\n",
    "YAWN_NONE, YAWN_WITH_HAND, YAWN_WITHOUT_HAND = 0, 1, 2\n",
    "\n",
    "eye_state = EYE_OPEN    # 초기 가정\n",
    "close_count = 0         # 연속 닫힘 프레임 수(블링크 판정용)\n",
    "yawn_state = YAWN_NONE\n",
    "yawn_count = 0\n",
    "\n",
    "# 캘리브레이션 샘플\n",
    "EAR_LOW, EAR_HIGH = 0.18, 0.26\n",
    "MAR_HIGH = 0.60\n",
    "ear_samples = []\n",
    "mar_samples = []\n",
    "\n",
    "# 졸림 지표 계산용 슬라이딩 버퍼 (초 단위 시간축)\n",
    "closed_flags = deque()   # (t, 0/1) — 눈감김 여부\n",
    "blink_events = deque()   # (t, duration_sec)\n",
    "yawn_events  = deque()   # (t,)\n",
    "active_close_start = None  # 현재 진행 중인 eye-closure 시작시간\n",
    "active_blink_start = None  # blink용(짧은 닫힘)\n",
    "\n",
    "# 졸음 단계 색상 팔레트\n",
    "LEVEL_COLOR = {\n",
    "    0: (0, 220, 0),     # alert - green\n",
    "    1: (0, 200, 255),   # mild - orange\n",
    "    2: (0, 128, 255),   # moderate - darker orange\n",
    "    3: (0, 0, 255)      # severe - red\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e154d3d9",
   "metadata": {},
   "source": [
    "# 각종 상태 및 라벨을 판별하는 함수들 + ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdccdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "def eye_aspect_ratio(lm, eye_idx, w, h):\n",
    "    pts = [(lm[i].x*w, lm[i].y*h) for i in eye_idx]\n",
    "    p1, p2, p3, p4, p5, p6 = pts\n",
    "    vertical = (euclid(p2, p6)+euclid(p3, p5))/2.0\n",
    "    horizontal = euclid(p1, p4)+1e-6\n",
    "    return vertical / horizontal\n",
    "\n",
    "def mouth_aspect_ratio(lm, w, h):\n",
    "    L = (lm[MOUTH_HORZ[0]].x*w, lm[MOUTH_HORZ[0]].y*h)\n",
    "    R = (lm[MOUTH_HORZ[1]].x*w, lm[MOUTH_HORZ[1]].y*h)\n",
    "    U = (lm[MOUTH_VERT[0]].x*w, lm[MOUTH_VERT[0]].y*h)\n",
    "    D = (lm[MOUTH_VERT[1]].x*w, lm[MOUTH_VERT[1]].y*h)\n",
    "    horizontal = euclid(L, R) + 1e-6\n",
    "    vertical = euclid(U, D)\n",
    "    return vertical / horizontal, ((L[0]+R[0])/2, (U[1]+D[1])/2)\n",
    "\n",
    "def moving_avg(buf, k):\n",
    "    if len(buf)==0: return None\n",
    "    return float(np.mean(list(buf)[-k:]))\n",
    "\n",
    "def draw_roi(frame, pts, color=(0,255,0), thickness=2):\n",
    "    xs = [p[0] for p in pts]; ys = [p[1] for p in pts]\n",
    "    x1, y1, x2, y2 = int(min(xs)), int(min(ys)), int(max(xs)), int(max(ys))\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
    "    return (x1, y1, x2, y2)\n",
    "\n",
    "def is_hand_near_mouth(hand_lm_list, mouth_center, max_dist_px, w, h):\n",
    "    if hand_lm_list is None: return False\n",
    "    cx, cy = mouth_center\n",
    "    for hand in hand_lm_list:\n",
    "        for lm in hand.landmark:\n",
    "            px, py = lm.x*w, lm.y*h\n",
    "            if euclid((px, py), (cx, cy)) <= max_dist_px:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def drowsiness_level(perclos, yawn_rate, avg_blink_dur, longest_ec):\n",
    "    # 가장 심한 상태 조건을 우선 판단\n",
    "    # Severe 우선\n",
    "    if (perclos is not None and perclos > PERCLOS_T3) or \\\n",
    "       (yawn_rate is not None and yawn_rate > YAWN_T3) or \\\n",
    "       (longest_ec is not None and longest_ec >= LONG_EC_T3):\n",
    "        return 3, \"severe_drowsy\"\n",
    "    # Moderate\n",
    "    if (perclos is not None and perclos > PERCLOS_T2) or \\\n",
    "       (yawn_rate is not None and yawn_rate > YAWN_T2) or \\\n",
    "       (avg_blink_dur is not None and avg_blink_dur > BLINK_DUR_T2) or \\\n",
    "       (longest_ec is not None and longest_ec >= LONG_EC_T2):\n",
    "        return 2, \"moderate_drowsy\"\n",
    "    # Mild\n",
    "    if (perclos is not None and perclos > PERCLOS_T1) or \\\n",
    "       (yawn_rate is not None and yawn_rate > YAWN_T1) or \\\n",
    "       (avg_blink_dur is not None and avg_blink_dur > BLINK_DUR_T1) or \\\n",
    "       (longest_ec is not None and longest_ec >= LONG_EC_T1):\n",
    "        return 1, \"mild_drowsy\"\n",
    "    # Alert\n",
    "    return 0, \"alert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf60f0f",
   "metadata": {},
   "source": [
    "# 영상 라벨링 분석을 위한 자동 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f666461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drowsiness_labeling(cap, output, logs, fps, width, height):\n",
    "    with mp_face.FaceMesh(\n",
    "       static_image_mode=False,\n",
    "       refine_landmarks=True,\n",
    "       max_num_faces=1,\n",
    "       min_detection_confidence=0.5,\n",
    "       min_tracking_confidence=0.5\n",
    "       ) as face_mesh, mp_hands.Hands(\n",
    "       static_image_mode=False,\n",
    "       max_num_hands=2,\n",
    "       min_detection_confidence=0.5,\n",
    "       min_tracking_confidence=0.5\n",
    "    ) as hands:\n",
    "       global EAR_HIGH, EAR_LOW, MAR_HIGH\n",
    "\n",
    "       frame_idx = 0\n",
    "       eye_state = EYE_OPEN    # 초기 가정\n",
    "       close_count = 0         # 연속 닫힘 프레임 수(블링크 판정용)\n",
    "       yawn_state = YAWN_NONE\n",
    "       yawn_count = 0\n",
    "\n",
    "       active_close_start = None  # 현재 진행 중인 eye-closure 시작시간\n",
    "       active_blink_start = None  # blink용(짧은 닫힘)\n",
    "\n",
    "       ear_buf.clear()\n",
    "       mar_buf.clear()\n",
    "       blink_events.clear()\n",
    "       yawn_events.clear()\n",
    "       closed_flags.clear()\n",
    "\n",
    "       while True:\n",
    "              ret, frame = cap.read()\n",
    "              if not ret: break\n",
    "              frame_idx += 1\n",
    "              t_sec = frame_idx / fps\n",
    "\n",
    "              rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "              face_res = face_mesh.process(rgb)\n",
    "              hands_res = None  # 조건부로 돌려도 됨(여기선 항상 실행)\n",
    "\n",
    "              label_id = 0\n",
    "              label_str = \"eyes_state/open\"\n",
    "\n",
    "              if face_res.multi_face_landmarks:\n",
    "                     face_landmarks = face_res.multi_face_landmarks[0].landmark\n",
    "\n",
    "                     # EAR/MAR\n",
    "                     ear_l = eye_aspect_ratio(face_landmarks, LEFT_EYE, width, height)\n",
    "                     ear_r = eye_aspect_ratio(face_landmarks, RIGHT_EYE, width, height)\n",
    "                     ear = (ear_l + ear_r) / 2.0\n",
    "                     mar, mouth_center = mouth_aspect_ratio(face_landmarks, width, height)\n",
    "\n",
    "                     ear_buf.append(ear)\n",
    "                     mar_buf.append(mar)\n",
    "                     ear_s = moving_avg(ear_buf, SMOOTH_WIN)\n",
    "                     mar_s = moving_avg(mar_buf, SMOOTH_WIN)\n",
    "\n",
    "                     # 캘리브레이션 샘플 수집\n",
    "                     if frame_idx <= int(CALIB_SECONDS * fps):\n",
    "                            ear_samples.append(ear)\n",
    "                            mar_samples.append(mar)\n",
    "                            if frame_idx == int(CALIB_SECONDS * fps):\n",
    "                                   if len(ear_samples) >= 5:\n",
    "                                          ear_med = float(np.median(ear_samples))\n",
    "                                          EAR_LOW  = ear_med * EYE_CLOSE_RATIO\n",
    "                                          EAR_HIGH = ear_med * EYE_OPEN_RATIO\n",
    "                                   if len(mar_samples) >= 5:\n",
    "                                          mar_med = float(np.median(mar_samples))\n",
    "                                          MAR_HIGH = mar_med * MOUTH_YAWN_RATIO\n",
    "\n",
    "                     # 손-입 근접\n",
    "                     hands_res = hands.process(rgb)\n",
    "                     hand_near = is_hand_near_mouth(\n",
    "                            hands_res.multi_hand_landmarks if hands_res else None,\n",
    "                            mouth_center, HAND_MOUTH_DIST_PX, width, height\n",
    "                     )\n",
    "\n",
    "                     # 눈 상태 머신\n",
    "                     prev_state = eye_state\n",
    "                     if ear_s is None:\n",
    "                            eye_state = EYE_OPEN\n",
    "                     else:\n",
    "                            if len(ear_buf) >= 3:\n",
    "                                   ear_deriv = ear_buf[-1] - ear_buf[-3]\n",
    "                            else:\n",
    "                                   ear_deriv = 0.0\n",
    "\n",
    "                            is_closed = ear_s < EAR_LOW\n",
    "                            is_opened = ear_s > EAR_HIGH\n",
    "\n",
    "                            if is_closed:\n",
    "                                   eye_state = EYE_CLOSE if prev_state == EYE_CLOSE else (EYE_CLOSING if ear_deriv < 0 else EYE_CLOSE)\n",
    "                                   close_count += 1\n",
    "                            elif is_opened:\n",
    "                                   eye_state = EYE_OPEN if prev_state == EYE_OPEN else (EYE_OPENING if ear_deriv > 0 else EYE_OPEN)\n",
    "                                   # blink 판정\n",
    "                                   if 0 < close_count <= BLINK_MAX_FRAMES:\n",
    "                                          eye_state = EYE_BLINK\n",
    "                                   close_count = 0\n",
    "                            else:\n",
    "                                   eye_state = EYE_OPENING if ear_deriv > 0 else (EYE_CLOSING if ear_deriv < 0 else prev_state)\n",
    "                                   if prev_state in (EYE_CLOSE, EYE_CLOSING):\n",
    "                                          close_count += 1\n",
    "                                   else:\n",
    "                                          close_count = 0\n",
    "\n",
    "                     # 하품 상태\n",
    "                     if mar_s is not None and mar_s > MAR_HIGH:\n",
    "                            yawn_count += 1\n",
    "                            yawn_state = YAWN_WITH_HAND if hand_near else YAWN_WITHOUT_HAND\n",
    "                     else:\n",
    "                            yawn_state = YAWN_NONE\n",
    "                            yawn_count = 0\n",
    "\n",
    "                     # 최종 행동 라벨\n",
    "                     if yawn_state != YAWN_NONE and yawn_count >= YAWN_MIN_FRAMES:\n",
    "                            if yawn_state == YAWN_WITH_HAND:\n",
    "                                   label_id, label_str = 5, \"yawning/Yawning with hand\"\n",
    "                            else:\n",
    "                                   label_id, label_str = 6, \"yawning/Yawning without hand\"\n",
    "                     else:\n",
    "                            if   eye_state == EYE_OPEN:    label_id, label_str = 0, \"eyes_state/open\"\n",
    "                            elif eye_state == EYE_CLOSE:   label_id, label_str = 1, \"eyes_state/close\"\n",
    "                            elif eye_state == EYE_OPENING: label_id, label_str = 2, \"eyes_state/opening\"\n",
    "                            elif eye_state == EYE_CLOSING: label_id, label_str = 3, \"eyes_state/closing\"\n",
    "                            elif eye_state == EYE_BLINK:   label_id, label_str = 4, \"blinks/blinking\"\n",
    "\n",
    "                     # ====== 졸림 지표 업데이트 ======\n",
    "                     # A) PERCLOS: 최근 PERCLOS_WIN_SEC 동안 '눈감김' 비율\n",
    "                     closed_flag = 1 if ear_s is not None and ear_s < EAR_LOW else 0\n",
    "                     closed_flags.append((t_sec, closed_flag))\n",
    "                     while closed_flags and (t_sec - closed_flags[0][0] > PERCLOS_WIN_SEC):\n",
    "                            closed_flags.popleft()\n",
    "                     if closed_flags:\n",
    "                            perclos = sum(f for _, f in closed_flags) / float(len(closed_flags))\n",
    "                     else:\n",
    "                            perclos = None\n",
    "\n",
    "                     # B) blink 이벤트 기록(짧은 닫힘)\n",
    "                     # blink가 찍히는 순간(eye_state == EYE_BLINK)에서 duration 계산\n",
    "                     # 간단히: 방금 전까지의 close_count를 duration으로 사용\n",
    "                     if eye_state == EYE_BLINK:\n",
    "                            blink_dur = close_count / fps  # 방금 열림과 함께 close_count가 0으로 초기화되기 전에 계산됨\n",
    "                            blink_events.append((t_sec, blink_dur))\n",
    "                     # 창구 유지\n",
    "                     while blink_events and (t_sec - blink_events[0][0] > RATE_WIN_SEC):\n",
    "                            blink_events.popleft()\n",
    "\n",
    "                     if blink_events:\n",
    "                            blink_rate = len(blink_events) * (60.0 / RATE_WIN_SEC)  # per 20s\n",
    "                            avg_blink_dur = float(np.mean([d for _, d in blink_events]))\n",
    "                     else:\n",
    "                            blink_rate = 0.0\n",
    "                            avg_blink_dur = None\n",
    "\n",
    "                     # C) 긴 eye-closure 감지(연속 close가 길면 이벤트로 기록)\n",
    "                     # close 연속 구간의 시작/끝 추적\n",
    "                     if closed_flag == 1 and active_close_start is None:\n",
    "                            active_close_start = t_sec\n",
    "                     if closed_flag == 0 and active_close_start is not None:\n",
    "                            dur = t_sec - active_close_start\n",
    "                            blink_events.append((t_sec, dur))  # 긴 eye closure도 blink_events에 포함시켜 평균/최대에 반영\n",
    "                            active_close_start = None\n",
    "                     # longest eye closure (최근 RATE_WIN_SEC)\n",
    "                     if blink_events:\n",
    "                            longest_ec = max(d for _, d in blink_events)\n",
    "                     else:\n",
    "                            longest_ec = None\n",
    "\n",
    "                     # D) yawn 이벤트(프레임 지속 충족 시 시점 기록)\n",
    "                     if yawn_state != YAWN_NONE and yawn_count == YAWN_MIN_FRAMES:\n",
    "                            yawn_events.append((t_sec,))\n",
    "                     while yawn_events and (t_sec - yawn_events[0][0] > RATE_WIN_SEC):\n",
    "                            yawn_events.popleft()\n",
    "                     yawn_rate = len(yawn_events) * (60.0 / RATE_WIN_SEC) if yawn_events else 0.0\n",
    "\n",
    "                     # ====== 졸림 단계 산출 ======\n",
    "                     d_level, d_label = drowsiness_level(perclos, yawn_rate, avg_blink_dur, longest_ec)\n",
    "\n",
    "                     # ====== 시각화 ======\n",
    "                     cv2.putText(frame, f\"Label {label_id}: {label_str}\", (20, 40),\n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 200, 255), 2)\n",
    "                     if ear_s is not None:\n",
    "                            cv2.putText(frame, f\"EAR:{ear_s:.3f} (L:{EAR_LOW:.3f} H:{EAR_HIGH:.3f})\",\n",
    "                                          (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "                     if mar_s is not None:\n",
    "                            cv2.putText(frame, f\"MAR:{mar_s:.3f} (Y>{MAR_HIGH:.3f})\",\n",
    "                                          (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,200,0), 2)\n",
    "\n",
    "                     # 졸림 지표/단계 표시\n",
    "                     c = LEVEL_COLOR[d_level]\n",
    "                     cv2.putText(frame, f\"Drowsiness {d_level}: {d_label}\", (20, 135),\n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, c, 2)\n",
    "                     cv2.putText(frame, f\"PERCLOS:{(perclos if perclos is not None else np.nan):.2f}  \"\n",
    "                                          f\"Yawn/min:{yawn_rate:.1f}  \"\n",
    "                                          f\"Blink/min:{blink_rate:.1f}  \"\n",
    "                                          f\"AvgBlinkDur:{(avg_blink_dur if avg_blink_dur else np.nan):.2f}s  \"\n",
    "                                          f\"LongestEC:{(longest_ec if longest_ec else np.nan):.2f}s\",\n",
    "                                   (20, 165), cv2.FONT_HERSHEY_SIMPLEX, 0.3, c, 2)\n",
    "\n",
    "              else:\n",
    "                     # 얼굴 미검출 시\n",
    "                     label_id, label_str = 0, \"eyes_state/open\"\n",
    "                     d_level, d_label = 0, \"alert\"\n",
    "                     perclos = None; yawn_rate = 0.0; blink_rate = 0.0; avg_blink_dur = None; longest_ec = None\n",
    "                     cv2.putText(frame, \"Face not detected\", (20, 40),\n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 2)\n",
    "\n",
    "              # ====== 로그 저장 ======\n",
    "              logs.append({\n",
    "                     \"frame\": frame_idx,\n",
    "                     \"time_sec\": t_sec,\n",
    "                     \"label_id\": label_id,\n",
    "                     \"label_name\": label_str,\n",
    "                     \"EAR\": float(ear_buf[-1]) if len(ear_buf)>0 else np.nan,\n",
    "                     \"MAR\": float(mar_buf[-1]) if len(mar_buf)>0 else np.nan,\n",
    "                     \"yawn_rate_per_min\": float(yawn_rate),\n",
    "                     \"blink_rate_per_min\": float(blink_rate) if face_res.multi_face_landmarks else 0.0,\n",
    "                     \"avg_blink_dur_sec\": float(avg_blink_dur) if avg_blink_dur is not None else np.nan,\n",
    "                     \"longest_eye_closure_sec\": float(longest_ec) if longest_ec is not None else np.nan,\n",
    "                     \"drowsiness_level\": d_level,\n",
    "                     \"drowsiness_label\": d_label\n",
    "              })\n",
    "\n",
    "              output.write(frame)\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158adbbe",
   "metadata": {},
   "source": [
    "# 영상 라벨링 수행\n",
    "## Normal, Talking, Yawning 구분에 따라 다른 for문 시작점 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041e988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video: ./output/1-FemaleNoGlasses-Yawning-labeled.avi\n",
      "Saved CSV:   ./output/1-FemaleNoGlasses-Yawning-labeled.csv\n",
      "Saved video: ./output/10-FemaleNoGlasses-Yawning-labeled.avi\n",
      "Saved CSV:   ./output/10-FemaleNoGlasses-Yawning-labeled.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 캘리브 구간 프레임 수\u001b[39;00m\n\u001b[0;32m     22\u001b[0m calib_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(CALIB_SECONDS \u001b[38;5;241m*\u001b[39m fps)\n\u001b[1;32m---> 24\u001b[0m output_log \u001b[38;5;241m=\u001b[39m drowsiness_labeling(cap, out, logs, fps, width, height)\n\u001b[0;32m     26\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m     27\u001b[0m out\u001b[38;5;241m.\u001b[39mrelease()\n",
      "Cell \u001b[1;32mIn[55], line 72\u001b[0m, in \u001b[0;36mdrowsiness_labeling\u001b[1;34m(cap, output, logs, fps, width, height)\u001b[0m\n\u001b[0;32m     69\u001b[0m                      MAR_HIGH \u001b[38;5;241m=\u001b[39m mar_med \u001b[38;5;241m*\u001b[39m MOUTH_YAWN_RATIO\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# 손-입 근접\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m hands_res \u001b[38;5;241m=\u001b[39m hands\u001b[38;5;241m.\u001b[39mprocess(rgb)\n\u001b[0;32m     73\u001b[0m hand_near \u001b[38;5;241m=\u001b[39m is_hand_near_mouth(\n\u001b[0;32m     74\u001b[0m        hands_res\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks \u001b[38;5;28;01mif\u001b[39;00m hands_res \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     75\u001b[0m        mouth_center, HAND_MOUTH_DIST_PX, width, height\n\u001b[0;32m     76\u001b[0m )\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# 눈 상태 머신\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    133\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mprocess(input_data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: image})\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mwait_until_idle()\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for video_path, video_name in zip(Normal_file_paths, Normal_file_names):\n",
    "#for video_path, video_name in zip(Talking_file_paths,Talking_file_names):\n",
    "for video_path, video_name in zip(Yawning_file_paths, Yawning_file_names):\n",
    "       # 미리 저장된 영상을 사용\n",
    "       cap = cv2.VideoCapture(video_path)  \n",
    "\n",
    "       fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "       if fps <= 1e-2: fps = FPS_FALLBACK\n",
    "       width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "       height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "       total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.get(cv2.CAP_PROP_FRAME_COUNT)>0 else None\n",
    "\n",
    "       fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "       output_name = video_name.replace(\".avi\", \"-labeled.avi\")\n",
    "       out = cv2.VideoWriter(\"./output/\"+ output_name, fourcc, fps, (width, height))\n",
    "\n",
    "       logs = []\n",
    "\n",
    "       # 캘리브 구간 프레임 수\n",
    "       calib_frames = int(CALIB_SECONDS * fps)\n",
    "\n",
    "       output_log = drowsiness_labeling(cap, out, logs, fps, width, height)\n",
    "\n",
    "       cap.release()\n",
    "       out.release()\n",
    "       cv2.destroyAllWindows()\n",
    "\n",
    "       pd.DataFrame(output_log).to_csv(\"./output/\"+output_name.replace(\".avi\", \".csv\"), index=False)\n",
    "       print(f\"Saved video: {\"./output/\"+output_name}\")\n",
    "       print(f\"Saved CSV:   {\"./output/\"+output_name.replace(\".avi\", \".csv\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac54d9d",
   "metadata": {},
   "source": [
    "# csv log 파일 → segment 정보를 담은 json 파일화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1-FemaleNoGlasses-Normal-labeled.csv', '10-FemaleNoGlasses-Normal-labeled.csv', '11-FemaleNoGlasses-Normal-labeled.csv', '12-FemaleNoGlasses-Normal-labeled.csv', '13-FemaleNoGlasses-Normal-labeled.csv', '14-FemaleNoGlasses-Normal-labeled.csv', '15-FemaleGlasses-Normal-labeled.csv', '16-FemaleGlasses-Normal-labeled.csv', '17-FemaleNoGlasses-Normal-labeled.csv', '18-FemaleNoGlasses-Normal-labeled.csv', '19-FemaleNoGlasses-Normal-labeled.csv', '2-FemaleNoGlasses-Normal-labeled.csv', '20-FemaleNoGlasses-Normal-labeled.csv', '21-FemaleNoGlasses-Normal-labeled.csv', '22-FemaleNoGlasses-Normal-labeled.csv', '23-FemaleNoGlasses-Normal-labeled.csv', '24-FemaleNoGlasses-Normal-labeled.csv', '25-FemaleNoGlasses-Normal-labeled.csv', '26-FemaleGlasses-Normal-labeled.csv', '27-FemaleNoGlasses-Normal-labeled.csv', '28-FemaleNoGlasses-Normal-labeled.csv', '29-FemaleNoGlasses-Normal-labeled.csv', '3-FemaleGlasses-Normal-labeled.csv', '30-FemaleNoGlasses-Normal-labeled.csv', '31-FemaleGlasses-Normal-labeled.csv', '31-FemaleNoGlasses-Normal-labeled.csv', '33-FemaleNoGlasses-Normal-labeled.csv', '34-FemaleNoGlasses-Normal-labeled.csv', '35-FemaleNoGlasses-Normal-labeled.csv', '36-FemaleNoGlasses-Normal-labeled.csv', '37-FemaleNoGlasses-Normal-labeled.csv', '38-FemaleNoGlasses-Normal-labeled.csv', '39-FemaleNoGlasses-Normal-labeled.csv', '4-FemaleGlasses-Normal-labeled.csv', '40-FemaleNoGlasses-Normal-labeled.csv', '41-FemaleGlasses-Normal-labeled.csv', '43-FemaleNoGlasses-Normal-labeled.csv', '5-FemaleGlasses-Normal-labeled.csv', '6-FemaleNoGlasses-Normal-labeled.csv', '7-FemaleGlasses-Normal-labeled.csv', '8-FemaleGlasses-Normal-labeled.csv', '9-FemaleNoGlasses-Normal-labeled.csv']\n",
      "['1-FemaleNoGlasses-Yawning-labeled.csv', '10-FemaleNoGlasses-Yawning-labeled.csv', '11-FemaleNoGlasses-Yawning-labeled.csv', '12-FemaleNoGlasses-Yawning-labeled.csv', '13-FemaleNoGlasses-Yawning-labeled.csv', '14-FemaleNoGlasses-Yawning-labeled.csv', '15-FemaleGlasses-Yawning-labeled.csv', '16-FemaleGlasses-Yawning-labeled.csv', '17-FemaleNoGlasses-Yawning-labeled.csv', '18-FemaleNoGlasses-Yawning-labeled.csv', '19-FemaleNoGlasses-Talking&Yawning-labeled.csv', '19-FemaleNoGlasses-Yawning-labeled.csv', '2-FemaleNoGlasses-Yawning-labeled.csv', '20-FemaleNoGlasses-Yawning-labeled.csv', '21-FemaleNoGlasses-Yawning-labeled.csv', '22-FemaleNoGlasses-Yawning-labeled.csv', '23-FemaleNoGlasses-Talking&Yawning-labeled.csv', '23-FemaleNoGlasses-Yawning-labeled.csv', '24-FemaleNoGlasses-Yawning-labeled.csv', '25-FemaleNoGlasses-Yawning-labeled.csv', '26-FemaleGlasses-Yawning-labeled.csv', '27-FemaleNoGlasses-Talking&Yawning-labeled.csv', '28-FemaleNoGlasses-Yawning-labeled.csv', '29-FemaleNoGlasses-Yawning-labeled.csv', '3-FemaleGlasses-Yawning-labeled.csv', '30-FemaleNoGlasses-Yawning-labeled.csv', '31-FemaleGlasses-Yawning-labeled.csv', '31-FemaleNoGlasses-Yawning-labeled.csv', '33-FemaleNoGlasses-Yawning-labeled.csv', '34-FemaleNoGlasses-Talking&Yawning-labeled.csv', '34-FemaleNoGlasses-Yawning-labeled.csv', '35-FemaleNoGlasses-Talking&Yawning-labeled.csv', '35-FemaleNoGlasses-Yawning-labeled.csv', '36-FemaleNoGlasses-Talking&Yawning-labeled.csv', '36-FemaleNoGlasses-Yawning-labeled.csv', '37-FemaleNoGlasses-Talking&Yawning-labeled.csv', '37-FemaleNoGlasses-Yawning-labeled.csv', '38-FemaleNoGlasses-Yawning-labeled.csv', '39-FemaleNoGlasses-Talking&Yawning-labeled.csv', '39-FemaleNoGlasses-Yawning-labeled.csv', '4-FemaleGlasses-Yawning-labeled.csv', '40-FemaleNoGlasses-Yawning-labeled.csv', '41-FemaleGlasses-Yawning-labeled.csv', '43-FemaleNoGlasses-Yawning-labeled.csv', '5-FemaleGlasses-Yawning-labeled.csv', '6-FemaleNoGlasses-Yawning-labeled.csv', '7-FemaleGlasses-Yawning-labeled.csv', '8-FemaleGlasses-Yawning-labeled.csv', '9-FemaleNoGlasses-Yawning-labeled.csv']\n"
     ]
    }
   ],
   "source": [
    "# csv 파일의 이름 및 경로를 normal, yawning 구분에 따라 나눠서 취합 후 저장\n",
    "\n",
    "normal_csv_file_paths, normal_csv_file_names = [], []\n",
    "yawning_csv_file_paths, yawning_csv_file_names = [], []\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    for fname in files:\n",
    "        if fname.endswith(\"Normal-labeled.csv\"):\n",
    "            normal_csv_file_paths.append(os.path.join(root, fname))\n",
    "            normal_csv_file_names.append(fname)\n",
    "        if fname.endswith(\"Yawning-labeled.csv\"):\n",
    "            yawning_csv_file_paths.append(os.path.join(root, fname))\n",
    "            yawning_csv_file_names.append(fname)\n",
    "            \n",
    "print(normal_csv_file_names)\n",
    "print(yawning_csv_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment화 json 파일 생성 부분\n",
    "# csv 파일을 읽은 후 → drowsiness level에 따라 구역을 segment화 시켜 각 구간의 길이를 계산\n",
    "def make_segments(df, frame_col, label_col, insert_gaps=True):\n",
    "    d = df.sort_values(by=frame_col).reset_index(drop=True).copy()\n",
    "    d[frame_col] = d[frame_col].astype(int)\n",
    "    d[label_col] = d[label_col].astype(int)\n",
    "    if d.empty: \n",
    "        return []\n",
    "\n",
    "    segs = []\n",
    "    start = int(d.loc[0, frame_col])\n",
    "    prev_frame = start\n",
    "    prev_label = int(d.loc[0, label_col])\n",
    "\n",
    "    for i in range(1, len(d)):\n",
    "        f = int(d.loc[i, frame_col])\n",
    "        lab = int(d.loc[i, label_col])\n",
    "        # 프레임 갭(누락 프레임) 처리\n",
    "        if f != prev_frame + 1:\n",
    "            segs.append({\"start\": start, \"end\": prev_frame + 1, \"label\": prev_label})\n",
    "            if insert_gaps and f > prev_frame + 1:\n",
    "                segs.append({\"start\": prev_frame + 1, \"end\": f, \"label\": -1})  # 전이/무시\n",
    "            start, prev_frame, prev_label = f, f, lab\n",
    "            continue\n",
    "        # 라벨 변경 경계\n",
    "        if lab != prev_label:\n",
    "            segs.append({\"start\": start, \"end\": f, \"label\": prev_label})\n",
    "            start, prev_label = f, lab\n",
    "        prev_frame = f\n",
    "\n",
    "    segs.append({\"start\": start, \"end\": prev_frame + 1, \"label\": prev_label})\n",
    "    return segs\n",
    "\n",
    "def convert_csv_to_segments_json(csv_path, out_json_path, fps=30):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[[\"frame\", \"time_sec\", \"drowsiness_level\", \"drowsiness_label\"]]\n",
    "\n",
    "    segments = make_segments(df, \"frame\", \"drowsiness_level\", insert_gaps=True)\n",
    "    num_frames = int(df[\"frame\"].max()) + 1\n",
    "\n",
    "    friendly = {0:\"정상\", 1:\"의심\", 2:\"주의\", 3:\"위험\", -1:\"무시\"}\n",
    "    class_map = [{\"id\": int(i), \"name\": friendly.get(int(i))} for i in friendly]\n",
    "\n",
    "    payload = {\n",
    "        \"schema_version\": \"1.0\",\n",
    "        \"dataset\": {\n",
    "            \"id\": os.path.splitext(os.path.basename(csv_path))[0],\n",
    "            \"source\": csv_path,\n",
    "            \"fps\": fps,\n",
    "            \"num_frames\": num_frames,\n",
    "            \"timebase\": \"frame\"\n",
    "        },\n",
    "        \"segments\": segments,\n",
    "        \"class_map\": class_map,\n",
    "        \"meta\": {\n",
    "            \"annotator\": \"auto-convert + human-verified\",\n",
    "            \"created_at\": pd.Timestamp.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "            \"comments\": \"half-open [start,end) rule; gaps labeled -1\"\n",
    "        }\n",
    "    }\n",
    "    with open(out_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65910d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for video_path, video_name, csv_path, csv_name in zip(Normal_file_paths, Normal_file_names, normal_csv_file_paths,normal_csv_file_names):\n",
    "for video_path, video_name, csv_path, csv_name in zip(Yawning_file_paths, Yawning_file_names, yawning_csv_file_paths, yawning_csv_file_names):\n",
    "    cap = cv2.VideoCapture(video_path)  \n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps <= 1e-2: fps = FPS_FALLBACK\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.get(cv2.CAP_PROP_FRAME_COUNT)>0 else None\n",
    "\n",
    "    convert_csv_to_segments_json(csv_path=csv_path, \n",
    "                                 out_json_path='./output/segment/'+csv_name.replace('.csv', '.json'),\n",
    "                                 fps=fps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
