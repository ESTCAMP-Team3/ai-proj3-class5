{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a301f8c",
   "metadata": {},
   "source": [
    "해당 코드들은 자동화 최적화가 되어 있지 않음\n",
    "\n",
    "아직은 1개씩만 돌려보고 결과를 확인하기 위한 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d983b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91fc970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.\\\\dmd\\\\gA\\\\1\\\\s5\\\\gA_1_s5_2019-03-14T14;26;17+01;00_rgb_face.mp4', '.\\\\dmd\\\\gA\\\\2\\\\s5\\\\gA_2_s5_2019-03-13T09;19;23+01;00_rgb_face.mp4', '.\\\\dmd\\\\gA\\\\3\\\\s5\\\\gA_3_s5_2019-03-13T09;36;25+01;00_rgb_face.mp4', '.\\\\dmd\\\\gA\\\\4\\\\s5\\\\gA_4_s5_2019-03-13T10;56;52+01;00_rgb_face.mp4', '.\\\\dmd\\\\gA\\\\5\\\\s5\\\\gA_5_s5_2019-03-13T09;06;49+01;00_rgb_face.mp4', '.\\\\dmd\\\\gB\\\\10\\\\s5\\\\gB_10_s5_2019-03-12T10;35;20+01;00_rgb_face.mp4', '.\\\\dmd\\\\gB\\\\6\\\\s5\\\\gB_6_s5_2019-03-13T13;37;11+01;00_rgb_face.mp4', '.\\\\dmd\\\\gB\\\\7\\\\s5\\\\gB_7_s5_2019-03-13T13;55;52+01;00_rgb_face.mp4', '.\\\\dmd\\\\gB\\\\8\\\\s5\\\\gB_8_s5_2019-03-13T14;10;09+01;00_rgb_face.mp4', '.\\\\dmd\\\\gB\\\\9\\\\s5\\\\gB_9_s5_2019-03-07T16;31;48+01;00_rgb_face.mp4', '.\\\\dmd\\\\gC\\\\11\\\\s5\\\\gC_11_s5_2019-03-12T09;08;15+01;00_rgb_face.mp4', '.\\\\dmd\\\\gC\\\\12\\\\s5\\\\gC_12_s5_2019-03-14T09;56;52+01;00_rgb_face.mp4', '.\\\\dmd\\\\gC\\\\13\\\\s5\\\\gC_13_s5_2019-03-12T10;03;00+01;00_rgb_face.mp4', '.\\\\dmd\\\\gC\\\\14\\\\s5\\\\gC_14_s5_2019-03-12T09;18;58+01;00_rgb_face.mp4', '.\\\\dmd\\\\gC\\\\15\\\\s5\\\\gC_15_s5_2019-03-12T11;03;23+01;00_rgb_face.mp4']\n",
      "['.\\\\dmd\\\\gA\\\\1\\\\s5\\\\gA_1_s5_2019-03-14T14;26;17+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gA\\\\2\\\\s5\\\\gA_2_s5_2019-03-13T09;19;23+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gA\\\\3\\\\s5\\\\gA_3_s5_2019-03-13T09;36;25+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gA\\\\4\\\\s5\\\\gA_4_s5_2019-03-13T10;56;52+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gA\\\\5\\\\s5\\\\gA_5_s5_2019-03-13T09;06;49+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gB\\\\10\\\\s5\\\\gB_10_s5_2019-03-12T10;35;20+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gB\\\\10\\\\s5\\\\gB_10_s5_2019-03-13T14;17;28+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gB\\\\6\\\\s5\\\\gB_6_s5_2019-03-13T13;37;11+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gB\\\\7\\\\s5\\\\gB_7_s5_2019-03-13T13;55;52+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gB\\\\8\\\\s5\\\\gB_8_s5_2019-03-13T14;10;09+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gB\\\\9\\\\s5\\\\gB_9_s5_2019-03-07T16;31;48+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gC\\\\11\\\\s5\\\\gC_11_s5_2019-03-12T09;08;15+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gC\\\\12\\\\s5\\\\gC_12_s5_2019-03-14T09;56;52+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gC\\\\13\\\\s5\\\\gC_13_s5_2019-03-12T10;03;00+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gC\\\\14\\\\s5\\\\gC_14_s5_2019-03-12T09;18;58+01;00_rgb_ann_drowsiness.json', '.\\\\dmd\\\\gC\\\\15\\\\s5\\\\gC_15_s5_2019-03-12T11;03;23+01;00_rgb_ann_drowsiness.json']\n"
     ]
    }
   ],
   "source": [
    "target_files = []\n",
    "json_paths = []\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    for fname in files:\n",
    "        if fname.endswith(\"rgb_face.mp4\"):\n",
    "            target_files.append(os.path.join(root, fname))\n",
    "        if fname.endswith(\"drowsiness.json\"):\n",
    "            json_paths.append(os.path.join(root, fname))\n",
    "\n",
    "print(target_files)\n",
    "print(json_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304910d7",
   "metadata": {},
   "source": [
    "# 1. Mediapipe 영상 labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4618f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_VIDEO = \"labeled_output_with_drowsiness.mp4\"              # 출력 비디오 파일명\n",
    "OUTPUT_CSV = \"per_frame_with_drowsiness.csv\"              # 출력 CSV 파일명\n",
    "\n",
    "CALIB_SECONDS = 2.0       # 초기 캘리브레이션 구간(초)\n",
    "FPS_FALLBACK = 30.0       # FPS 정보가 없을 때 기본값\n",
    "SMOOTH_WIN = 5            # EAR/MAR 이동평균 윈도우\n",
    "BLINK_MAX_FRAMES = 8      # blink로 볼 수 있는 최대 닫힘 프레임 길이\n",
    "YAWN_MIN_FRAMES = 30      # 하품으로 간주할 최소 프레임 길이\n",
    "HAND_MOUTH_DIST_PX = 80   # 손가락 포인트와 입 중심 간 근접 판정 거리(픽셀)\n",
    "\n",
    "# 상태 머신 임계치 비율 (캘리브레이션 결과에 곱해 사용)\n",
    "EYE_CLOSE_RATIO = 0.85    # 눈감김 임계치: EAR_low = median(EAR_calib)*EYE_CLOSE_RATIO\n",
    "EYE_OPEN_RATIO  = 1.05    # 눈뜸 임계치: EAR_high = median(EAR_calib)*EYE_OPEN_RATIO\n",
    "MOUTH_YAWN_RATIO = 1.25   # 하품 임계치: MAR_high = median(MAR_calib)*MOUTH_YAWN_RATIO\n",
    "\n",
    "# 졸림 지표 윈도우(초)\n",
    "PERCLOS_WIN_SEC = 10.0\n",
    "RATE_WIN_SEC = 20.0\n",
    "\n",
    "# 졸림 임계값(튜닝 가능)\n",
    "PERCLOS_T1, PERCLOS_T2, PERCLOS_T3 = 0.20, 0.40, 0.60\n",
    "YAWN_T1, YAWN_T2, YAWN_T3 = 2.0, 4.0, 6.0           # per minute\n",
    "BLINK_DUR_T1, BLINK_DUR_T2, BLINK_DUR_T3 = 0.25, 0.35, 0.50  # seconds\n",
    "LONG_EC_T1, LONG_EC_T2, LONG_EC_T3 = 0.5, 0.8, 1.0            # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e13200b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FaceMesh / Hands 초기화\n",
    "mp_face = mp.solutions.face_mesh\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "mp_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# FaceMesh 눈/입 계산용 랜드마크 인덱스 (MediaPipe FaceMesh)\n",
    "# EAR: (상하 거리 합) / (좌우 거리)  -- 관례적 정의\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]   # [left, top1, top2, right, bottom1, bottom2]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "# MAR: (상하 거리) / (좌우 거리)\n",
    "MOUTH_HORZ = (61, 291)    # 좌우 외측 입꼬리\n",
    "MOUTH_VERT = (13, 14)     # 상하(안쪽 입술 중앙)\n",
    "\n",
    "# 상태 관련 버퍼\n",
    "ear_buf = deque(maxlen=SMOOTH_WIN)\n",
    "mar_buf = deque(maxlen=SMOOTH_WIN)\n",
    "\n",
    "# 상태 머신 상수 (눈 + 하품)\n",
    "EYE_OPEN, EYE_CLOSE, EYE_OPENING, EYE_CLOSING, EYE_BLINK = range(5)\n",
    "YAWN_NONE, YAWN_WITH_HAND, YAWN_WITHOUT_HAND = 0, 1, 2\n",
    "\n",
    "eye_state = EYE_OPEN    # 초기 가정\n",
    "close_count = 0         # 연속 닫힘 프레임 수(블링크 판정용)\n",
    "yawn_state = YAWN_NONE\n",
    "yawn_count = 0\n",
    "\n",
    "# 캘리브레이션 샘플\n",
    "EAR_LOW, EAR_HIGH = 0.18, 0.26\n",
    "MAR_HIGH = 0.60\n",
    "ear_samples = []\n",
    "mar_samples = []\n",
    "\n",
    "# 졸림 지표 계산용 슬라이딩 버퍼 (초 단위 시간축)\n",
    "closed_flags = deque()   # (t, 0/1) — 눈감김 여부\n",
    "blink_events = deque()   # (t, duration_sec)\n",
    "yawn_events  = deque()   # (t,)\n",
    "active_close_start = None  # 현재 진행 중인 eye-closure 시작시간\n",
    "active_blink_start = None  # blink용(짧은 닫힘)\n",
    "\n",
    "# 졸음 단계 색상 팔레트\n",
    "LEVEL_COLOR = {\n",
    "    0: (0, 220, 0),     # alert - green\n",
    "    1: (0, 200, 255),   # mild - orange\n",
    "    2: (0, 128, 255),   # moderate - darker orange\n",
    "    3: (0, 0, 255)      # severe - red\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cdccdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각종 상태 및 라벨을 판별하는 함수들 + ROI\n",
    "def euclid(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "def eye_aspect_ratio(lm, eye_idx, w, h):\n",
    "    pts = [(lm[i].x*w, lm[i].y*h) for i in eye_idx]\n",
    "    p1, p2, p3, p4, p5, p6 = pts\n",
    "    vertical = (euclid(p2, p6)+euclid(p3, p5))/2.0\n",
    "    horizontal = euclid(p1, p4)+1e-6\n",
    "    return vertical / horizontal\n",
    "\n",
    "def mouth_aspect_ratio(lm, w, h):\n",
    "    L = (lm[MOUTH_HORZ[0]].x*w, lm[MOUTH_HORZ[0]].y*h)\n",
    "    R = (lm[MOUTH_HORZ[1]].x*w, lm[MOUTH_HORZ[1]].y*h)\n",
    "    U = (lm[MOUTH_VERT[0]].x*w, lm[MOUTH_VERT[0]].y*h)\n",
    "    D = (lm[MOUTH_VERT[1]].x*w, lm[MOUTH_VERT[1]].y*h)\n",
    "    horizontal = euclid(L, R) + 1e-6\n",
    "    vertical = euclid(U, D)\n",
    "    return vertical / horizontal, ((L[0]+R[0])/2, (U[1]+D[1])/2)\n",
    "\n",
    "def moving_avg(buf, k):\n",
    "    if len(buf)==0: return None\n",
    "    return float(np.mean(list(buf)[-k:]))\n",
    "\n",
    "def draw_roi(frame, pts, color=(0,255,0), thickness=2):\n",
    "    xs = [p[0] for p in pts]; ys = [p[1] for p in pts]\n",
    "    x1, y1, x2, y2 = int(min(xs)), int(min(ys)), int(max(xs)), int(max(ys))\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
    "    return (x1, y1, x2, y2)\n",
    "\n",
    "def is_hand_near_mouth(hand_lm_list, mouth_center, max_dist_px, w, h):\n",
    "    if hand_lm_list is None: return False\n",
    "    cx, cy = mouth_center\n",
    "    for hand in hand_lm_list:\n",
    "        for lm in hand.landmark:\n",
    "            px, py = lm.x*w, lm.y*h\n",
    "            if euclid((px, py), (cx, cy)) <= max_dist_px:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def drowsiness_level(perclos, yawn_rate, avg_blink_dur, longest_ec):\n",
    "    # 가장 심한 상태 조건을 우선 판단\n",
    "    # Severe 우선\n",
    "    if (perclos is not None and perclos > PERCLOS_T3) or \\\n",
    "       (yawn_rate is not None and yawn_rate > YAWN_T3) or \\\n",
    "       (longest_ec is not None and longest_ec >= LONG_EC_T3):\n",
    "        return 3, \"severe_drowsy\"\n",
    "    # Moderate\n",
    "    if (perclos is not None and perclos > PERCLOS_T2) or \\\n",
    "       (yawn_rate is not None and yawn_rate > YAWN_T2) or \\\n",
    "       (avg_blink_dur is not None and avg_blink_dur > BLINK_DUR_T2) or \\\n",
    "       (longest_ec is not None and longest_ec >= LONG_EC_T2):\n",
    "        return 2, \"moderate_drowsy\"\n",
    "    # Mild\n",
    "    if (perclos is not None and perclos > PERCLOS_T1) or \\\n",
    "       (yawn_rate is not None and yawn_rate > YAWN_T1) or \\\n",
    "       (avg_blink_dur is not None and avg_blink_dur > BLINK_DUR_T1) or \\\n",
    "       (longest_ec is not None and longest_ec >= LONG_EC_T1):\n",
    "        return 1, \"mild_drowsy\"\n",
    "    # Alert\n",
    "    return 0, \"alert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e041e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미리 저장된 영상을 사용\n",
    "video_path = target_files[0]\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 컴퓨터 연결 카메라 사용, 실시간 웹캠 등\n",
    "#cap = cv2.VideoCapture(CAM_INDEX)   \n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps <= 1e-2: fps = FPS_FALLBACK\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.get(cv2.CAP_PROP_FRAME_COUNT)>0 else None\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\"./output/labeled_output_with_drowsiness.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "logs = []\n",
    "\n",
    "# 캘리브 구간 프레임 수\n",
    "calib_frames = int(CALIB_SECONDS * fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c58c49",
   "metadata": {},
   "source": [
    "# 행동 라벨링 영상 추출 영역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f1674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.0774 sec\n"
     ]
    }
   ],
   "source": [
    "# MediaPipe 컨텍스트\n",
    "# EAR 및 MAR 영역 표시 + 행동상태 라벨링(졸림상태는 X) \n",
    "start = time.time()\n",
    "with mp_face.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    refine_landmarks=True,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ") as face_mesh, mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ") as hands:\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    # 1) 캘리브레이션\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: \n",
    "              # print(\"Webcam frame read failed.\")\n",
    "              break\n",
    "        frame_idx += 1\n",
    "        t_sec = frame_idx / fps\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_res = face_mesh.process(rgb)\n",
    "        hand_res = None \n",
    "\n",
    "        if face_res.multi_face_landmarks:\n",
    "            face_landmarks = face_res.multi_face_landmarks[0].landmark\n",
    "            ear_l = eye_aspect_ratio(face_landmarks, LEFT_EYE, width, height)\n",
    "            ear_r = eye_aspect_ratio(face_landmarks, RIGHT_EYE, width, height)\n",
    "            ear = (ear_l + ear_r) / 2.0\n",
    "            mar, mouth_center = mouth_aspect_ratio(face_landmarks, width, height)\n",
    "            ear_samples.append(ear)\n",
    "            mar_samples.append(mar)\n",
    "\n",
    "        if frame_idx >= calib_frames:\n",
    "            break\n",
    "    # 임계치 계산\n",
    "    if len(ear_samples) >= 5:\n",
    "        ear_med = float(np.median(ear_samples))\n",
    "        EAR_LOW  = ear_med * EYE_CLOSE_RATIO\n",
    "        EAR_HIGH = ear_med * EYE_OPEN_RATIO\n",
    "    else:\n",
    "        EAR_LOW, EAR_HIGH = 0.18, 0.26  # 안전 기본값 (얼굴 크기/거리 따라 다를 수 있음)\n",
    "\n",
    "    if len(mar_samples) >= 5:\n",
    "        mar_med = float(np.median(mar_samples))\n",
    "        MAR_HIGH = mar_med * MOUTH_YAWN_RATIO\n",
    "    else:\n",
    "        MAR_HIGH = 0.5  # 안전 기본값\n",
    "    \n",
    "\n",
    "    # 2) 본 처리 루프 (다시 처음부터)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        frame_idx += 1\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_res = face_mesh.process(rgb)\n",
    "        hands_res = hands.process(rgb)\n",
    "\n",
    "        label_id = 0\n",
    "        label_str = \"eyes_state/open\"\n",
    "\n",
    "        if face_res.multi_face_landmarks:\n",
    "            face_landmarks = face_res.multi_face_landmarks[0].landmark\n",
    "\n",
    "            # EAR/MAR\n",
    "            ear_l = eye_aspect_ratio(face_landmarks, LEFT_EYE, width, height)\n",
    "            ear_r = eye_aspect_ratio(face_landmarks, RIGHT_EYE, width, height)\n",
    "            ear = (ear_l + ear_r) / 2.0\n",
    "            mar, mouth_center = mouth_aspect_ratio(face_landmarks, width, height)\n",
    "\n",
    "            ear_buf.append(ear)\n",
    "            mar_buf.append(mar)\n",
    "            ear_s = moving_avg(ear_buf, SMOOTH_WIN)\n",
    "            mar_s = moving_avg(mar_buf, SMOOTH_WIN)\n",
    "\n",
    "            # 눈 상태 머신 업데이트\n",
    "            prev_state = eye_state\n",
    "            if ear_s is None:\n",
    "                eye_state = EYE_OPEN\n",
    "            else:\n",
    "                # opening/closing은 EAR 변화율로 판정(최근 3프레임)\n",
    "                if len(ear_buf) >= 3:\n",
    "                    ear_deriv = ear_buf[-1] - ear_buf[-3]\n",
    "                else:\n",
    "                    ear_deriv = 0.0\n",
    "\n",
    "                is_closed = ear_s < EAR_LOW\n",
    "                is_opened = ear_s > EAR_HIGH\n",
    "\n",
    "                if is_closed:\n",
    "                    eye_state = EYE_CLOSE if prev_state == EYE_CLOSE else (EYE_CLOSING if ear_deriv < 0 else EYE_CLOSE)\n",
    "                    close_count += 1\n",
    "                elif is_opened:\n",
    "                    eye_state = EYE_OPEN if prev_state == EYE_OPEN else (EYE_OPENING if ear_deriv > 0 else EYE_OPEN)\n",
    "                    if 0 < close_count <= BLINK_MAX_FRAMES:\n",
    "                        eye_state = EYE_BLINK\n",
    "                    close_count = 0\n",
    "                else:\n",
    "                    eye_state = EYE_OPENING if ear_deriv > 0 else (EYE_CLOSING if ear_deriv < 0 else prev_state)\n",
    "                    if prev_state in (EYE_CLOSE, EYE_CLOSING):\n",
    "                        close_count += 1\n",
    "                    else:\n",
    "                        close_count = 0\n",
    "\n",
    "            # 하품 상태 판별\n",
    "            hand_near = is_hand_near_mouth(\n",
    "                hands_res.multi_hand_landmarks if hands_res else None,\n",
    "                mouth_center, HAND_MOUTH_DIST_PX, width, height\n",
    "            )\n",
    "            if mar_s is not None and mar_s > MAR_HIGH:\n",
    "                yawn_count += 1\n",
    "                yawn_state = YAWN_WITH_HAND if hand_near else YAWN_WITHOUT_HAND\n",
    "            else:\n",
    "                yawn_state = YAWN_NONE\n",
    "                yawn_count = 0\n",
    "\n",
    "            # 최종 라벨 우선순위: 하품 > 눈 상태/눈 깜빡임\n",
    "            if yawn_state != YAWN_NONE and yawn_count >= YAWN_MIN_FRAMES:\n",
    "                if yawn_state == YAWN_WITH_HAND:\n",
    "                    label_id, label_str = 5, \"yawning/Yawning with hand\"\n",
    "                else:\n",
    "                    label_id, label_str = 6, \"yawning/Yawning without hand\"\n",
    "            else:\n",
    "                if eye_state == EYE_OPEN: label_id, label_str = 0, \"eyes_state/open\"\n",
    "                elif eye_state == EYE_CLOSE: label_id, label_str = 1, \"eyes_state/close\"\n",
    "                elif eye_state == EYE_OPENING: label_id, label_str = 2, \"eyes_state/opening\"\n",
    "                elif eye_state == EYE_CLOSING: label_id, label_str = 3, \"eyes_state/closing\"\n",
    "                elif eye_state == EYE_BLINK:   label_id, label_str = 4, \"blinks/blinking\"\n",
    "\n",
    "            # 얼굴 랜드마크 시각화 드로잉\n",
    "            mp_draw.draw_landmarks(\n",
    "                frame,\n",
    "                face_res.multi_face_landmarks[0],\n",
    "                mp_face.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_styles.get_default_face_mesh_tesselation_style()\n",
    "            )\n",
    "            # 눈/입 ROI 박스\n",
    "            def idx_to_pts(idxs):\n",
    "                return [(int(face_landmarks[i].x*width), int(face_landmarks[i].y*height)) for i in idxs]\n",
    "\n",
    "            left_eye_pts = idx_to_pts(LEFT_EYE)\n",
    "            right_eye_pts = idx_to_pts(RIGHT_EYE)\n",
    "            mouth_pts = idx_to_pts([MOUTH_HORZ[0], MOUTH_HORZ[1], MOUTH_VERT[0], MOUTH_VERT[1]])\n",
    "            draw_roi(frame, left_eye_pts, (0,255,0), 2)\n",
    "            draw_roi(frame, right_eye_pts, (0,255,0), 2)\n",
    "            draw_roi(frame, mouth_pts, (255,0,0), 2)\n",
    "\n",
    "            # 손 랜드마크\n",
    "            if hands_res and hands_res.multi_hand_landmarks:\n",
    "                for hlm in hands_res.multi_hand_landmarks:\n",
    "                    mp_draw.draw_landmarks(frame, hlm, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # 라벨/지표 텍스트\n",
    "            cv2.putText(frame, f\"Label {label_id}: {label_str}\", (20, 40),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 200, 255), 2)\n",
    "            if ear_s is not None:\n",
    "                cv2.putText(frame, f\"EAR:{ear_s:.3f}  (low:{EAR_LOW:.3f} high:{EAR_HIGH:.3f})\",\n",
    "                            (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            if mar_s is not None:\n",
    "                cv2.putText(frame, f\"MAR:{mar_s:.3f}  (yawn>{MAR_HIGH:.3f})\",\n",
    "                            (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 200, 0), 2)\n",
    "            if yawn_state != YAWN_NONE:\n",
    "                cv2.putText(frame, f\"HandNearMouth: {bool(hand_near)}  YawnFrames:{yawn_count}\",\n",
    "                            (20, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 180, 255), 2)\n",
    "        else:\n",
    "            # 얼굴 미검출 시 기본 라벨 유지(열림 가정)\n",
    "            label_id, label_str = 0, \"eyes_state/open\"\n",
    "            cv2.putText(frame, \"Face not detected\", (20, 40),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "        # 프레임 로그\n",
    "        logs.append({\n",
    "            \"frame\": frame_idx,\n",
    "            \"label_id\": label_id,\n",
    "            \"label_name\": label_str,\n",
    "            \"EAR\": float(ear_buf[-1]) if len(ear_buf)>0 else np.nan,\n",
    "            \"MAR\": float(mar_buf[-1]) if len(mar_buf)>0 else np.nan\n",
    "        })\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow(\"Realtime Labeling (Press 'q' to quit)\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "pd.DataFrame(logs).to_csv(\"./output/per_frame_labels.csv\", index=False)\n",
    "print(f\"Saved video to: {OUTPUT_VIDEO}\")\n",
    "print(f\"Saved per-frame CSV to: {OUTPUT_CSV}\")\n",
    "print(f\"{time.time()-start:.4f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f7b12",
   "metadata": {},
   "source": [
    "# 졸음 상태 라벨링 영상 추출 영역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea831e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video: labeled_output_with_drowsiness.mp4\n",
      "Saved CSV:   per_frame_with_drowsiness.csv\n"
     ]
    }
   ],
   "source": [
    "# EAR 및 MAR 영역 표시 안함 + 행동상태 라벨링 + 졸림 상태 라벨링(기준 지표 포함) \n",
    "start = time.time()\n",
    "with mp_face.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    refine_landmarks=True,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ") as face_mesh, mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ") as hands:\n",
    "\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        frame_idx += 1\n",
    "        t_sec = frame_idx / fps\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_res = face_mesh.process(rgb)\n",
    "        hands_res = None  # 조건부로 돌려도 됨(여기선 항상 실행)\n",
    "\n",
    "        label_id = 0\n",
    "        label_str = \"eyes_state/open\"\n",
    "\n",
    "        if face_res.multi_face_landmarks:\n",
    "            face_landmarks = face_res.multi_face_landmarks[0].landmark\n",
    "\n",
    "            # EAR/MAR\n",
    "            ear_l = eye_aspect_ratio(face_landmarks, LEFT_EYE, width, height)\n",
    "            ear_r = eye_aspect_ratio(face_landmarks, RIGHT_EYE, width, height)\n",
    "            ear = (ear_l + ear_r) / 2.0\n",
    "            mar, mouth_center = mouth_aspect_ratio(face_landmarks, width, height)\n",
    "\n",
    "            ear_buf.append(ear)\n",
    "            mar_buf.append(mar)\n",
    "            ear_s = moving_avg(ear_buf, SMOOTH_WIN)\n",
    "            mar_s = moving_avg(mar_buf, SMOOTH_WIN)\n",
    "\n",
    "            # 캘리브레이션 샘플 수집\n",
    "            if frame_idx <= int(CALIB_SECONDS * fps):\n",
    "                ear_samples.append(ear)\n",
    "                mar_samples.append(mar)\n",
    "                if frame_idx == int(CALIB_SECONDS * fps):\n",
    "                    if len(ear_samples) >= 5:\n",
    "                        ear_med = float(np.median(ear_samples))\n",
    "                        EAR_LOW  = ear_med * EYE_CLOSE_RATIO\n",
    "                        EAR_HIGH = ear_med * EYE_OPEN_RATIO\n",
    "                    if len(mar_samples) >= 5:\n",
    "                        mar_med = float(np.median(mar_samples))\n",
    "                        MAR_HIGH = mar_med * MOUTH_YAWN_RATIO\n",
    "\n",
    "            # 손-입 근접\n",
    "            hands_res = hands.process(rgb)\n",
    "            hand_near = is_hand_near_mouth(\n",
    "                hands_res.multi_hand_landmarks if hands_res else None,\n",
    "                mouth_center, HAND_MOUTH_DIST_PX, width, height\n",
    "            )\n",
    "\n",
    "            # 눈 상태 머신\n",
    "            prev_state = eye_state\n",
    "            if ear_s is None:\n",
    "                eye_state = EYE_OPEN\n",
    "            else:\n",
    "                if len(ear_buf) >= 3:\n",
    "                    ear_deriv = ear_buf[-1] - ear_buf[-3]\n",
    "                else:\n",
    "                    ear_deriv = 0.0\n",
    "\n",
    "                is_closed = ear_s < EAR_LOW\n",
    "                is_opened = ear_s > EAR_HIGH\n",
    "\n",
    "                if is_closed:\n",
    "                    eye_state = EYE_CLOSE if prev_state == EYE_CLOSE else (EYE_CLOSING if ear_deriv < 0 else EYE_CLOSE)\n",
    "                    close_count += 1\n",
    "                elif is_opened:\n",
    "                    eye_state = EYE_OPEN if prev_state == EYE_OPEN else (EYE_OPENING if ear_deriv > 0 else EYE_OPEN)\n",
    "                    # blink 판정\n",
    "                    if 0 < close_count <= BLINK_MAX_FRAMES:\n",
    "                        eye_state = EYE_BLINK\n",
    "                    close_count = 0\n",
    "                else:\n",
    "                    eye_state = EYE_OPENING if ear_deriv > 0 else (EYE_CLOSING if ear_deriv < 0 else prev_state)\n",
    "                    if prev_state in (EYE_CLOSE, EYE_CLOSING):\n",
    "                        close_count += 1\n",
    "                    else:\n",
    "                        close_count = 0\n",
    "\n",
    "            # 하품 상태\n",
    "            if mar_s is not None and mar_s > MAR_HIGH:\n",
    "                yawn_count += 1\n",
    "                yawn_state = YAWN_WITH_HAND if hand_near else YAWN_WITHOUT_HAND\n",
    "            else:\n",
    "                yawn_state = YAWN_NONE\n",
    "                yawn_count = 0\n",
    "\n",
    "            # 최종 행동 라벨\n",
    "            if yawn_state != YAWN_NONE and yawn_count >= YAWN_MIN_FRAMES:\n",
    "                if yawn_state == YAWN_WITH_HAND:\n",
    "                    label_id, label_str = 5, \"yawning/Yawning with hand\"\n",
    "                else:\n",
    "                    label_id, label_str = 6, \"yawning/Yawning without hand\"\n",
    "            else:\n",
    "                if   eye_state == EYE_OPEN:    label_id, label_str = 0, \"eyes_state/open\"\n",
    "                elif eye_state == EYE_CLOSE:   label_id, label_str = 1, \"eyes_state/close\"\n",
    "                elif eye_state == EYE_OPENING: label_id, label_str = 2, \"eyes_state/opening\"\n",
    "                elif eye_state == EYE_CLOSING: label_id, label_str = 3, \"eyes_state/closing\"\n",
    "                elif eye_state == EYE_BLINK:   label_id, label_str = 4, \"blinks/blinking\"\n",
    "\n",
    "            # ====== 졸림 지표 업데이트 ======\n",
    "            # A) PERCLOS: 최근 PERCLOS_WIN_SEC 동안 '눈감김' 비율\n",
    "            closed_flag = 1 if ear_s is not None and ear_s < EAR_LOW else 0\n",
    "            closed_flags.append((t_sec, closed_flag))\n",
    "            while closed_flags and (t_sec - closed_flags[0][0] > PERCLOS_WIN_SEC):\n",
    "                closed_flags.popleft()\n",
    "            if closed_flags:\n",
    "                perclos = sum(f for _, f in closed_flags) / float(len(closed_flags))\n",
    "            else:\n",
    "                perclos = None\n",
    "\n",
    "            # B) blink 이벤트 기록(짧은 닫힘)\n",
    "            # blink가 찍히는 순간(eye_state == EYE_BLINK)에서 duration 계산\n",
    "            # 간단히: 방금 전까지의 close_count를 duration으로 사용\n",
    "            if eye_state == EYE_BLINK:\n",
    "                blink_dur = close_count / fps  # 방금 열림과 함께 close_count가 0으로 초기화되기 전에 계산됨\n",
    "                blink_events.append((t_sec, blink_dur))\n",
    "            # 창구 유지\n",
    "            while blink_events and (t_sec - blink_events[0][0] > RATE_WIN_SEC):\n",
    "                blink_events.popleft()\n",
    "\n",
    "            if blink_events:\n",
    "                blink_rate = len(blink_events) * (60.0 / RATE_WIN_SEC)  # per 20s\n",
    "                avg_blink_dur = float(np.mean([d for _, d in blink_events]))\n",
    "            else:\n",
    "                blink_rate = 0.0\n",
    "                avg_blink_dur = None\n",
    "\n",
    "            # C) 긴 eye-closure 감지(연속 close가 길면 이벤트로 기록)\n",
    "            # close 연속 구간의 시작/끝 추적\n",
    "            if closed_flag == 1 and active_close_start is None:\n",
    "                active_close_start = t_sec\n",
    "            if closed_flag == 0 and active_close_start is not None:\n",
    "                dur = t_sec - active_close_start\n",
    "                blink_events.append((t_sec, dur))  # 긴 eye closure도 blink_events에 포함시켜 평균/최대에 반영\n",
    "                active_close_start = None\n",
    "            # longest eye closure (최근 RATE_WIN_SEC)\n",
    "            if blink_events:\n",
    "                longest_ec = max(d for _, d in blink_events)\n",
    "            else:\n",
    "                longest_ec = None\n",
    "\n",
    "            # D) yawn 이벤트(프레임 지속 충족 시 시점 기록)\n",
    "            if yawn_state != YAWN_NONE and yawn_count == YAWN_MIN_FRAMES:\n",
    "                yawn_events.append((t_sec,))\n",
    "            while yawn_events and (t_sec - yawn_events[0][0] > RATE_WIN_SEC):\n",
    "                yawn_events.popleft()\n",
    "            yawn_rate = len(yawn_events) * (60.0 / RATE_WIN_SEC) if yawn_events else 0.0\n",
    "\n",
    "            # ====== 졸림 단계 산출 ======\n",
    "            d_level, d_label = drowsiness_level(perclos, yawn_rate, avg_blink_dur, longest_ec)\n",
    "\n",
    "            # ====== 시각화 ======\n",
    "            cv2.putText(frame, f\"Label {label_id}: {label_str}\", (20, 40),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 200, 255), 2)\n",
    "            if ear_s is not None:\n",
    "                cv2.putText(frame, f\"EAR:{ear_s:.3f} (L:{EAR_LOW:.3f} H:{EAR_HIGH:.3f})\",\n",
    "                            (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "            if mar_s is not None:\n",
    "                cv2.putText(frame, f\"MAR:{mar_s:.3f} (Y>{MAR_HIGH:.3f})\",\n",
    "                            (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,200,0), 2)\n",
    "\n",
    "            # 졸림 지표/단계 표시\n",
    "            c = LEVEL_COLOR[d_level]\n",
    "            cv2.putText(frame, f\"Drowsiness {d_level}: {d_label}\", (20, 135),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, c, 2)\n",
    "            cv2.putText(frame, f\"PERCLOS:{(perclos if perclos is not None else np.nan):.2f}  \"\n",
    "                                f\"Yawn/min:{yawn_rate:.1f}  \"\n",
    "                                f\"Blink/min:{blink_rate:.1f}  \"\n",
    "                                f\"AvgBlinkDur:{(avg_blink_dur if avg_blink_dur else np.nan):.2f}s  \"\n",
    "                                f\"LongestEC:{(longest_ec if longest_ec else np.nan):.2f}s\",\n",
    "                        (20, 165), cv2.FONT_HERSHEY_SIMPLEX, 0.55, c, 2)\n",
    "\n",
    "        else:\n",
    "            # 얼굴 미검출 시\n",
    "            label_id, label_str = 0, \"eyes_state/open\"\n",
    "            d_level, d_label = 0, \"alert\"\n",
    "            perclos = None; yawn_rate = 0.0; blink_rate = 0.0; avg_blink_dur = None; longest_ec = None\n",
    "            cv2.putText(frame, \"Face not detected\", (20, 40),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "        # ====== 로그 저장 ======\n",
    "        logs.append({\n",
    "            \"frame\": frame_idx,\n",
    "            \"time_sec\": t_sec,\n",
    "            \"label_id\": label_id,\n",
    "            \"label_name\": label_str,\n",
    "            \"EAR\": float(ear_buf[-1]) if len(ear_buf)>0 else np.nan,\n",
    "            \"MAR\": float(mar_buf[-1]) if len(mar_buf)>0 else np.nan,\n",
    "            \"yawn_rate_per_min\": float(yawn_rate),\n",
    "            \"blink_rate_per_min\": float(blink_rate) if face_res.multi_face_landmarks else 0.0,\n",
    "            \"avg_blink_dur_sec\": float(avg_blink_dur) if avg_blink_dur is not None else np.nan,\n",
    "            \"longest_eye_closure_sec\": float(longest_ec) if longest_ec is not None else np.nan,\n",
    "            \"drowsiness_level\": d_level,\n",
    "            \"drowsiness_label\": d_label\n",
    "        })\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "pd.DataFrame(logs).to_csv(\"./output/\"+OUTPUT_CSV, index=False)\n",
    "print(f\"Saved video: {OUTPUT_VIDEO}\")\n",
    "print(f\"Saved CSV:   {OUTPUT_CSV}\")\n",
    "print(f\"{time.time()-start:.4f} sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
