{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a301f8c",
   "metadata": {},
   "source": [
    "해당 코드들은 자동화 최적화가 되어 있지 않음\n",
    "\n",
    "아직은 1개씩만 돌려보고 결과를 확인하기 위한 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d983b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ae07a",
   "metadata": {},
   "source": [
    "### YawDD 데이타셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../../20.분석/21.데이타셋/DMD dataset/gA/3/s5/gA_3_s5_2019-03-13T09;36;25+01;00_depth_hands.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/3/s5/gA_3_s5_2019-03-13T09;36;25+01;00_depth_face.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/3/s5/gA_3_s5_2019-03-13T09;36;25+01;00_depth_body.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/3/s5/gA_3_s5_2019-03-13T09;36;25+01;00_rgb_mosaic.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/1/s5/gA_1_s5_2019-03-14T14;26;17+01;00_depth_body.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/1/s5/gA_1_s5_2019-03-14T14;26;17+01;00_depth_hands.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/1/s5/gA_1_s5_2019-03-14T14;26;17+01;00_rgb_mosaic.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/1/s5/gA_1_s5_2019-03-14T14;26;17+01;00_depth_face.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/5/s5/gA_5_s5_2019-03-13T09;06;49+01;00_depth_hands.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/5/s5/gA_5_s5_2019-03-13T09;06;49+01;00_depth_face.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/5/s5/gA_5_s5_2019-03-13T09;06;49+01;00_rgb_mosaic.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/5/s5/gA_5_s5_2019-03-13T09;06;49+01;00_depth_body.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/2/s5/gA_2_s5_2019-03-13T09;19;23+01;00_rgb_mosaic.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/2/s5/gA_2_s5_2019-03-13T09;19;23+01;00_depth_body.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/2/s5/gA_2_s5_2019-03-13T09;19;23+01;00_depth_face.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/2/s5/gA_2_s5_2019-03-13T09;19;23+01;00_depth_hands.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/4/s5/gA_4_s5_2019-03-13T10;56;52+01;00_depth_face.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/4/s5/gA_4_s5_2019-03-13T10;56;52+01;00_rgb_mosaic.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/4/s5/gA_4_s5_2019-03-13T10;56;52+01;00_depth_hands.avi', '../../../20.분석/21.데이타셋/DMD dataset/gA/4/s5/gA_4_s5_2019-03-13T10;56;52+01;00_depth_body.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/9/s5/gB_9_s5_2019-03-07T16;31;48+01;00_depth_hands.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/9/s5/gB_9_s5_2019-03-07T16;31;48+01;00_depth_face.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/9/s5/gB_9_s5_2019-03-07T16;31;48+01;00_rgb_mosaic.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/9/s5/gB_9_s5_2019-03-07T16;31;48+01;00_depth_body.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/8/s5/gB_8_s5_2019-03-13T14;10;09+01;00_depth_body.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/8/s5/gB_8_s5_2019-03-13T14;10;09+01;00_depth_hands.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/8/s5/gB_8_s5_2019-03-13T14;10;09+01;00_depth_face.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/8/s5/gB_8_s5_2019-03-13T14;10;09+01;00_rgb_mosaic.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/7/s5/gB_7_s5_2019-03-13T13;55;52+01;00_depth_hands.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/7/s5/gB_7_s5_2019-03-13T13;55;52+01;00_depth_body.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/7/s5/gB_7_s5_2019-03-13T13;55;52+01;00_rgb_mosaic.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/7/s5/gB_7_s5_2019-03-13T13;55;52+01;00_depth_face.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/6/s5/gB_6_s5_2019-03-13T13;37;11+01;00_depth_face.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/6/s5/gB_6_s5_2019-03-13T13;37;11+01;00_rgb_mosaic.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/6/s5/gB_6_s5_2019-03-13T13;37;11+01;00_depth_hands.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/6/s5/gB_6_s5_2019-03-13T13;37;11+01;00_depth_body.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/10/s5/gB_10_s5_2019-03-12T10;35;20+01;00_rgb_mosaic.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/10/s5/gB_10_s5_2019-03-12T10;35;20+01;00_depth_hands.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/10/s5/gB_10_s5_2019-03-12T10;35;20+01;00_depth_body.avi', '../../../20.분석/21.데이타셋/DMD dataset/gB/10/s5/gB_10_s5_2019-03-12T10;35;20+01;00_depth_face.avi', '../../../20.분석/21.데이타셋/DMD dataset/gC/13/s5/gC_13_s5_2019-03-12T10;03;00+01;00_depth_hands.avi']\n",
      "['../../../20.분석/21.데이타셋/DMD dataset/gA/3/s5/gA_3_s5_2019-03-13T09;36;25+01;00_rgb_ann_drowsiness.json', '../../../20.분석/21.데이타셋/DMD dataset/gA/1/s5/gA_1_s5_2019-03-14T14;26;17+01;00_rgb_ann_drowsiness.json', '../../../20.분석/21.데이타셋/DMD dataset/gA/5/s5/gA_5_s5_2019-03-13T09;06;49+01;00_rgb_ann_drowsiness.json', '../../../20.분석/21.데이타셋/DMD dataset/gA/2/s5/gA_2_s5_2019-03-13T09;19;23+01;00_rgb_ann_drowsiness.json', '../../../20.분석/21.데이타셋/DMD dataset/gA/4/s5/gA_4_s5_2019-03-13T10;56;52+01;00_rgb_ann_drowsiness.json', '../../../20.분석/21.데이타셋/DMD dataset/gB/9/s5/gB_9_s5_2019-03-07T16;31;48+01;00_rgb_ann_drowsiness.json', '../../../20.분석/21.데이타셋/DMD dataset/gB/8/s5/gB_8_s5_2019-03-13T14;10;09+01;00_rgb_ann_drowsiness.json', '../../../20.분석/21.데이타셋/DMD dataset/gB/7/s5/gB_7_s5_2019-03-13T13;55;52+01;00_rgb_ann_drowsiness.json', '../../../20.분석/21.데이타셋/DMD dataset/gB/6/s5/gB_6_s5_2019-03-13T13;37;11+01;00_rgb_ann_drowsiness.json', '../../../20.분석/21.데이타셋/DMD dataset/gB/10/s5/gB_10_s5_2019-03-12T10;35;20+01;00_rgb_ann_drowsiness.json', '../../../20.분석/21.데이타셋/DMD dataset/gC/13/s5/gC_13_s5_2019-03-12T10;03;00+01;00_rgb_ann_drowsiness.json']\n"
     ]
    }
   ],
   "source": [
    "target_files = []\n",
    "json_paths = []\n",
    "target_path = \"../../../20.분석/21.데이타셋/YawDD dataset/Mirror/Male_mirror Avi Videos\"\n",
    "\n",
    "for root, dirs, files in os.walk(target_path):\n",
    "    for fname in files:\n",
    "        # .avi 확장자이면서 SunGlass, Talking 이 없는 파일만 선택\n",
    "        if fname.endswith(\".avi\") and \"SunGlass\" not in fname and \"Talking\" not in fname:\n",
    "            target_files.append(os.path.join(root, fname))\n",
    "\n",
    "        # JSON 경로는 기존 로직 유지\n",
    "        if fname.endswith(\"drowsiness.json\"):\n",
    "            json_paths.append(os.path.join(root, fname))\n",
    "\n",
    "print(target_files)\n",
    "print(json_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7185f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304910d7",
   "metadata": {},
   "source": [
    "# 1. Mediapipe 영상 labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4618f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUT_VIDEO = \"labeled_output_with_drowsiness.mp4\"              # 출력 비디오 파일명\n",
    "#OUTPUT_CSV = \"per_frame_with_drowsiness.csv\"              # 출력 CSV 파일명\n",
    "\n",
    "CALIB_SECONDS = 2.0       # 초기 캘리브레이션 구간(초)\n",
    "FPS_FALLBACK = 30.0       # FPS 정보가 없을 때 기본값\n",
    "SMOOTH_WIN = 5            # EAR/MAR 이동평균 윈도우\n",
    "BLINK_MAX_FRAMES = 8      # blink로 볼 수 있는 최대 닫힘 프레임 길이\n",
    "YAWN_MIN_FRAMES = 30      # 하품으로 간주할 최소 프레임 길이\n",
    "HAND_MOUTH_DIST_PX = 80   # 손가락 포인트와 입 중심 간 근접 판정 거리(픽셀)\n",
    "\n",
    "# 상태 머신 임계치 비율 (캘리브레이션 결과에 곱해 사용)\n",
    "EYE_CLOSE_RATIO = 0.85    # 눈감김 임계치: EAR_low = median(EAR_calib)*EYE_CLOSE_RATIO\n",
    "EYE_OPEN_RATIO  = 1.05    # 눈뜸 임계치: EAR_high = median(EAR_calib)*EYE_OPEN_RATIO\n",
    "MOUTH_YAWN_RATIO = 1.25   # 하품 임계치: MAR_high = median(MAR_calib)*MOUTH_YAWN_RATIO\n",
    "\n",
    "# 졸림 지표 윈도우(초)\n",
    "PERCLOS_WIN_SEC = 10.0\n",
    "RATE_WIN_SEC = 20.0\n",
    "\n",
    "# 졸림 임계값(튜닝 가능)\n",
    "PERCLOS_T1, PERCLOS_T2, PERCLOS_T3 = 0.20, 0.40, 0.60\n",
    "YAWN_T1, YAWN_T2, YAWN_T3 = 2.0, 4.0, 6.0           # per minute\n",
    "BLINK_DUR_T1, BLINK_DUR_T2, BLINK_DUR_T3 = 0.25, 0.35, 0.50  # seconds\n",
    "LONG_EC_T1, LONG_EC_T2, LONG_EC_T3 = 0.5, 0.8, 1.0            # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e13200b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FaceMesh / Hands 초기화\n",
    "mp_face = mp.solutions.face_mesh\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "mp_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# FaceMesh 눈/입 계산용 랜드마크 인덱스 (MediaPipe FaceMesh)\n",
    "# EAR: (상하 거리 합) / (좌우 거리)  -- 관례적 정의\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]   # [left, top1, top2, right, bottom1, bottom2]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "# MAR: (상하 거리) / (좌우 거리)\n",
    "MOUTH_HORZ = (61, 291)    # 좌우 외측 입꼬리\n",
    "MOUTH_VERT = (13, 14)     # 상하(안쪽 입술 중앙)\n",
    "\n",
    "# 상태 관련 버퍼\n",
    "ear_buf = deque(maxlen=SMOOTH_WIN)\n",
    "mar_buf = deque(maxlen=SMOOTH_WIN)\n",
    "\n",
    "# 상태 머신 상수 (눈 + 하품)\n",
    "EYE_OPEN, EYE_CLOSE, EYE_OPENING, EYE_CLOSING, EYE_BLINK = range(5)\n",
    "YAWN_NONE, YAWN_WITH_HAND, YAWN_WITHOUT_HAND = 0, 1, 2\n",
    "\n",
    "eye_state = EYE_OPEN    # 초기 가정\n",
    "close_count = 0         # 연속 닫힘 프레임 수(블링크 판정용)\n",
    "yawn_state = YAWN_NONE\n",
    "yawn_count = 0\n",
    "\n",
    "# 캘리브레이션 샘플\n",
    "EAR_LOW, EAR_HIGH = 0.18, 0.26\n",
    "MAR_HIGH = 0.60\n",
    "ear_samples = []\n",
    "mar_samples = []\n",
    "\n",
    "# 졸림 지표 계산용 슬라이딩 버퍼 (초 단위 시간축)\n",
    "closed_flags = deque()   # (t, 0/1) — 눈감김 여부\n",
    "blink_events = deque()   # (t, duration_sec)\n",
    "yawn_events  = deque()   # (t,)\n",
    "active_close_start = None  # 현재 진행 중인 eye-closure 시작시간\n",
    "active_blink_start = None  # blink용(짧은 닫힘)\n",
    "\n",
    "# 졸음 단계 색상 팔레트\n",
    "LEVEL_COLOR = {\n",
    "    0: (0, 220, 0),     # alert - green\n",
    "    1: (0, 200, 255),   # mild - orange\n",
    "    2: (0, 128, 255),   # moderate - darker orange\n",
    "    3: (0, 0, 255)      # severe - red\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cdccdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각종 상태 및 라벨을 판별하는 함수들 + ROI\n",
    "def euclid(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "def eye_aspect_ratio(lm, eye_idx, w, h):\n",
    "    pts = [(lm[i].x*w, lm[i].y*h) for i in eye_idx]\n",
    "    p1, p2, p3, p4, p5, p6 = pts\n",
    "    vertical = (euclid(p2, p6)+euclid(p3, p5))/2.0\n",
    "    horizontal = euclid(p1, p4)+1e-6\n",
    "    return vertical / horizontal\n",
    "\n",
    "def mouth_aspect_ratio(lm, w, h):\n",
    "    L = (lm[MOUTH_HORZ[0]].x*w, lm[MOUTH_HORZ[0]].y*h)\n",
    "    R = (lm[MOUTH_HORZ[1]].x*w, lm[MOUTH_HORZ[1]].y*h)\n",
    "    U = (lm[MOUTH_VERT[0]].x*w, lm[MOUTH_VERT[0]].y*h)\n",
    "    D = (lm[MOUTH_VERT[1]].x*w, lm[MOUTH_VERT[1]].y*h)\n",
    "    horizontal = euclid(L, R) + 1e-6\n",
    "    vertical = euclid(U, D)\n",
    "    return vertical / horizontal, ((L[0]+R[0])/2, (U[1]+D[1])/2)\n",
    "\n",
    "def moving_avg(buf, k):\n",
    "    if len(buf)==0: return None\n",
    "    return float(np.mean(list(buf)[-k:]))\n",
    "\n",
    "def draw_roi(frame, pts, color=(0,255,0), thickness=2):\n",
    "    xs = [p[0] for p in pts]; ys = [p[1] for p in pts]\n",
    "    x1, y1, x2, y2 = int(min(xs)), int(min(ys)), int(max(xs)), int(max(ys))\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
    "    return (x1, y1, x2, y2)\n",
    "\n",
    "def is_hand_near_mouth(hand_lm_list, mouth_center, max_dist_px, w, h):\n",
    "    if hand_lm_list is None: return False\n",
    "    cx, cy = mouth_center\n",
    "    for hand in hand_lm_list:\n",
    "        for lm in hand.landmark:\n",
    "            px, py = lm.x*w, lm.y*h\n",
    "            if euclid((px, py), (cx, cy)) <= max_dist_px:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def drowsiness_level(perclos, yawn_rate, avg_blink_dur, longest_ec):\n",
    "    # 가장 심한 상태 조건을 우선 판단\n",
    "    # Severe 우선\n",
    "    if (perclos is not None and perclos > PERCLOS_T3) or \\\n",
    "       (yawn_rate is not None and yawn_rate > YAWN_T3) or \\\n",
    "       (longest_ec is not None and longest_ec >= LONG_EC_T3):\n",
    "        return 3, \"severe_drowsy\"\n",
    "    # Moderate\n",
    "    if (perclos is not None and perclos > PERCLOS_T2) or \\\n",
    "       (yawn_rate is not None and yawn_rate > YAWN_T2) or \\\n",
    "       (avg_blink_dur is not None and avg_blink_dur > BLINK_DUR_T2) or \\\n",
    "       (longest_ec is not None and longest_ec >= LONG_EC_T2):\n",
    "        return 2, \"moderate_drowsy\"\n",
    "    # Mild\n",
    "    if (perclos is not None and perclos > PERCLOS_T1) or \\\n",
    "       (yawn_rate is not None and yawn_rate > YAWN_T1) or \\\n",
    "       (avg_blink_dur is not None and avg_blink_dur > BLINK_DUR_T1) or \\\n",
    "       (longest_ec is not None and longest_ec >= LONG_EC_T1):\n",
    "        return 1, \"mild_drowsy\"\n",
    "    # Alert\n",
    "    return 0, \"alert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a68afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47-MaleNoGlasses-Yawning-label.mp4\n",
      "47-MaleNoGlasses-Yawning-label.csv\n"
     ]
    }
   ],
   "source": [
    "# 미리 저장된 영상을 사용\n",
    "video_path = target_files[2]\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "OUTPUT_VIDEO = os.path.basename(video_path)              # 출력 비디오 파일명\n",
    "OUTPUT_VIDEO =  os.path.splitext(OUTPUT_VIDEO)[0] + \"-label.mp4\"              # 출력 비디오 파일명\n",
    "OUTPUT_CSV = os.path.splitext(OUTPUT_VIDEO)[0]  + \".csv\"            # 출력 CSV 파일명\n",
    "\n",
    "print(OUTPUT_VIDEO)\n",
    "print(OUTPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "375f301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_files(video_path):\n",
    "    \"\"\"\n",
    "    주어진 비디오 경로에서 출력 비디오 및 CSV 파일명을 생성합니다.\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(video_path)\n",
    "    output_video = os.path.splitext(base_name)[0] + \"-label.mp4\"\n",
    "    output_csv = os.path.splitext(output_video)[0] + \".csv\"\n",
    "    return output_video, output_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bebd9d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../20.분석/21.데이타셋/YawDD dataset/Mirror/Male_mirror Avi Videos/._11-MaleGlasses-Normal.avi\n"
     ]
    }
   ],
   "source": [
    "print(target_files[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c66d1b",
   "metadata": {},
   "source": [
    "# 행동 라벨링 영상 추출 영역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_video(video_path):\n",
    "\n",
    "    # FaceMesh / Hands 초기화\n",
    "    mp_face = mp.solutions.face_mesh\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_draw = mp.solutions.drawing_utils\n",
    "    mp_styles = mp.solutions.drawing_styles\n",
    "\n",
    "    # FaceMesh 눈/입 계산용 랜드마크 인덱스 (MediaPipe FaceMesh)\n",
    "    # EAR: (상하 거리 합) / (좌우 거리)  -- 관례적 정의\n",
    "    LEFT_EYE = [33, 160, 158, 133, 153, 144]   # [left, top1, top2, right, bottom1, bottom2]\n",
    "    RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "    # MAR: (상하 거리) / (좌우 거리)\n",
    "    MOUTH_HORZ = (61, 291)    # 좌우 외측 입꼬리\n",
    "    MOUTH_VERT = (13, 14)     # 상하(안쪽 입술 중앙)\n",
    "\n",
    "    # 상태 관련 버퍼\n",
    "    ear_buf = deque(maxlen=SMOOTH_WIN)\n",
    "    mar_buf = deque(maxlen=SMOOTH_WIN)\n",
    "\n",
    "    # 상태 머신 상수 (눈 + 하품)\n",
    "    EYE_OPEN, EYE_CLOSE, EYE_OPENING, EYE_CLOSING, EYE_BLINK = range(5)\n",
    "    YAWN_NONE, YAWN_WITH_HAND, YAWN_WITHOUT_HAND = 0, 1, 2\n",
    "\n",
    "    eye_state = EYE_OPEN    # 초기 가정\n",
    "    close_count = 0         # 연속 닫힘 프레임 수(블링크 판정용)\n",
    "    yawn_state = YAWN_NONE\n",
    "    yawn_count = 0\n",
    "\n",
    "    # 캘리브레이션 샘플\n",
    "    EAR_LOW, EAR_HIGH = 0.18, 0.26\n",
    "    MAR_HIGH = 0.60\n",
    "    ear_samples = []\n",
    "    mar_samples = []\n",
    "\n",
    "    # 졸림 지표 계산용 슬라이딩 버퍼 (초 단위 시간축)\n",
    "    closed_flags = deque()   # (t, 0/1) — 눈감김 여부\n",
    "    blink_events = deque()   # (t, duration_sec)\n",
    "    yawn_events  = deque()   # (t,)\n",
    "    active_close_start = None  # 현재 진행 중인 eye-closure 시작시간\n",
    "    active_blink_start = None  # blink용(짧은 닫힘)\n",
    "\n",
    "    # 졸음 단계 색상 팔레트\n",
    "    LEVEL_COLOR = {\n",
    "        0: (0, 220, 0),     # alert - green\n",
    "        1: (0, 200, 255),   # mild - orange\n",
    "        2: (0, 128, 255),   # moderate - darker orange\n",
    "        3: (0, 0, 255)      # severe - red\n",
    "    }\n",
    "\n",
    "    # 미리 저장된 영상을 사용\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    output_video, output_csv = get_output_files(video_path)\n",
    "\n",
    "    # 컴퓨터 연결 카메라 사용, 실시간 웹캠 등\n",
    "    #cap = cv2.VideoCapture(CAM_INDEX)   \n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps <= 1e-2: fps = FPS_FALLBACK\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.get(cv2.CAP_PROP_FRAME_COUNT)>0 else None\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    outfilePath = \"./output/\" + output_video\n",
    "    out = cv2.VideoWriter(outfilePath, fourcc, fps, (width, height))\n",
    "\n",
    "    logs = []\n",
    "\n",
    "    # 캘리브 구간 프레임 수\n",
    "    calib_frames = int(CALIB_SECONDS * fps)\n",
    "\n",
    "    # EAR 및 MAR 영역 표시 안함 + 행동상태 라벨링 + 졸림 상태 라벨링(기준 지표 포함) \n",
    "    start = time.time()\n",
    "    with mp_face.FaceMesh(\n",
    "        static_image_mode=False,\n",
    "        refine_landmarks=True,\n",
    "        max_num_faces=1,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    ) as face_mesh, mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    ) as hands:\n",
    "\n",
    "        frame_idx = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            frame_idx += 1\n",
    "            t_sec = frame_idx / fps\n",
    "\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            face_res = face_mesh.process(rgb)\n",
    "            hands_res = None  # 조건부로 돌려도 됨(여기선 항상 실행)\n",
    "\n",
    "            label_id = 0\n",
    "            label_str = \"eyes_state/open\"\n",
    "\n",
    "            if face_res.multi_face_landmarks:\n",
    "                face_landmarks = face_res.multi_face_landmarks[0].landmark\n",
    "\n",
    "                # EAR/MAR\n",
    "                ear_l = eye_aspect_ratio(face_landmarks, LEFT_EYE, width, height)\n",
    "                ear_r = eye_aspect_ratio(face_landmarks, RIGHT_EYE, width, height)\n",
    "                ear = (ear_l + ear_r) / 2.0\n",
    "                mar, mouth_center = mouth_aspect_ratio(face_landmarks, width, height)\n",
    "\n",
    "                ear_buf.append(ear)\n",
    "                mar_buf.append(mar)\n",
    "                ear_s = moving_avg(ear_buf, SMOOTH_WIN)\n",
    "                mar_s = moving_avg(mar_buf, SMOOTH_WIN)\n",
    "\n",
    "                # 캘리브레이션 샘플 수집\n",
    "                if frame_idx <= int(CALIB_SECONDS * fps):\n",
    "                    ear_samples.append(ear)\n",
    "                    mar_samples.append(mar)\n",
    "                    if frame_idx == int(CALIB_SECONDS * fps):\n",
    "                        if len(ear_samples) >= 5:\n",
    "                            ear_med = float(np.median(ear_samples))\n",
    "                            EAR_LOW  = ear_med * EYE_CLOSE_RATIO\n",
    "                            EAR_HIGH = ear_med * EYE_OPEN_RATIO\n",
    "                        if len(mar_samples) >= 5:\n",
    "                            mar_med = float(np.median(mar_samples))\n",
    "                            MAR_HIGH = mar_med * MOUTH_YAWN_RATIO\n",
    "\n",
    "                # 손-입 근접\n",
    "                hands_res = hands.process(rgb)\n",
    "                hand_near = is_hand_near_mouth(\n",
    "                    hands_res.multi_hand_landmarks if hands_res else None,\n",
    "                    mouth_center, HAND_MOUTH_DIST_PX, width, height\n",
    "                )\n",
    "\n",
    "                # 눈 상태 머신\n",
    "                prev_state = eye_state\n",
    "                if ear_s is None:\n",
    "                    eye_state = EYE_OPEN\n",
    "                else:\n",
    "                    if len(ear_buf) >= 3:\n",
    "                        ear_deriv = ear_buf[-1] - ear_buf[-3]\n",
    "                    else:\n",
    "                        ear_deriv = 0.0\n",
    "\n",
    "                    is_closed = ear_s < EAR_LOW\n",
    "                    is_opened = ear_s > EAR_HIGH\n",
    "\n",
    "                    if is_closed:\n",
    "                        eye_state = EYE_CLOSE if prev_state == EYE_CLOSE else (EYE_CLOSING if ear_deriv < 0 else EYE_CLOSE)\n",
    "                        close_count += 1\n",
    "                    elif is_opened:\n",
    "                        eye_state = EYE_OPEN if prev_state == EYE_OPEN else (EYE_OPENING if ear_deriv > 0 else EYE_OPEN)\n",
    "                        # blink 판정\n",
    "                        if 0 < close_count <= BLINK_MAX_FRAMES:\n",
    "                            eye_state = EYE_BLINK\n",
    "                        close_count = 0\n",
    "                    else:\n",
    "                        eye_state = EYE_OPENING if ear_deriv > 0 else (EYE_CLOSING if ear_deriv < 0 else prev_state)\n",
    "                        if prev_state in (EYE_CLOSE, EYE_CLOSING):\n",
    "                            close_count += 1\n",
    "                        else:\n",
    "                            close_count = 0\n",
    "\n",
    "                # 하품 상태\n",
    "                if mar_s is not None and mar_s > MAR_HIGH:\n",
    "                    yawn_count += 1\n",
    "                    yawn_state = YAWN_WITH_HAND if hand_near else YAWN_WITHOUT_HAND\n",
    "                else:\n",
    "                    yawn_state = YAWN_NONE\n",
    "                    yawn_count = 0\n",
    "\n",
    "                # 최종 행동 라벨\n",
    "                if yawn_state != YAWN_NONE and yawn_count >= YAWN_MIN_FRAMES:\n",
    "                    if yawn_state == YAWN_WITH_HAND:\n",
    "                        label_id, label_str = 5, \"yawning/Yawning with hand\"\n",
    "                    else:\n",
    "                        label_id, label_str = 6, \"yawning/Yawning without hand\"\n",
    "                else:\n",
    "                    if   eye_state == EYE_OPEN:    label_id, label_str = 0, \"eyes_state/open\"\n",
    "                    elif eye_state == EYE_CLOSE:   label_id, label_str = 1, \"eyes_state/close\"\n",
    "                    elif eye_state == EYE_OPENING: label_id, label_str = 2, \"eyes_state/opening\"\n",
    "                    elif eye_state == EYE_CLOSING: label_id, label_str = 3, \"eyes_state/closing\"\n",
    "                    elif eye_state == EYE_BLINK:   label_id, label_str = 4, \"blinks/blinking\"\n",
    "\n",
    "                # ====== 졸림 지표 업데이트 ======\n",
    "                # A) PERCLOS: 최근 PERCLOS_WIN_SEC 동안 '눈감김' 비율\n",
    "                closed_flag = 1 if ear_s is not None and ear_s < EAR_LOW else 0\n",
    "                closed_flags.append((t_sec, closed_flag))\n",
    "                while closed_flags and (t_sec - closed_flags[0][0] > PERCLOS_WIN_SEC):\n",
    "                    closed_flags.popleft()\n",
    "                if closed_flags:\n",
    "                    perclos = sum(f for _, f in closed_flags) / float(len(closed_flags))\n",
    "                else:\n",
    "                    perclos = None\n",
    "\n",
    "                # B) blink 이벤트 기록(짧은 닫힘)\n",
    "                # blink가 찍히는 순간(eye_state == EYE_BLINK)에서 duration 계산\n",
    "                # 간단히: 방금 전까지의 close_count를 duration으로 사용\n",
    "                if eye_state == EYE_BLINK:\n",
    "                    blink_dur = close_count / fps  # 방금 열림과 함께 close_count가 0으로 초기화되기 전에 계산됨\n",
    "                    blink_events.append((t_sec, blink_dur))\n",
    "                # 창구 유지\n",
    "                while blink_events and (t_sec - blink_events[0][0] > RATE_WIN_SEC):\n",
    "                    blink_events.popleft()\n",
    "\n",
    "                if blink_events:\n",
    "                    blink_rate = len(blink_events) * (60.0 / RATE_WIN_SEC)  # per 20s\n",
    "                    avg_blink_dur = float(np.mean([d for _, d in blink_events]))\n",
    "                else:\n",
    "                    blink_rate = 0.0\n",
    "                    avg_blink_dur = None\n",
    "\n",
    "                # C) 긴 eye-closure 감지(연속 close가 길면 이벤트로 기록)\n",
    "                # close 연속 구간의 시작/끝 추적\n",
    "                if closed_flag == 1 and active_close_start is None:\n",
    "                    active_close_start = t_sec\n",
    "                if closed_flag == 0 and active_close_start is not None:\n",
    "                    dur = t_sec - active_close_start\n",
    "                    blink_events.append((t_sec, dur))  # 긴 eye closure도 blink_events에 포함시켜 평균/최대에 반영\n",
    "                    active_close_start = None\n",
    "                # longest eye closure (최근 RATE_WIN_SEC)\n",
    "                if blink_events:\n",
    "                    longest_ec = max(d for _, d in blink_events)\n",
    "                else:\n",
    "                    longest_ec = None\n",
    "\n",
    "                # D) yawn 이벤트(프레임 지속 충족 시 시점 기록)\n",
    "                if yawn_state != YAWN_NONE and yawn_count == YAWN_MIN_FRAMES:\n",
    "                    yawn_events.append((t_sec,))\n",
    "                while yawn_events and (t_sec - yawn_events[0][0] > RATE_WIN_SEC):\n",
    "                    yawn_events.popleft()\n",
    "                yawn_rate = len(yawn_events) * (60.0 / RATE_WIN_SEC) if yawn_events else 0.0\n",
    "\n",
    "                # ====== 졸림 단계 산출 ======\n",
    "                d_level, d_label = drowsiness_level(perclos, yawn_rate, avg_blink_dur, longest_ec)\n",
    "\n",
    "                # ====== 시각화 ======\n",
    "                cv2.putText(frame, f\"Label {label_id}: {label_str}\", (20, 40),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 200, 255), 2)\n",
    "                if ear_s is not None:\n",
    "                    cv2.putText(frame, f\"EAR:{ear_s:.3f} (L:{EAR_LOW:.3f} H:{EAR_HIGH:.3f})\",\n",
    "                                (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                if mar_s is not None:\n",
    "                    cv2.putText(frame, f\"MAR:{mar_s:.3f} (Y>{MAR_HIGH:.3f})\",\n",
    "                                (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,200,0), 2)\n",
    "\n",
    "                # 졸림 지표/단계 표시\n",
    "                c = LEVEL_COLOR[d_level]\n",
    "                cv2.putText(frame, f\"Drowsiness {d_level}: {d_label}\", (20, 135),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, c, 2)\n",
    "                cv2.putText(frame, f\"PERCLOS:{(perclos if perclos is not None else np.nan):.2f}  \"\n",
    "                                    f\"Yawn/min:{yawn_rate:.1f}  \"\n",
    "                                    f\"Blink/min:{blink_rate:.1f}  \"\n",
    "                                    f\"AvgBlinkDur:{(avg_blink_dur if avg_blink_dur else np.nan):.2f}s  \"\n",
    "                                    f\"LongestEC:{(longest_ec if longest_ec else np.nan):.2f}s\",\n",
    "                            (20, 165), cv2.FONT_HERSHEY_SIMPLEX, 0.55, c, 2)\n",
    "\n",
    "            else:\n",
    "                # 얼굴 미검출 시\n",
    "                label_id, label_str = 0, \"eyes_state/open\"\n",
    "                d_level, d_label = 0, \"alert\"\n",
    "                perclos = None; yawn_rate = 0.0; blink_rate = 0.0; avg_blink_dur = None; longest_ec = None\n",
    "                cv2.putText(frame, \"Face not detected\", (20, 40),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "            # ====== 로그 저장 ======\n",
    "            logs.append({\n",
    "                \"frame\": frame_idx,\n",
    "                \"time_sec\": t_sec,\n",
    "                \"label_id\": label_id,\n",
    "                \"label_name\": label_str,\n",
    "                \"EAR\": float(ear_buf[-1]) if len(ear_buf)>0 else np.nan,\n",
    "                \"MAR\": float(mar_buf[-1]) if len(mar_buf)>0 else np.nan,\n",
    "                \"yawn_rate_per_min\": float(yawn_rate),\n",
    "                \"blink_rate_per_min\": float(blink_rate) if face_res.multi_face_landmarks else 0.0,\n",
    "                \"avg_blink_dur_sec\": float(avg_blink_dur) if avg_blink_dur is not None else np.nan,\n",
    "                \"longest_eye_closure_sec\": float(longest_ec) if longest_ec is not None else np.nan,\n",
    "                \"drowsiness_level\": d_level,\n",
    "                \"drowsiness_label\": d_label\n",
    "            })\n",
    "\n",
    "            out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    pd.DataFrame(logs).to_csv(\"./output/\"+output_csv, index=False)\n",
    "    print(f\"Saved video: {output_video}\")\n",
    "    print(f\"Saved CSV:   {output_csv}\")\n",
    "    print(f\"{time.time()-start:.4f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "314aed27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755655785.764491 25583315 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1755655785.766828 25687750 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1755655785.770785 25583315 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1755655785.777543 25687757 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755655785.783355 25687765 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755655785.791448 25687765 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video: 11-MaleGlasses-Yawning-label.mp4\n",
      "Saved CSV:   11-MaleGlasses-Yawning-label.csv\n",
      "15.6475 sec\n"
     ]
    }
   ],
   "source": [
    "label_video(target_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fed83ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: ../../../20.분석/21.데이타셋/DMD dataset/gC/13/s5/gC_13_s5_2019-03-12T10;03;00+01;00_rgb_face.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755663310.856296 25583315 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1755663310.859540 25992764 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1755663310.866183 25583315 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1755663310.868562 25992768 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755663310.875588 25992775 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755663310.881605 25992775 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video: gC_13_s5_2019-03-12T10;03;00+01;00_rgb_face-label.mp4\n",
      "Saved CSV:   gC_13_s5_2019-03-12T10;03;00+01;00_rgb_face-label.csv\n",
      "171.2254 sec\n",
      "Processing video: ../../../20.분석/21.데이타셋/DMD dataset/gC/11/s5/gC_11_s5_2019-03-12T09;08;15+01;00_rgb_face.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755663482.120757 25583315 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1755663482.123458 26001004 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1755663482.125514 25583315 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1755663482.133097 26001010 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755663482.133168 26001015 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755663482.139728 26001015 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video: gC_11_s5_2019-03-12T09;08;15+01;00_rgb_face-label.mp4\n",
      "Saved CSV:   gC_11_s5_2019-03-12T09;08;15+01;00_rgb_face-label.csv\n",
      "168.9174 sec\n",
      "Processing video: ../../../20.분석/21.데이타셋/DMD dataset/gC/12/s5/gC_12_s5_2019-03-14T09;56;52+01;00_rgb_face.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755663651.077497 25583315 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1755663651.080061 26008697 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1755663651.082032 25583315 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1755663651.088932 26008707 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755663651.089019 26008696 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755663651.093948 26008707 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video: gC_12_s5_2019-03-14T09;56;52+01;00_rgb_face-label.mp4\n",
      "Saved CSV:   gC_12_s5_2019-03-14T09;56;52+01;00_rgb_face-label.csv\n",
      "211.9921 sec\n",
      "Processing video: ../../../20.분석/21.데이타셋/DMD dataset/gC/14/s5/gC_14_s5_2019-03-12T09;18;58+01;00_rgb_face.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755663863.110795 25583315 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1755663863.113658 26018935 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1755663863.121328 25583315 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1755663863.123392 26018936 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755663863.129456 26018948 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755663863.140602 26018948 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video: gC_14_s5_2019-03-12T09;18;58+01;00_rgb_face-label.mp4\n",
      "Saved CSV:   gC_14_s5_2019-03-12T09;18;58+01;00_rgb_face-label.csv\n",
      "181.5161 sec\n",
      "Processing video: ../../../20.분석/21.데이타셋/DMD dataset/gC/15/s5/gC_15_s5_2019-03-12T11;03;23+01;00_rgb_face.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755664044.665718 25583315 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1755664044.668393 26028081 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1755664044.670815 25583315 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "W0000 00:00:1755664044.677796 26028081 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755664044.678686 26028090 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755664044.684772 26028090 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video: gC_15_s5_2019-03-12T11;03;23+01;00_rgb_face-label.mp4\n",
      "Saved CSV:   gC_15_s5_2019-03-12T11;03;23+01;00_rgb_face-label.csv\n",
      "189.6454 sec\n"
     ]
    }
   ],
   "source": [
    "for target_file in target_files:\n",
    "    print(f\"Processing video: {target_file}\")\n",
    "    label_video(target_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
