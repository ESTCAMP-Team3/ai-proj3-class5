#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìµœì í™”ëœ ì¡¸ìŒìš´ì „ ë°©ì§€ ì„œë¹„ìŠ¤ ì„œë²„
- Flask-SocketIO ê¸°ë°˜ ì‹¤ì‹œê°„ í†µì‹ 
- LLMì„ í™œìš©í•œ ë™ì  ìƒí˜¸ì‘ìš©
- ìƒíƒœ ì•ˆì •í™” ë° ì¿¨ë‹¤ìš´ ë¡œì§ ì ìš©
"""
import os
import json
import time
import hashlib
import threading
from pathlib import Path
from dotenv import load_dotenv
from flask import Flask, render_template, request, jsonify
from flask_socketio import SocketIO
from LLM_chat import generate_stage_payload
import requests

# eventlet/gevent ì‚¬ìš© ì‹œ DNS ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•œ ì„¤ì •
os.environ.setdefault("EVENTLET_NO_GREENDNS", "yes")
import eventlet
eventlet.monkey_patch()

class DrowsinessServer:
    """ì¡¸ìŒìš´ì „ ë°©ì§€ ì„œë²„ ë©”ì¸ í´ë˜ìŠ¤"""

    # --- ìƒìˆ˜ ì •ì˜ ---
    # API ëª¨ë¸ ë° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    LLM_MODEL = "gpt-4o-mini"
    LLM_SYSTEM_PROMPT = "ë‹¹ì‹ ì€ ì¡¸ìŒìš´ì „ ë°©ì§€ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì¹œê·¼í•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”."
    
    # ë¡œì»¬ ì €ì¥ íŒŒì¼ëª…
    LOCAL_CHAT_FILE = "chats_local.jsonl"

    def __init__(self):
        """ì„œë²„ ì´ˆê¸°í™”"""
        self.setup_env()
        self.setup_app()
        self.setup_storage()
        self.setup_state()
        
    def setup_env(self):
        """í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° ì„¤ì • ì´ˆê¸°í™”"""
        env_path = Path(__file__).parent / ".env"
        load_dotenv(dotenv_path=env_path)
        
        self.config = {
            'OPENAI_API_KEY': os.getenv("OPENAI_API_KEY", ""),
            'PORT': int(os.getenv("PORT", "8000")),
            'MONGO_URI': os.getenv("MONGO_URI", ""),
            'STABILITY_SECONDS': float(os.getenv("STABILITY_SECONDS", "3.0")),
            'COOLDOWN_SECONDS': float(os.getenv("COOLDOWN_SECONDS", "5.0")),
            'SECRET_KEY': os.getenv("SECRET_KEY", "dev_secret_key")
        }
        print(f"Config loaded - Port: {self.config['PORT']}, OpenAI: {bool(self.config['OPENAI_API_KEY'])}")

    def setup_app(self):
        """Flask ë° SocketIO ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™”"""
        self.app = Flask(__name__, static_folder="static", template_folder="templates")
        self.app.config["SECRET_KEY"] = self.config['SECRET_KEY']
        
        # ë¹„ë™ê¸° ëª¨ë“œë¡œ SocketIO ì„¤ì • (eventlet ìš°ì„ )
        try:
            self.socketio = SocketIO(self.app, cors_allowed_origins="*", async_mode="eventlet")
        except ImportError:
            self.socketio = SocketIO(self.app, cors_allowed_origins="*", async_mode="threading")
            
        self.setup_routes()
        
    def setup_storage(self):
        """ë°ì´í„° ì €ì¥ì†Œ(MongoDB ë˜ëŠ” ë¡œì»¬ íŒŒì¼) ì„¤ì •"""
        self.msg_col = None
        self.local_file = Path(self.LOCAL_CHAT_FILE)
        
        if self.config['MONGO_URI']:
            try:
                from pymongo import MongoClient, errors
                mongo_client = MongoClient(self.config['MONGO_URI'], serverSelectionTimeoutMS=3000)
                mongo_client.server_info() # ì—°ê²° í…ŒìŠ¤íŠ¸
                self.msg_col = mongo_client.drowsy_db.chat_messages
                print("âœ… MongoDB connected successfully.")
            except errors.ServerSelectionTimeoutError as e:
                print(f"âš ï¸ MongoDB connection failed: {e}. Falling back to local storage.")
        else:
            print("â„¹ï¸ Using local JSONL file for chat storage.")
            
    def setup_state(self):
        """ì‹¤ì‹œê°„ ìƒíƒœ ê´€ë¦¬ ë³€ìˆ˜ ì´ˆê¸°í™”"""
        self.state = {
            'last_stage': None,      # ë§ˆì§€ë§‰ìœ¼ë¡œ í™•ì •ëœ ë‹¨ê³„
            'last_emit_ts': 0.0,     # ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ë²¤íŠ¸ë¥¼ ë³´ë‚¸ íƒ€ì„ìŠ¤íƒ¬í”„
            'pending_stage': None,   # ë³€ê²½ ê°ì§€ í›„ ì•ˆì •í™”ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ë‹¨ê³„
            'pending_since': 0.0     # pending ìƒíƒœê°€ ì‹œì‘ëœ íƒ€ì„ìŠ¤íƒ¬í”„
        }
        self.emit_lock = threading.Lock() # ë™ì‹œì„± ì œì–´ë¥¼ ìœ„í•œ Lock

    # === ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ ===
    def get_stage_from_d(self, D_value):
        """Dê°’(ì¡¸ìŒ ì ìˆ˜)ì„ ê¸°ë°˜ìœ¼ë¡œ í˜„ì¬ ë‹¨ê³„ë¥¼ ê²°ì •"""
        try:
            D = float(D_value)
            # (ì„ê³„ê°’, ë‹¨ê³„ëª…) ìˆœì„œì˜ íŠœí”Œ ë¦¬ìŠ¤íŠ¸
            stages = [
                (30, 'ì •ìƒ'), (40, 'ì˜ì‹¬ê²½ê³ '), (50, 'ì§‘ì¤‘ëª¨ë‹ˆí„°ë§'), (60, 'ê°œì„ '), 
                (70, 'L1'), (80, 'L2'), (90, 'L3'), (float('inf'), 'FAILSAFE')
            ]
            # Dê°’ì´ ì„ê³„ê°’ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì€ ì²« ë²ˆì§¸ ë‹¨ê³„ë¥¼ ë°˜í™˜
            return next((stage for threshold, stage in stages if D <= threshold), 'FAILSAFE')
        except (ValueError, TypeError):
            return None
            
    def save_chat(self, msg: dict):
        """ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì„¤ì •ëœ ì €ì¥ì†Œì— ì €ì¥"""
        try:
            if self.msg_col is not None:
                self.msg_col.insert_one(msg)
            else:
                # ë¡œì»¬ íŒŒì¼ì— JSON Lines í˜•ì‹ìœ¼ë¡œ ì¶”ê°€ (íš¨ìœ¨ì )
                with open(self.local_file, 'a', encoding='utf-8') as f:
                    f.write(json.dumps(msg, ensure_ascii=False) + '\n')
        except Exception as e:
            print(f"ğŸš¨ Error saving chat message: {e}")
            
    def get_fallback_payload(self, stage: str) -> dict:
        """LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ì •ì  í˜ì´ë¡œë“œ ìƒì„±"""
        fallbacks = {
            'ì •ìƒ': ('ì •ìƒ ìƒíƒœì…ë‹ˆë‹¤.', ''),
            'ì˜ì‹¬ê²½ê³ ': ('ì£¼ì˜! ì¡¸ìŒ ì‹ í˜¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.', ''),
            'ì§‘ì¤‘ëª¨ë‹ˆí„°ë§': ('ìš´ì „ì ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤.', ''),
            'ê°œì„ ': ('ìƒíƒœê°€ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤. ê³„ì† ì•ˆì „ ìš´ì „í•˜ì„¸ìš”.', ''),
            'L1': ('ì¡¸ìŒì´ ê°ì§€ë©ë‹ˆë‹¤. ì ì‹œ íœ´ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤.', 'ì§€ê¸ˆ ê³„ì‹  ê³³ì˜ ë‹¤ìŒ íœ´ê²Œì†ŒëŠ” ì–´ë””ì¸ê°€ìš”?'),
            'L2': ('ê°•í•œ ì¡¸ìŒ ì‹ í˜¸ì…ë‹ˆë‹¤. ì°½ë¬¸ì„ ì—´ì–´ í™˜ê¸°í•˜ì„¸ìš”.', 'ì˜¤ëŠ˜ì˜ ë‚ ì§œì™€ ìš”ì¼ì„ ë§ì”€í•´ì£¼ì„¸ìš”.'),
            'L3': ('ìœ„í—˜! ë§¤ìš° ì¡¸ë¦° ìƒíƒœì…ë‹ˆë‹¤. ì¦‰ì‹œ ì•ˆì „í•œ ê³³ì— ì •ì°¨í•˜ì„¸ìš”.', '10ë¶€í„° 1ê¹Œì§€ ê±°ê¾¸ë¡œ ìˆ«ìë¥¼ ì„¸ì–´ë³´ì„¸ìš”.'),
            'FAILSAFE': ('ê³ ìœ„í—˜! ì¦‰ì‹œ ì°¨ëŸ‰ì„ ì •ì°¨í•˜ê³  íœ´ì‹ì„ ì·¨í•˜ì„¸ìš”.', '')
        }
        announcement, question = fallbacks.get(stage, ('ìƒíƒœê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.', ''))
        return {'announcement': announcement, 'question': question, 'stage': stage, 'ts': time.time()}
        
    # === ë¼ìš°íŠ¸ ë° ì†Œì¼“ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì • ===
    def setup_routes(self):
        """Flask ë¼ìš°íŠ¸ì™€ SocketIO ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë¥¼ ì •ì˜"""
        
        @self.app.route("/")
        def index():
            # templates í´ë”ì˜ index.htmlì„ ë Œë”ë§
            return render_template("index.html")

        @self.app.route("/ingest", methods=["POST"])
        def ingest():
            # ì¡¸ìŒ ë°ì´í„° ìˆ˜ì‹  ë° ì²˜ë¦¬
            return self.handle_ingest()
            
        @self.app.route("/chat_send", methods=["POST"]) 
        def chat_send():
            # ì‚¬ìš©ì ì±„íŒ… ë©”ì‹œì§€ ìˆ˜ì‹  ë° ì‘ë‹µ ìƒì„±
            return self.handle_chat_send()
            
        @self.app.route("/health", methods=["GET"])
        def health():
            # ì„œë²„ ìƒíƒœ í™•ì¸ìš© ì—”ë“œí¬ì¸íŠ¸
            return jsonify({"status": "ok"})
            
        @self.socketio.on("connect")
        def on_connect():
            print("âœ… Client connected")
            
        @self.socketio.on("disconnect") 
        def on_disconnect():
            print("ğŸ”Œ Client disconnected")
            
    # === í•µì‹¬ ë¡œì§ í•¸ë“¤ëŸ¬ ===
    def handle_ingest(self):
        """/ingest ìš”ì²­ ì²˜ë¦¬: Dê°’ì„ ë°›ì•„ ìƒíƒœë¥¼ ê²°ì •í•˜ê³  ì´ë²¤íŠ¸ë¥¼ ë°œìƒì‹œí‚¤ëŠ” í•µì‹¬ ë¡œì§"""
        data = request.get_json(force=True) or {}
        D_value = data.get("D")
        
        if D_value is None:
            return jsonify({"error": "D value is required"}), 400
            
        # Dê°’ì„ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        self.socketio.emit("d_update", {"D": D_value, "ts": data.get("ts", time.time())})
            
        stage = self.get_stage_from_d(D_value)
        if not stage:
            return jsonify({"error": "Invalid D value"}), 400
            
        now = time.time()
        
        # --- ìƒíƒœ ì „ì´ ë¡œì§ ---
        # 1. ì´ì „ê³¼ ë™ì¼í•œ ë‹¨ê³„ëŠ” ë¬´ì‹œí•˜ê³ , pending ìƒíƒœ ì´ˆê¸°í™”
        if stage == self.state['last_stage']:
            self.state['pending_stage'] = None
            return jsonify({"ok": True, "stage": stage, "emitted": False, "reason": "no_change"}), 200
            
        # 2. ìƒˆë¡œìš´ ë‹¨ê³„ê°€ ê°ì§€ë˜ë©´ 'pending' ìƒíƒœë¡œ ì „í™˜
        if self.state['pending_stage'] != stage:
            self.state['pending_stage'] = stage
            self.state['pending_since'] = now
            return jsonify({"ok": True, "stage": stage, "status": "pending"}), 200
            
        # 3. 'pending' ìƒíƒœê°€ ì•ˆì •í™” ì‹œê°„(STABILITY_SECONDS)ì„ ì¶©ì¡±í–ˆëŠ”ì§€ í™•ì¸
        if now - self.state['pending_since'] < self.config['STABILITY_SECONDS']:
            return jsonify({"ok": True, "stage": stage, "status": "stabilizing"}), 200
            
        # 4. ì•ˆì •í™” ì™„ë£Œ, ì´ë²¤íŠ¸ ë°œìƒ ì‹œë„
        with self.emit_lock:
            # ì¿¨ë‹¤ìš´(COOLDOWN_SECONDS) ì‹œê°„ í™•ì¸
            if now - self.state['last_emit_ts'] < self.config['COOLDOWN_SECONDS']:
                return jsonify({"ok": True, "stage": stage, "emitted": False, "reason": "cooldown"}), 200
                
            # LLM ë˜ëŠ” í´ë°±ì„ ì‚¬ìš©í•˜ì—¬ í˜ì´ë¡œë“œ ìƒì„±
            try:
                use_llm = bool(self.config['OPENAI_API_KEY'])
                payload = generate_stage_payload(stage, D_value, prefer_llm=use_llm)
            except Exception as e:
                print(f"ğŸš¨ LLM payload generation failed: {e}. Using fallback.")
                payload = self.get_fallback_payload(stage)
                
            print(f"ğŸš€ Stage transition: {self.state['last_stage']} -> {stage} (D={D_value})")
            
            # í´ë¼ì´ì–¸íŠ¸ì— 'state_prompt' ì´ë²¤íŠ¸ ì „ì†¡
            self.socketio.emit("state_prompt", payload)
                
            # ìƒíƒœ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
            self.state['last_stage'] = stage
            self.state['last_emit_ts'] = now
            self.state['pending_stage'] = None
            
            return jsonify({"ok": True, "stage": stage, "emitted": True, "payload": payload}), 200
            
    def handle_chat_send(self):
        """/chat_send ìš”ì²­ ì²˜ë¦¬: ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ LLM ì‘ë‹µ ìƒì„± ë° ì „ì†¡"""
        data = request.get_json() or {}
        text = data.get("text", "").strip()
        
        if not text:
            return jsonify({"error": "text is required"}), 400
            
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        ts = time.time()
        user_msg = {
            "ts": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(ts)),
            "user": "user", 
            "text": text,
            "msg_id": hashlib.sha1(f"user|{ts}|{text}".encode()).hexdigest()
        }
        self.save_chat(user_msg)
        
        # LLM ì‘ë‹µ ìƒì„±
        assistant_text = self.generate_llm_response(text)
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì €ì¥ ë° í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
        assistant_msg = {
            "ts": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
            "user": "assistant",
            "text": assistant_text, 
            "msg_id": hashlib.sha1(f"assistant|{ts}|{assistant_text}".encode()).hexdigest()
        }
        self.save_chat(assistant_msg)
        self.socketio.emit("chat_message", assistant_msg)
        
        return jsonify(assistant_msg), 200
        
    def generate_llm_response(self, text: str) -> str:
        """OpenAI APIë¥¼ í˜¸ì¶œí•˜ì—¬ LLM ì‘ë‹µì„ ìƒì„±. ì‹¤íŒ¨ ì‹œ ì •ì  ì‘ë‹µ ë°˜í™˜."""
        if not self.config['OPENAI_API_KEY']:
            return f"ì‘ë‹µ(ìƒ˜í”Œ): \"{text}\"ë¼ê³  ë§ì”€í•˜ì…¨ë„¤ìš”. í˜„ì¬ëŠ” OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
        try:
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.config['OPENAI_API_KEY']}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.LLM_MODEL,
                    "messages": [
                        {"role": "system", "content": self.LLM_SYSTEM_PROMPT},
                        {"role": "user", "content": text}
                    ],
                    "max_tokens": 150,
                    "temperature": 0.7
                },
                timeout=10
            )
            response.raise_for_status() # 200ë²ˆëŒ€ ì‘ë‹µì´ ì•„ë‹ˆë©´ ì˜ˆì™¸ ë°œìƒ
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
        except requests.RequestException as e:
            print(f"ğŸš¨ LLM API call failed: {e}")
            return f"ì‘ë‹µ ìƒì„±ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
    def run(self):
        """ì„œë²„ë¥¼ ì‹œì‘"""
        print("="*50)
        print(f"ğŸš— ì¡¸ìŒìš´ì „ ë°©ì§€ ì„œë²„ ì‹œì‘ - http://0.0.0.0:{self.config['PORT']}")
        print(f"ğŸ“Š ì•ˆì •í™” ì‹œê°„: {self.config['STABILITY_SECONDS']}ì´ˆ | ì¿¨ë‹¤ìš´: {self.config['COOLDOWN_SECONDS']}ì´ˆ")
        print("="*50)
        
        self.socketio.run(
            self.app, 
            host="0.0.0.0", 
            port=self.config['PORT'], 
            debug=False, 
            use_reloader=False
        )

# --- ì„œë²„ ì‹¤í–‰ ---
if __name__ == "__main__":
    server = DrowsinessServer()
    server.run()