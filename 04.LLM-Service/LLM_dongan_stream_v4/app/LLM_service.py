# LLM_service.py - ì¡¸ìŒìš´ì „ ë°©ì§€ ê³ ê¸‰ ëŒ€í™” AI ì„œë¹„ìŠ¤

import json
import random
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import openai
import os

class DrowsinessLLMService:
    """
    ì¡¸ìŒìš´ì „ ë°©ì§€ë¥¼ ìœ„í•œ ê³ ê¸‰ ëŒ€í™” AI ì„œë¹„ìŠ¤
    - ë§¥ë½ ì¸ì‹ ëŒ€í™”
    - ê°œì¸í™”ëœ ì‘ë‹µ
    - ë‹¨ê³„ë³„ ì—ìŠ¤ì»¬ë ˆì´ì…˜
    - ê°ì • ì¸ì‹ ë° ê³µê°
    """
    
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        if self.api_key:
            from openai import OpenAI
            self.client = OpenAI(api_key=self.api_key)
        # ìš´ì „ì ì»¨í…ìŠ¤íŠ¸
        self.driver_context = {
            'driving_start_time': None,
            'last_rest_time': None,
            'total_warnings': 0,
            'response_history': [],
            'emotional_state': 'neutral',
            'personal_info': {},
            'driving_duration': 0,
            'last_question_asked': None,  # ë§ˆì§€ë§‰ ì§ˆë¬¸ ì €ì¥
            'engagement_mode': None,      # 'joke' or 'quiz'
            'engagement_step': 0,        # ë°˜ë³µ íšŸìˆ˜
            'last_quiz': None,            # ë§ˆì§€ë§‰ í€´ì¦ˆ
            'last_joke': None            # ë§ˆì§€ë§‰ ì•„ì¬ê°œê·¸
        }
        # ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.stage_prompts = self.load_stage_prompts()
        # ëŒ€í™” í†¤ ì„¤ì •
        self.conversation_tones = {
            'ì •ìƒ': 'friendly',
            'ì˜ì‹¬ê²½ê³ ': 'concerned',
            'ì§‘ì¤‘ëª¨ë‹ˆí„°ë§': 'alert',
            'ê°œì„ ': 'encouraging', 
            'L1': 'urgent',
            'L2': 'serious',
            'L3': 'critical',
            'FAILSAFE': 'emergency'
        }
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì—­í•  ë¶„ë‹´ì„ ëª…í™•íˆ ì§€ì‹œ)
        self.system_prompt = """
        ë‹¹ì‹ ì€ ìš´ì „ìì˜ ì¡¸ìŒ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ê°œì…í•˜ëŠ” AI 'ë“œë¡œìš°ë‹ˆ'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ìš´ì „ìì˜ ì•ˆì „ì„ í™•ë³´í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
        ì¤‘ìš”í•œ ê·œì¹™:
        1. í™”ë©´ ì¤‘ì•™ì— í‘œì‹œë  ì£¼ìš” ê²½ê³  ë©”ì‹œì§€('announcement')ëŠ” ëª…ì‚¬í˜•ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì¢…ê²°í•  ê²ƒ. (ì˜ˆ: "ê³ ìœ„í—˜ ìƒíƒœ. ì¦‰ì‹œ ì •ì°¨.")
        2. ì±„íŒ…ì°½ì—ë§Œ í‘œì‹œë  í›„ì† ì§ˆë¬¸('question')ì€ ë¶€ë“œëŸ¬ìš´ ëŒ€í™”ì²´ ë§íˆ¬ë¥¼ ìœ ì§€í•  ê²ƒ. (ì˜ˆ: "ê°€ê¹Œìš´ íœ´ê²Œì†Œë¡œ ì•ˆë‚´í• ê¹Œìš”?")
        3. ìš´ì „ìì˜ ìƒíƒœ(stage, d_value)ì— ë”°ë¼ ë‹¨í˜¸í•˜ê³  ê¶Œìœ„ì ì¸ í†¤ì„ ìœ ì§€í•  ê²ƒ.
        4. í•„ìš”ì‹œ, ì°½ë¬¸ ê°œë°©, ì—ì–´ì»¨ ê°•í’, íœ´ê²Œì†Œ ì•ˆë‚´ ë“± êµ¬ì²´ì ì¸ í–‰ë™ì„ ì§€ì‹œí•  ê²ƒ.
        5. ìš´ì „ìì˜ ë§ì„ ì •í™•íˆ ì´í•´í•˜ê³  ë§¥ë½ì— ë§ëŠ” ì‘ë‹µì„ í•  ê²ƒ.
        6. "ì¡¸ë ¤"ë¼ëŠ” ë§ì—ëŠ” "ì•ˆë…•í•˜ì„¸ìš”"ê°€ ì•„ë‹Œ ì¡¸ìŒê³¼ ê´€ë ¨ëœ ì ì ˆí•œ ì‘ë‹µì„ í•  ê²ƒ.
        7. ìŒì•… ê´€ë ¨ ëª…ë ¹ì–´("ìŒì•… í‹€ì–´ì¤˜", "ìŒì•… êº¼ì¤˜" ë“±)ë¥¼ ì •í™•íˆ ì¸ì‹í•˜ê³  ì²˜ë¦¬í•  ê²ƒ.
        """

        # ì•„ì¬ê°œê·¸/í€´ì¦ˆ ë¦¬ìŠ¤íŠ¸
        self.jokes = [
            "ìë™ì°¨ê°€ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ê³¼ì¼ì€? ì¹´~ë©œë¡ !",
            "ìš´ì „ìê°€ ê°€ì¥ ì‹«ì–´í•˜ëŠ” ì±„ì†ŒëŠ”? ë¸Œë ˆì´í¬~ì½œë¦¬!",
            "ë„ë¡œ ìœ„ì—ì„œ ì¶¤ì¶”ëŠ” ì°¨ëŠ”? ìŠ¤í…ì›¨ê±´!"
        ]
        self.quizzes = [
            {"question": "ìš°ë¦¬ë‚˜ë¼ ìˆ˜ë„ëŠ” ì–´ë””ì¼ê¹Œìš”?", "answer": "ì„œìš¸"},
            {"question": "ìë™ì°¨ ë°”í€´ëŠ” ëª‡ ê°œì¼ê¹Œìš”?", "answer": "4ê°œ"},
            {"question": "ë¹¨ê°„ë¶ˆì— í•´ì•¼ í•  í–‰ë™ì€?", "answer": "ì •ì§€"}
        ]
    def _start_engagement(self, mode: str):
        """
        ì˜ì‹¬ê²½ê³  ë‹¨ê³„ ì§„ì… ì‹œ ì•„ì¬ê°œê·¸/í€´ì¦ˆ/ìŒì•…/ê²½ê³  ëŒ€í™” ì‹œì‘
        mode: 'joke' or 'quiz'
        """
        self.driver_context['engagement_mode'] = mode
        self.driver_context['engagement_step'] = 1
        if mode == 'joke':
            joke = random.choice(self.jokes)
            self.driver_context['last_joke'] = joke
            return {
                'announcement': "ì¡¸ìŒì´ ì‹œì‘ë©ë‹ˆë‹¤. ì°½ë¬¸ì„ ë‚´ë¦¬ì„¸ìš”! í˜¹ì‹œ ì•„ì¬ê°œê·¸ ë“¤ì–´ë³´ì‹¤ë˜ìš”?",
                'question': joke + "\nì¬ë°Œìœ¼ì…¨ë‚˜ìš”? í•˜ë‚˜ ë” ë“¤ì–´ë³¼ê¹Œìš”?",
                'action_suggestion': "ì°½ë¬¸ì„ ì—´ê±°ë‚˜ ìŒì•…ì„ í‹€ì–´ë³´ì„¸ìš”.",
                'engagement_mode': 'joke'
            }
        elif mode == 'quiz':
            quiz = random.choice(self.quizzes)
            self.driver_context['last_quiz'] = quiz
            return {
                'announcement': "ì¡¸ìŒì´ ì‹œì‘ë©ë‹ˆë‹¤. ì°½ë¬¸ì„ ë‚´ë¦¬ì„¸ìš”! í€´ì¦ˆ í•˜ë‚˜ í’€ì–´ë³´ì‹¤ë˜ìš”?",
                'question': quiz['question'] + "\nì •ë‹µì„ ë§ì”€í•´ ì£¼ì„¸ìš”!",
                'action_suggestion': "ì°½ë¬¸ì„ ì—´ê±°ë‚˜ ìŒì•…ì„ í‹€ì–´ë³´ì„¸ìš”.",
                'engagement_mode': 'quiz'
            }
        else:
            return {
                'announcement': "ì¡¸ìŒì´ ì‹œì‘ë©ë‹ˆë‹¤. ì°½ë¬¸ì„ ë‚´ë¦¬ì„¸ìš”! ìŒì•…ì„ í‹€ì–´ë“œë¦´ê¹Œìš”?",
                'question': "ì¡¸ìŒ ë°©ì§€ ìŒì•…ì„ ì¬ìƒí• ê¹Œìš”?",
                'action_suggestion': "ì°½ë¬¸ì„ ì—´ê±°ë‚˜ ìŒì•…ì„ í‹€ì–´ë³´ì„¸ìš”.",
                'engagement_mode': None
            }

    def _continue_engagement(self, user_input: str):
        """
        ìš´ì „ì ë°˜ì‘ì— ë”°ë¼ ì•„ì¬ê°œê·¸/í€´ì¦ˆ ë°˜ë³µ ë˜ëŠ” ì¢…ë£Œ
        """
        mode = self.driver_context.get('engagement_mode')
        if not mode:
            return None
        # ê¸ì •/ë¶€ì • íŒë³„
        positive = any(x in user_input for x in ['ë„¤', 'ì¢‹ì•„ìš”', 'ì‘', 'ì¬ë°Œ', 'í’€', 'ë”', 'ì˜ˆ', 'OK', 'ë˜'])
        negative = any(x in user_input for x in ['ì•„ë‹ˆ', 'ê·¸ë§Œ', 'ì‹«', 'ì•ˆ', 'ë…¸', 'ì•„ë‹ˆì˜¤', 'ê·¸ë§Œí•´'])
        if mode == 'joke':
            if positive:
                joke = random.choice(self.jokes)
                self.driver_context['last_joke'] = joke
                self.driver_context['engagement_step'] += 1
                return {
                    'announcement': "í•˜ë‚˜ ë”!",
                    'question': joke + "\në˜ í•˜ë‚˜ ë” ë“¤ì–´ë³¼ê¹Œìš”?",
                    'action_suggestion': "ì°½ë¬¸ì„ ì—´ê±°ë‚˜ ìŒì•…ì„ í‹€ì–´ë³´ì„¸ìš”.",
                    'engagement_mode': 'joke'
                }
            elif negative:
                self.driver_context['engagement_mode'] = None
                return {
                    'announcement': "ì•Œê² ì–´ìš”, ì•ˆì „ìš´ì „í•˜ì„¸ìš”!",
                    'question': "ì¡¸ìŒì´ ì˜¤ë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.",
                    'action_suggestion': "ì°½ë¬¸ì„ ì—´ê±°ë‚˜ ìŒì•…ì„ í‹€ì–´ë³´ì„¸ìš”.",
                    'engagement_mode': None
                }
        elif mode == 'quiz':
            last_quiz = self.driver_context.get('last_quiz')
            if last_quiz and last_quiz['answer'] in user_input:
                # ì •ë‹µ
                self.driver_context['engagement_step'] += 1
                quiz = random.choice(self.quizzes)
                self.driver_context['last_quiz'] = quiz
                return {
                    'announcement': "ì •ë‹µì…ë‹ˆë‹¤! ë˜ë‹¤ë¥¸ í€´ì¦ˆë¥¼ í’€ì–´ë³¼ê¹Œìš”?",
                    'question': quiz['question'] + "\nì •ë‹µì„ ë§ì”€í•´ ì£¼ì„¸ìš”!",
                    'action_suggestion': "ì°½ë¬¸ì„ ì—´ê±°ë‚˜ ìŒì•…ì„ í‹€ì–´ë³´ì„¸ìš”.",
                    'engagement_mode': 'quiz'
                }
            elif negative:
                self.driver_context['engagement_mode'] = None
                return {
                    'announcement': "ì•Œê² ì–´ìš”, ì•ˆì „ìš´ì „í•˜ì„¸ìš”!",
                    'question': "ì¡¸ìŒì´ ì˜¤ë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.",
                    'action_suggestion': "ì°½ë¬¸ì„ ì—´ê±°ë‚˜ ìŒì•…ì„ í‹€ì–´ë³´ì„¸ìš”.",
                    'engagement_mode': None
                }
            else:
                # ì˜¤ë‹µ
                return {
                    'announcement': "ì•„ì‰½ë„¤ìš”! ì •ë‹µì€ " + last_quiz['answer'] + "ì…ë‹ˆë‹¤. ë˜ë‹¤ë¥¸ í€´ì¦ˆë¥¼ í’€ì–´ë³¼ê¹Œìš”?",
                    'question': random.choice(self.quizzes)['question'] + "\nì •ë‹µì„ ë§ì”€í•´ ì£¼ì„¸ìš”!",
                    'action_suggestion': "ì°½ë¬¸ì„ ì—´ê±°ë‚˜ ìŒì•…ì„ í‹€ì–´ë³´ì„¸ìš”.",
                    'engagement_mode': 'quiz'
                }
        return None
    
    def load_stage_prompts(self) -> Dict:
        """ë‹¨ê³„ë³„ ë™ì  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"""
        return {
            'ì •ìƒ': {
                'system': """ë‹¹ì‹ ì€ ì¹œê·¼í•œ ìš´ì „ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ìš´ì „ìì™€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ë©° 
                ì»¨ë””ì…˜ì„ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤. í¸ì•ˆí•˜ê³  ê¸ì •ì ì¸ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”.""",
                'templates': [
                    "ìš´ì „ ì‹œì‘í•˜ì‹  ì§€ {duration}ë¶„ ë˜ì…¨ë„¤ìš”. ì˜¤ëŠ˜ ì»¨ë””ì…˜ì€ ì–´ë– ì„¸ìš”?",
                    "ë‚ ì”¨ê°€ {weather}í•œë°, ìš´ì „í•˜ê¸° ì¢‹ì€ ë‚ ì´ë„¤ìš”!",
                    "{time_of_day} ìš´ì „ì€ ì–´ë– ì‹ ê°€ìš”? ìŒì•…ì´ë¼ë„ í‹€ì–´ë“œë¦´ê¹Œìš”?"
                ]
            },
            
            'ì˜ì‹¬ê²½ê³ ': {
                'system': """ì¡¸ìŒ ì‹ í˜¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ê³µê°ì„ ë¨¼ì € í‘œí˜„í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì œì•ˆì„ í•˜ì„¸ìš”.
                'í”¼ê³¤í•˜ì‹œê² ì–´ìš”' ê°™ì€ ê³µê°ë¶€í„° ì‹œì‘í•˜ê³ , êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì¹˜ë¥¼ ì œì•ˆí•˜ì„¸ìš”.""",
                'templates': [
                    "í”¼ê³¤í•˜ì‹œê² ì–´ìš”. ì°½ë¬¸ì„ ì¡°ê¸ˆ ì—´ì–´ì„œ ì‹ ì„ í•œ ë°”ëŒ ì¬ëŠ” ê²Œ ì–´ë–¨ê¹Œìš”?",
                    "ì¡¸ìŒì´ ì˜¤ì‹œëŠ”êµ°ìš”. ê¹Šê²Œ ì‹¬í˜¸í¡ì„ ëª‡ ë²ˆ í•´ë³´ì‹œê±°ë‚˜ ëª©ì„ ì¢Œìš°ë¡œ ëŒë ¤ë³´ì„¸ìš”.",
                    "ìš´ì „í•˜ëŠë¼ ìˆ˜ê³ ê°€ ë§ìœ¼ì„¸ìš”. ì ê¹ ì–´ê¹¨ë¥¼ ìœ¼ì“±í•´ë³´ì‹œë©´ ê¸°ë¶„ì´ ë‚˜ì•„ì§ˆ ê±°ì˜ˆìš”."
                ],
                'engaging_questions': [
                    "ëª©ì ì§€ê¹Œì§€ ì–¼ë§ˆë‚˜ ë‚¨ì•˜ë‚˜ìš”",
                    "ì˜¤ëŠ˜ ì»¨ë””ì…˜ì€ ì–´ë– ì„¸ìš”",
                    "ì»¤í”¼ í•œ ì” í•˜ì‹œê³  ì‹¶ì§€ ì•Šë‚˜ìš”"
                ]
            },
            
            'L1': {
                'system': """ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤. ê³µê°ê³¼ ì´í•´ë¥¼ í‘œí˜„í•œ í›„ ë‹¨í˜¸í•˜ì§€ë§Œ ì¹œê·¼í•œ í†¤ìœ¼ë¡œ 
                ì¦‰ê°ì ì¸ í–‰ë™ì„ ìœ ë„í•˜ì„¸ìš”. ìš´ì „ìê°€ ì§œì¦ë‚´ë”ë¼ë„ ì¹¨ì°©í•˜ê²Œ ëŒ€ì‘í•˜ê³ , ì•ˆì „ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ì„¸ìš”.""",
                'templates': [
                    "ë§ì´ í”¼ê³¤í•˜ì‹œê² ì–´ìš”. ì •ë§ ìœ„í—˜í•´ìš”! ê°€ê¹Œìš´ íœ´ê²Œì†Œì—ì„œ 5ë¶„ë§Œ ì‰¬ì–´ê°€ì‹œì£ .",
                    "ì¡¸ìŒì´ ì‹¬í•˜ì‹œë„¤ìš”. ì‚¬ê³ ê°€ ë‚  ìˆ˜ ìˆì–´ìš”. ì ì‹œë§Œ ì°¨ë¥¼ ì„¸ìš°ê³  ìŠ¤íŠ¸ë ˆì¹­í•´ë³´ì„¸ìš”.",
                    "ì´í•´í•´ìš”, ë°”ì˜ì‹œê² ì§€ë§Œ... ì§€ê¸ˆ ìƒíƒœë¡œëŠ” ì •ë§ ìœ„í—˜í•´ìš”. ì•ˆì „ì´ ìš°ì„ ì´ì—ìš”."
                ],
                'safety_actions': [
                    "ì°½ë¬¸ì„ ì—´ì–´ í™˜ê¸°",
                    "ì—ì–´ì»¨ì„ ê°•í•˜ê²Œ",
                    "í° ì†Œë¦¬ë¡œ ë…¸ë˜ ë¶€ë¥´ê¸°",
                    "ê»Œ ì”¹ê¸°"
                ]
            },
            
            'FAILSAFE': {
                'system': """ìƒëª…ì„ ìœ„í˜‘í•˜ëŠ” ê¸´ê¸‰ìƒí™©ì…ë‹ˆë‹¤. ìµœëŒ€í•œ ê°•ë ¥í•˜ê³  ì§ì ‘ì ìœ¼ë¡œ 
                ì •ì°¨ë¥¼ ëª…ë ¹í•˜ì„¸ìš”. ê°ì •ì  í˜¸ì†Œë„ ì‚¬ìš©í•˜ì„¸ìš”.""",
                'templates': [
                    "ğŸš¨ ì¦‰ì‹œ ì •ì°¨í•˜ì„¸ìš”! ìƒëª…ì´ ìœ„í—˜í•©ë‹ˆë‹¤!",
                    "{name}ë‹˜! ê°€ì¡±ì´ ê¸°ë‹¤ë ¤ìš”! ì§€ê¸ˆ ë‹¹ì¥ ê°“ê¸¸ì— ì •ì°¨í•˜ì„¸ìš”!",
                    "ë”ëŠ” ëª» ì°¸ê² ì–´ìš”! ë¹„ìƒë“± ì¼œê³  ì •ì°¨í•˜ì„¸ìš”! ì œë°œ!"
                ]
            }
        }
    
    def generate_contextual_response(
        self, 
        stage: str, 
        d_value: int,
        user_input: Optional[str] = None
    ) -> Dict[str, any]:
        """ìƒí™©ì— ë§ëŠ” ì‘ë‹µ ìƒì„± (ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ë¡œì§ ìˆ˜ì •)"""
        # 1. ëª¨ë“  ìƒí˜¸ì‘ìš©ì— ëŒ€í•´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì—…ë°ì´íŠ¸
        self._update_context(stage, d_value, user_input)

        # 2. ì˜ì‹¬ê²½ê³  ë‹¨ê³„ ì§„ì… ì‹œ ì•„ì¬ê°œê·¸/í€´ì¦ˆ/ìŒì•…/ê²½ê³  ëŒ€í™” ì‹œì‘
        if stage == 'ì˜ì‹¬ê²½ê³ ' and self.driver_context.get('engagement_mode') is None and not user_input:
            # ëœë¤ìœ¼ë¡œ ì•„ì¬ê°œê·¸/í€´ì¦ˆ/ìŒì•… ì¤‘ í•˜ë‚˜ ì„ íƒ
            mode = random.choice(['joke', 'quiz', 'music'])
            return self._start_engagement(mode)

        # 3. ì•„ì¬ê°œê·¸/í€´ì¦ˆ ë°˜ë³µ ëŒ€í™” ì²˜ë¦¬
        if self.driver_context.get('engagement_mode') in ['joke', 'quiz'] and user_input:
            engagement_response = self._continue_engagement(user_input)
            if engagement_response:
                return engagement_response

        # 4. ì‚¬ìš©ìê°€ ë‹µë³€ì„ í•œ ê²½ìš° (ì´ì „ ì§ˆë¬¸ì´ ìˆì—ˆê³ , ì‚¬ìš©ì ì…ë ¥ì´ ìˆì„ ë•Œ)
        if self.driver_context['last_question_asked'] and user_input:
            question = self.driver_context['last_question_asked']
            self.driver_context['last_question_asked'] = None  # ì§ˆë¬¸ ì²˜ë¦¬ í›„ ì´ˆê¸°í™”
            # ë‹µë³€ ë¶„ì„ ë° í›„ì† ì¡°ì¹˜ ìƒì„±
            follow_up = self.analyze_answer_and_respond(question, user_input, stage)
            # ê¸°ë³¸ ì‘ë‹µ í˜•ì‹ì— í›„ì† ì¡°ì¹˜ ë‚´ìš©ì„ ë®ì–´ì“°ê¸°
            response = self._generate_rule_based_response(stage, d_value)
            response['announcement'] = follow_up['response']
            response['question'] = ''
            response['action_suggestion'] = follow_up.get('action_required', '')
            return response

        # 5. ì¼ë°˜ì ì¸ ìƒí™© (LLM ë˜ëŠ” ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ ìƒì„±)
        if self.api_key:
            return self._generate_llm_response(stage, d_value, user_input)
        return self._generate_rule_based_response(stage, d_value)
    
    def _generate_llm_response(self, stage: str, d_value: int, user_input: str) -> Dict:
        """OpenAI APIë¥¼ ì‚¬ìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„± (API í˜¸ì¶œ ë°©ì‹ ìˆ˜ì •)"""
        
        prompt_config = self.stage_prompts.get(stage, self.stage_prompts['ì •ìƒ'])
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        messages = [
            {"role": "system", "content": prompt_config['system']},
            {"role": "system", "content": self.system_prompt},
            {"role": "system", "content": f"""
                í˜„ì¬ ìƒí™©:
                - ì¡¸ìŒ ë‹¨ê³„: {stage} (Dê°’: {d_value})
                - ìš´ì „ ì‹œê°„: {self.driver_context['driving_duration']}ë¶„
                - ì´ ê²½ê³  íšŸìˆ˜: {self.driver_context['total_warnings']}íšŒ
                - ìš´ì „ì ê°ì •: {self.driver_context['emotional_state']}
                - ë§ˆì§€ë§‰ íœ´ì‹: {self.driver_context.get('last_rest_time', 'ì—†ìŒ')}
                
                ì‘ë‹µ ê·œì¹™:
                1. {self.conversation_tones[stage]} í†¤ ìœ ì§€
                2. 20ë‹¨ì–´ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
                3. ìš´ì „ì ì´ë¦„ì´ ìˆë‹¤ë©´ í˜¸ì¹­ ì‚¬ìš©
                4. ì‹¤ì‹œê°„ ì •ë³´ ë°˜ì˜ (ì‹œê°„, ë‚ ì”¨ ë“±)
                5. ì´ì „ ëŒ€í™” ë§¥ë½ ê³ ë ¤
                6. ì‚¬ìš©ì ì…ë ¥ì˜ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ê´€ë ¨ëœ ì‘ë‹µì„ í•  ê²ƒ
                
                íŠ¹ë³„ ì²˜ë¦¬ ì§€ì¹¨:
                - "ì¡¸ë ¤", "í”¼ê³¤í•´" â†’ "í”¼ê³¤í•˜ì‹œê² ì–´ìš”" ê°™ì€ ê³µê°ë¶€í„° ì‹œì‘í•˜ê³  êµ¬ì²´ì  ì¡°ì¹˜ ì œì•ˆ
                - "ìŒì•… í‹€ì–´", "ë…¸ë˜ í‹€ì–´" â†’ ìŒì•… ì¬ìƒ í™•ì¸ 
                - "ìŒì•… êº¼", "ê·¸ë§Œ", "ë©ˆì¶°" â†’ ìŒì•… ì¤‘ì§€ í™•ì¸
                - ì¼ë°˜ ì•ˆë¶€ ì¸ì‚¬ì—ëŠ” ì¹œê·¼í•˜ê²Œ ì‘ë‹µ
                - í•­ìƒ ê³µê° í‘œí˜„ì„ ë¨¼ì € í•˜ê³  ì‹¤ìš©ì ì¸ ì œì•ˆì„ í•  ê²ƒ
                
                ì‘ë‹µ íŒ¨í„´: [ê³µê°] + [ì œì•ˆ] í˜•ì‹ìœ¼ë¡œ êµ¬ì„±
                ì˜ˆ: "í”¼ê³¤í•˜ì‹œê² ì–´ìš”. ì°½ë¬¸ì„ ì¡°ê¸ˆ ì—´ì–´ë³´ì‹œëŠ” ê²Œ ì–´ë–¨ê¹Œìš”?"
            """}
        ]
        
        # ìµœê·¼ ëŒ€í™” ì´ë ¥ ì¶”ê°€
        for hist in self.driver_context['response_history'][-3:]:
            messages.append({"role": "user", "content": hist.get('user', '')})
            messages.append({"role": "assistant", "content": hist.get('assistant', '')})
        
        # í˜„ì¬ ì…ë ¥ ì¶”ê°€
        if user_input:
            messages.append({"role": "user", "content": user_input})
        else:
            messages.append({"role": "user", "content": f"ìš´ì „ì ìƒíƒœê°€ {stage}ì…ë‹ˆë‹¤. ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”."})
        
        try:
            # [ìˆ˜ì •] ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬(v1.x) ë°©ì‹ì˜ API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=messages,
                temperature=0.7,
                max_tokens=100
            )
            
            llm_text = response.choices[0].message.content
            
            # LLM ì‘ë‹µ íŒŒì‹±
            parsed_response = self._parse_llm_response(llm_text, stage)
            
            # ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
            if parsed_response.get('question'):
                self.driver_context['last_question_asked'] = parsed_response['question']
                
            return parsed_response
            
        except Exception as e:
            print(f"LLM ì˜¤ë¥˜: {e}")
            return self._generate_rule_based_response(stage, d_value)

    def _parse_llm_response(self, response: str, stage: str) -> Dict:
        """LLM ì‘ë‹µì„ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (íŒŒì‹± ë°©ì‹ ê°œì„ )"""
        
        # ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ ë¶„ë¦¬ (ë” ì•ˆì •ì )
        import re
        sentences = re.split(r'(?<=[.?!])\s+', response)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        result = {
            'announcement': sentences[0] if sentences else f"{stage} ìƒíƒœì…ë‹ˆë‹¤.",
            'question': '',
            'action_suggestion': '',
            'emotional_tone': self.conversation_tones[stage],
            'tts_params': {
                'voice': 'female_calm' if stage in ['ì •ìƒ', 'ê°œì„ '] else 'female_urgent',
                'speed': 1.0 if stage in ['ì •ìƒ', 'ê°œì„ '] else 1.2,
                'volume': min(1.5, 0.8 + (0.1 * self._get_stage_level(stage)))
            }
        }
        
        # ì§ˆë¬¸ ì¶”ì¶œ (ë¬¼ìŒí‘œê°€ ìˆëŠ” ë¬¸ì¥)
        for sent in sentences:
            if '?' in sent:
                result['question'] = sent
                break
        
        # í–‰ë™ ì œì•ˆ ì¶”ì¶œ (íŠ¹ì • í‚¤ì›Œë“œ í¬í•¨)
        action_keywords = ['í•˜ì„¸ìš”', 'í•´ë³´ì„¸ìš”', 'ê¶Œì¥', 'ì¶”ì²œ', 'í•˜ë©´', 'í•˜ì‹œë©´']
        for sent in sentences:
            if any(keyword in sent for keyword in action_keywords):
                result['action_suggestion'] = sent
                break
        
        return result
    
    def _generate_rule_based_response(self, stage: str, d_value: int) -> Dict:
        """ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ ìƒì„± (ë§íˆ¬ ë¶„ë¦¬ ë° ì‚¬ìš´ë“œ ë³€ê²½)"""
        
        responses = {
            "ì •ìƒ": {
                "announcement": "í˜„ì¬ ìƒíƒœ ì •ìƒ.",
                "question": "ìš´ì „í•˜ê¸° ì¢‹ì€ ë‚ ì´ë„¤ìš”! ëª©ì ì§€ê¹Œì§€ ì•ˆì „í•˜ê²Œ ê°€ìš”."
            },
            "ì˜ì‹¬ê²½ê³ ": {
                "announcement": "ì¡¸ìŒ ì‹ í˜¸ ê°ì§€",
                "question": "ì¡¸ìŒì´ ì˜¤ì‹œëŠ”êµ°ìš”. ì°½ë¬¸ì„ ì—´ì–´ ì‹ ì„ í•œ ê³µê¸°ë¥¼ ë“¤ì´í‚¤ëŠ” ê²ƒì€ ì–´ë– ì„¸ìš”?"
            },
            "L1": {
                "announcement": "ì¡¸ìŒ ì§€ì†",
                "question": "ì¡¸ìŒì´ ì§€ì†ë˜ê³  ìˆë„¤ìš”. ìŒì•…ì„ í‹€ì–´ë“œë¦´ê¹Œìš”? ì•„ë‹ˆë©´ ì ì‹œ ì‰¬ì–´ê°€ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"
            },
            "L2": {
                "announcement": "ê°•í•œ ì¡¸ìŒ ê°ì§€",
                "question": "ì¡¸ìŒì´ ì‹¬í•´ì§€ê³  ìˆì–´ìš”. ì°½ë¬¸ì„ ì—´ê±°ë‚˜ ì—ì–´ì»¨ì„ ê°•í•˜ê²Œ í‹€ì–´ë³´ì‹œëŠ” ê²Œ ì–´ë–¨ê¹Œìš”?"
            },
            "L3": {
                "announcement": "ê³ ìœ„í—˜ ìƒíƒœ",
                "question": "ì •ë§ ìœ„í—˜í•œ ìƒíƒœì˜ˆìš”. ê°€ê¹Œìš´ íœ´ê²Œì†Œì—ì„œ ì ì‹œ ì‰¬ì–´ê°€ì‹œëŠ” ê²ƒì„ ê°•ë ¥íˆ ê¶Œí•©ë‹ˆë‹¤."
            },
            "FAILSAFE": {
                "announcement": "ì¦‰ì‹œ ì •ì°¨",
                "question": "ì§€ê¸ˆ ë‹¹ì¥ ê°“ê¸¸ì— ì •ì°¨í•˜ì„¸ìš”! ìƒëª…ì´ ì†Œì¤‘í•´ìš”!"
            }
        }
        
        response = responses.get(stage, responses['ì •ìƒ'])
        response['music'] = self._select_appropriate_music(stage)
        response['emotional_tone'] = self.conversation_tones[stage]
        response['tts_params'] = {
            'voice': 'female_calm' if stage in ['ì •ìƒ', 'ê°œì„ '] else 'female_urgent',
            'speed': 1.0 if stage in ['ì •ìƒ', 'ê°œì„ '] else 1.2,
            'volume': min(1.5, 0.8 + (0.1 * self._get_stage_level(stage)))
        }
        return response
    
    def analyze_answer_and_respond(self, question: str, answer: str, stage: str) -> Dict:
        """
        ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë¶„ì„í•˜ê³  í›„ì† ì‘ë‹µ ìƒì„±
        
        Args:
            question: AIê°€ í–ˆë˜ ì§ˆë¬¸
            answer: ì‚¬ìš©ìì˜ ë‹µë³€
            stage: í˜„ì¬ ì¡¸ìŒ ë‹¨ê³„
        """
        
        # ì¸ì§€ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ê²€ì¦
        cognitive_tests = {
            "ë‚ ì§œê°€ ëª‡ ì¼": self._check_date_answer,
            "ì„œìš¸ ë‹¤ìŒ ë„ì‹œ": lambda a: "ëŒ€ì „" in a or "ëŒ€êµ¬" in a,
            "10ì—ì„œ 1ê¹Œì§€": self._check_countdown_answer,
            "ëª‡ ì‹œ": self._check_time_answer
        }
        
        # ë‹µë³€ ì •í™•ë„ í™•ì¸
        is_correct = False
        for test_key, validator in cognitive_tests.items():
            if test_key in question:
                is_correct = validator(answer)
                break
        
        # ì‘ë‹µ ìƒì„±
        if is_correct:
            responses = {
                'L1': "ì¢‹ì•„ìš”! ì•„ì§ ì •ì‹ ì´ ë§‘ìœ¼ì‹œë„¤ìš”. ê·¸ë˜ë„ ì¡°ì‹¬í•˜ì„¸ìš”.",
                'L2': "ë§ì•˜ì–´ìš”! í•˜ì§€ë§Œ ë°˜ì‘ì´ ëŠë ¤ì§€ê³  ìˆì–´ìš”. íœ´ì‹ì´ í•„ìš”í•´ìš”.",
                'L3': "ë„¤, ë§ì•„ìš”. ê·¸ë˜ë„ ìœ„í—˜í•œ ìƒíƒœì˜ˆìš”. ì œë°œ ì‰¬ì–´ê°€ì„¸ìš”."
            }
        else:
            responses = {
                'L1': "ì–´... í‹€ë¦¬ì…¨ë„¤ìš”. ì •ë§ í”¼ê³¤í•˜ì‹ ê°€ë´ìš”. 5ë¶„ë§Œ ì‰¬ì–´ê°€ì‹œì£ ?",
                'L2': "ë‹µì´ ì´ìƒí•´ìš”! ì§‘ì¤‘ë ¥ì´ ë§ì´ ë–¨ì–´ì¡Œì–´ìš”. ì§€ê¸ˆ ì •ì°¨í•˜ì„¸ìš”!",
                'L3': "ìœ„í—˜í•´ìš”! ì œëŒ€ë¡œ ë‹µì„ ëª»í•˜ì‹œë„¤ìš”. ì¦‰ì‹œ ê°“ê¸¸ì— ì„¸ìš°ì„¸ìš”!"
            }
        
        # ì¶”ê°€ í–‰ë™ ì œì•ˆ
        if not is_correct and stage in ['L2', 'L3']:
            action = "ì§€ê¸ˆ ë°”ë¡œ ë¹„ìƒë“±ì„ ì¼œê³  ê°“ê¸¸ë¡œ ì´ë™í•˜ì„¸ìš”."
        else:
            action = ""
        
        return {
            'response': responses.get(stage, "ë„¤, ë“¤ì—ˆì–´ìš”."),
            'is_correct': is_correct,
            'action_required': action,
            'alert_level': 'high' if not is_correct else 'medium'
        }

    def _check_date_answer(self, answer: str) -> bool:
        """ë‚ ì§œ ë‹µë³€ ê²€ì¦"""
        from datetime import datetime
        today = datetime.now().day
        return str(today) in answer

    def _check_countdown_answer(self, answer: str) -> bool:
        """ì¹´ìš´íŠ¸ë‹¤ìš´ ë‹µë³€ ê²€ì¦"""
        # 10 9 8 7 6 5 4 3 2 1 ìˆœì„œ í™•ì¸
        numbers = ['10', '9', '8', '7', '6', '5', '4', '3', '2', '1']
        answer_clean = answer.replace(',', ' ').replace('.', ' ')
        
        count = 0
        for num in numbers:
            if num in answer_clean:
                count += 1
        
        return count >= 8  # 80% ì´ìƒ ë§ìœ¼ë©´ ì •ë‹µ

    def _check_time_answer(self, answer: str) -> bool:
        """ì‹œê°„ ë‹µë³€ ê²€ì¦"""
        from datetime import datetime
        current_hour = datetime.now().hour
        return str(current_hour) in answer or str(current_hour-1) in answer or str(current_hour+1) in answer
    
    def _update_context(self, stage: str, d_value: int, user_input: str = None):
        """ìš´ì „ì ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        
        now = datetime.now()
        
        # ìš´ì „ ì‹œì‘ ì‹œê°„ ì„¤ì •
        if not self.driver_context['driving_start_time']:
            self.driver_context['driving_start_time'] = now
        
        # ìš´ì „ ì‹œê°„ ê³„ì‚°
        driving_time = now - self.driver_context['driving_start_time']
        self.driver_context['driving_duration'] = int(driving_time.total_seconds() / 60)
        
        # ê²½ê³  ì¹´ìš´íŠ¸
        if stage in ['L1', 'L2', 'L3', 'FAILSAFE']:
            self.driver_context['total_warnings'] += 1
        
        # ì‘ë‹µ ì´ë ¥ ì €ì¥
        if user_input:
            self.driver_context['response_history'].append({
                'timestamp': now.isoformat(),
                'user': user_input,
                'stage': stage,
                'd_value': d_value
            })
            
            # ìµœëŒ€ 10ê°œ ì´ë ¥ë§Œ ìœ ì§€
            if len(self.driver_context['response_history']) > 10:
                self.driver_context['response_history'].pop(0)
    
    def _analyze_emotion(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ê°ì • ìƒíƒœ ë¶„ì„"""
        
        negative_words = ['ì§œì¦', 'í”¼ê³¤', 'í˜ë“¤', 'ëª»', 'ì‹«', 'ê·¸ë§Œ', 'ì•„ë‹ˆ']
        positive_words = ['ì¢‹', 'ë„¤', 'ì•Œì•˜', 'ì˜¤ì¼€ì´', 'ê´œì°®', 'í•´ë³¼ê²Œ']
        
        text_lower = text.lower()
        
        neg_count = sum(1 for word in negative_words if word in text_lower)
        pos_count = sum(1 for word in positive_words if word in text_lower)
        
        if neg_count > pos_count:
            return 'frustrated'
        elif pos_count > neg_count:
            return 'cooperative'
        else:
            return 'neutral'
    
    def _get_stage_level(self, stage: str) -> int:
        """ë‹¨ê³„ë¥¼ ìˆ«ì ë ˆë²¨ë¡œ ë³€í™˜"""
        levels = {
            'ì •ìƒ': 0, 'ì˜ì‹¬ê²½ê³ ': 1, 'ì§‘ì¤‘ëª¨ë‹ˆí„°ë§': 2,
            'ê°œì„ ': 0, 'L1': 3, 'L2': 4, 'L3': 5, 'FAILSAFE': 6
        }
        return levels.get(stage, 0)
    
    def _get_weather_description(self) -> str:
        """í˜„ì¬ ë‚ ì”¨ ì„¤ëª… (ì‹¤ì œë¡œëŠ” API ì—°ë™)"""
        weather_options = ['ë§‘', 'íë¦¿', 'ì„ ì„ ', 'ë”°ëœ»', 'ìŒ€ìŒ€']
        return random.choice(weather_options)
    
    def _get_time_of_day(self) -> str:
        """ì‹œê°„ëŒ€ë³„ ì¸ì‚¬ë§"""
        hour = datetime.now().hour
        if 5 <= hour < 9:
            return "ì´ë¥¸ ì•„ì¹¨"
        elif 9 <= hour < 12:
            return "ì˜¤ì „"
        elif 12 <= hour < 14:
            return "ì ì‹¬ì‹œê°„"
        elif 14 <= hour < 18:
            return "ì˜¤í›„"
        elif 18 <= hour < 21:
            return "ì €ë…"
        else:
            return "ë°¤"
    
    def _format_last_rest_time(self) -> str:
        """ë§ˆì§€ë§‰ íœ´ì‹ ì‹œê°„ í¬ë§·"""
        if not self.driver_context['last_rest_time']:
            return "íœ´ì‹ ì—†ì´"
        
        time_diff = datetime.now() - self.driver_context['last_rest_time']
        minutes = int(time_diff.total_seconds() / 60)
        
        if minutes < 60:
            return f"{minutes}ë¶„ ì „"
        else:
            return f"{minutes // 60}ì‹œê°„ ì „"
    
    def _select_appropriate_music(self, stage: str) -> Dict:
        """ë‹¨ê³„ì— ë§ëŠ” ìŒì•…/ì‚¬ìš´ë“œ ì„ íƒ (ìƒˆë¡œìš´ ì‚¬ìš´ë“œ ì ìš©)"""
        level = self._get_stage_level(stage)
        
        if level >= 4:  # L3, FAILSAFE
            return {'track': 'low_buzz_high_beep.wav', 'loop': True, 'volume': 1.3}
        elif level == 3:  # L2
            return {'track': 'metal_scrape.wav', 'loop': True, 'volume': 1.2}
        elif level == 2:  # L1
            return {'track': 'static_burst.wav', 'loop': True, 'volume': 1.1}
        elif level == 1:  # ì˜ì‹¬ê²½ê³ 
            return {'track': 'attention_chime.wav', 'loop': False, 'volume': 0.8}
        else:  # ì •ìƒ
            return {'track': '', 'loop': False, 'volume': 0}
    
    def analyze_voice_command(self, text: str, context: Dict = None) -> Dict:
        """
        GPT APIë¥¼ í™œìš©í•œ ì§€ëŠ¥í˜• ìŒì„± ëª…ë ¹ ë¶„ì„
        
        Args:
            text: ì‚¬ìš©ìê°€ ë§í•œ ë‚´ìš©
            context: í˜„ì¬ ìƒí™© ì •ë³´ (ìŒì•… ì¬ìƒ ìƒíƒœ, ë‹¨ê³„ ë“±)
            
        Returns:
            dict: ë¶„ì„ ê²°ê³¼ (action, confidence, reasoning)
        """
        if not self.api_key:
            # API í‚¤ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í‚¤ì›Œë“œ ë¶„ì„
            return self._basic_command_analysis(text)
        
        try:
            # GPTë¥¼ í†µí•œ ì§€ëŠ¥í˜• ë¶„ì„
            messages = [
                {
                    "role": "system", 
                    "content": """
                    ë‹¹ì‹ ì€ ìš´ì „ìì˜ ìŒì„± ëª…ë ¹ì„ ë¶„ì„í•˜ëŠ” AIì…ë‹ˆë‹¤. 
                    ì‚¬ìš©ìì˜ ë§ì„ ë“£ê³  ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:
                    
                    1. start_music: ìŒì•…ì„ í‹€ì–´ë‹¬ë¼ëŠ” ì˜ë„
                       - ì˜ˆ: "ìŒì•… í‹€ì–´ì¤˜", "ë®¤ì§ ìŠ¤íƒ€íŠ¸", "ë…¸ë˜ ì¢€", "music please", "tuneì„ í‹€ì–´ë´"
                    
                    2. stop_music: ìŒì•…ì„ ì¤‘ì§€í•´ë‹¬ë¼ëŠ” ì˜ë„  
                       - ì˜ˆ: "ìŒì•… êº¼ì¤˜", "ë®¤ì§ ìŠ¤í†±", "ê·¸ë§Œ", "ì¤‘ì§€í•´", "music off", "turn it off"
                    
                    3. general_chat: ì¼ë°˜ì ì¸ ëŒ€í™”
                       - ì˜ˆ: "ì¡¸ë ¤", "í”¼ê³¤í•´", "ì•ˆë…•", "ì–´ë””ê°€?", "ëª‡ ì‹œì•¼?"
                    
                    ì‘ë‹µì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ í•˜ì„¸ìš”:
                    {
                        "action": "start_music|stop_music|general_chat",
                        "confidence": 0.0-1.0,
                        "reasoning": "íŒë‹¨ ê·¼ê±°"
                    }
                    """
                },
                {
                    "role": "user",
                    "content": f"""
                    ë¶„ì„í•  í…ìŠ¤íŠ¸: "{text}"
                    
                    í˜„ì¬ ìƒí™©:
                    - ìŒì•… ì¬ìƒ ì¤‘: {context.get('current_music_state', False) if context else False}
                    - ìš´ì „ ìƒíƒœ: {context.get('stage', 'ì •ìƒ') if context else 'ì •ìƒ'}
                    
                    ìœ„ í…ìŠ¤íŠ¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.
                    """
                }
            ]
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",  # ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ 3.5 ì‚¬ìš©
                messages=messages,
                temperature=0.1,  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„
                max_tokens=150
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                import json
                result = json.loads(result_text)
                
                # ìœ íš¨ì„± ê²€ì¦
                valid_actions = ['start_music', 'stop_music', 'general_chat']
                if result.get('action') not in valid_actions:
                    result['action'] = 'general_chat'
                
                # confidence ë²”ìœ„ í™•ì¸
                confidence = float(result.get('confidence', 0.5))
                result['confidence'] = max(0.0, min(1.0, confidence))
                
                return result
                
            except (json.JSONDecodeError, KeyError, ValueError) as e:
                print(f"GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}, ì›ë³¸: {result_text}")
                return self._basic_command_analysis(text)
                
        except Exception as e:
            print(f"GPT ìŒì„± ëª…ë ¹ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._basic_command_analysis(text)
    
    def _basic_command_analysis(self, text: str) -> Dict:
        """ê¸°ë³¸ í‚¤ì›Œë“œ ê¸°ë°˜ ìŒì„± ëª…ë ¹ ë¶„ì„"""
        text_lower = text.lower()
        
        # ìŒì•… ì¬ìƒ ê´€ë ¨
        start_keywords = [
            'ìŒì•…', 'ë…¸ë˜', 'ë®¤ì§', 'music', 'í‹€ì–´', 'ì¬ìƒ', 'í”Œë ˆì´', 'play', 
            'ì¼œ', 'ì‹œì‘', 'start', 'ë“¤ë ¤ì¤˜', 'ë“¤ë ¤', 'íŠ¸ëŠ”', 'ì¼œì¤˜', 'on'
        ]
        
        # ìŒì•… ì¤‘ì§€ ê´€ë ¨  
        stop_keywords = [
            'êº¼', 'ì¤‘ì§€', 'ë©ˆì¶°', 'ìŠ¤í†±', 'stop', 'ë', 'ê·¸ë§Œ', 'ì •ì§€', 'off',
            'êº¼ì¤˜', 'ë©ˆì¶°ì¤˜', 'ì¤‘ì§€í•´', 'ë„ì', 'ë©ˆì¶”ì', 'turn off', 'shut'
        ]
        
        start_score = sum(1 for keyword in start_keywords if keyword in text_lower)
        stop_score = sum(1 for keyword in stop_keywords if keyword in text_lower)
        
        if start_score > stop_score and start_score > 0:
            return {
                "action": "start_music",
                "confidence": min(0.9, 0.6 + (start_score * 0.1)),
                "reasoning": f"ìŒì•… ì¬ìƒ í‚¤ì›Œë“œ {start_score}ê°œ ê°ì§€"
            }
        elif stop_score > 0:
            return {
                "action": "stop_music", 
                "confidence": min(0.9, 0.6 + (stop_score * 0.1)),
                "reasoning": f"ìŒì•… ì¤‘ì§€ í‚¤ì›Œë“œ {stop_score}ê°œ ê°ì§€"
            }
        else:
            return {
                "action": "general_chat",
                "confidence": 0.8,
                "reasoning": "ìŒì•… ê´€ë ¨ í‚¤ì›Œë“œ ì—†ìŒ, ì¼ë°˜ ëŒ€í™”ë¡œ íŒë‹¨"
            }

    def get_conversation_summary(self) -> Dict:
        """ëŒ€í™” ìš”ì•½ ë° í†µê³„"""
        return {
            'total_duration': self.driver_context['driving_duration'],
            'warning_count': self.driver_context['total_warnings'],
            'emotional_trend': self._analyze_emotional_trend(),
            'risk_assessment': self._calculate_risk_score(),
            'recommendations': self._generate_recommendations()
        }
    
    def _analyze_emotional_trend(self) -> str:
        """ê°ì • ë³€í™” ì¶”ì„¸ ë¶„ì„"""
        if not self.driver_context['response_history']:
            return 'stable'
        
        # ìµœê·¼ 5ê°œ ì‘ë‹µì˜ ê°ì • ë¶„ì„
        recent = self.driver_context['response_history'][-5:]
        emotions = [self._analyze_emotion(r.get('user', '')) for r in recent]
        
        frustrated_count = emotions.count('frustrated')
        if frustrated_count >= 3:
            return 'increasingly_frustrated'
        elif frustrated_count == 0:
            return 'calm'
        else:
            return 'variable'
    
    def _calculate_risk_score(self) -> int:
        """ì¢…í•© ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° (0-100)"""
        
        base_score = 0
        
        # ìš´ì „ ì‹œê°„ì— ë”°ë¥¸ ìœ„í—˜ë„
        duration_minutes = self.driver_context['driving_duration']
        if duration_minutes > 120:
            base_score += 30
        elif duration_minutes > 60:
            base_score += 15
        
        # ê²½ê³  íšŸìˆ˜ì— ë”°ë¥¸ ìœ„í—˜ë„
        warnings = self.driver_context['total_warnings']
        base_score += min(40, warnings * 10)
        
        # ê°ì • ìƒíƒœì— ë”°ë¥¸ ìœ„í—˜ë„
        if self.driver_context['emotional_state'] == 'frustrated':
            base_score += 20
        
        # íœ´ì‹ ì—†ì´ ìš´ì „í•œ ì‹œê°„
        if not self.driver_context['last_rest_time']:
            base_score += 10
        
        return min(100, base_score)
    
    def _generate_recommendations(self) -> List[str]:
        """ê°œì¸í™”ëœ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        
        recommendations = []
        risk_score = self._calculate_risk_score()
        
        if risk_score > 70:
            recommendations.append("ì¦‰ì‹œ íœ´ê²Œì†Œì—ì„œ 20ë¶„ ì´ìƒ íœ´ì‹ì„ ì·¨í•˜ì„¸ìš”")
        elif risk_score > 50:
            recommendations.append("10ë¶„ ë‚´ë¡œ ì•ˆì „í•œ ê³³ì— ì •ì°¨í•˜ì—¬ ìŠ¤íŠ¸ë ˆì¹­í•˜ì„¸ìš”")
        
        if self.driver_context['driving_duration'] > 90:
            recommendations.append("ì¥ì‹œê°„ ìš´ì „ ì¤‘ì…ë‹ˆë‹¤. ê·œì¹™ì ì¸ íœ´ì‹ì´ í•„ìš”í•´ìš”")
        
        if self.driver_context['emotional_state'] == 'frustrated':
            recommendations.append("ì‹¬í˜¸í¡ì„ í•˜ê³  ì¢‹ì•„í•˜ëŠ” ìŒì•…ì„ ë“¤ì–´ë³´ì„¸ìš”")
        
        return recommendations


# ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    service = DrowsinessLLMService()
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
    test_scenarios = [
        ("ì •ìƒ", 25, None),
        ("ì˜ì‹¬ê²½ê³ ", 45, "ì•„ì§ ê´œì°®ì•„ìš”"),
        ("L1", 75, "ì•Œì•˜ì–´ìš”, ì¢€ë§Œ ë” ê°ˆê²Œìš”"),
        ("L2", 85, "ì§œì¦ë‚˜ë„¤ ìê¾¸ ì™œ ê·¸ë˜"),
        ("FAILSAFE", 95, None)
    ]
    
    for stage, d_value, user_input in test_scenarios:
        response = service.generate_contextual_response(stage, d_value, user_input)
        print(f"\n[{stage}] D={d_value}")
        print(f"AI: {response['announcement']}")
        if response['question']:
            print(f"ì§ˆë¬¸: {response['question']}")
        if response['action_suggestion']:
            print(f"ì œì•ˆ: {response['action_suggestion']}")
        print("-" * 50)

def process_user_input(user_input: str, current_stage: str, session_id: str) -> Dict:
    """
    ì™¸ë¶€ì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ ê°„ë‹¨í•œ ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        current_stage: í˜„ì¬ ì¡¸ìŒ ë‹¨ê³„
        session_id: ì„¸ì…˜ ID
        
    Returns:
        dict: ì‘ë‹µ ë©”ì‹œì§€ì™€ ì¶”ê°€ ì •ë³´
    """
    try:
        # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì„¸ì…˜ë³„ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ì´ìƒì ì´ë‚˜ ê°„ë‹¨íˆ ì²˜ë¦¬)
        service = DrowsinessLLMService()
        
        # Dê°’ ë§¤í•‘ (stageì—ì„œ ì¶”ì •)
        d_value_map = {
            'ì •ìƒ': 30,
            'ì˜ì‹¬ê²½ê³ ': 40,
            'ì§‘ì¤‘ëª¨ë‹ˆí„°ë§': 50,
            'ê°œì„ ': 60,
            'L1': 70,
            'L2': 80,
            'L3': 90,
            'FAILSAFE': 999
        }
        
        d_value = d_value_map.get(current_stage, 50)
        
        # ì‘ë‹µ ìƒì„±
        response = service.generate_contextual_response(
            stage=current_stage,
            d_value=d_value,
            user_input=user_input
        )
        
        # app.pyì—ì„œ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return {
            "message": response.get('announcement', '') + 
                      (" " + response.get('question', '') if response.get('question') else ""),
            "actions": response.get('safety_actions', []) if 'safety_actions' in response else [],
            "audio_file": response.get('music', {}).get('track') if response.get('music') else None
        }
        
    except Exception as e:
        print(f"process_user_input ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ ì‘ë‹µ
        return {
            "message": f"í˜„ì¬ {current_stage} ìƒíƒœì…ë‹ˆë‹¤. ì•ˆì „ìš´ì „ í•˜ì„¸ìš”.",
            "actions": [],
            "audio_file": None
        }