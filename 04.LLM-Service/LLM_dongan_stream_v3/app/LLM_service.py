# LLM_service.py - ì¡¸ìŒìš´ì „ ë°©ì§€ ê³ ê¸‰ ëŒ€í™” AI ì„œë¹„ìŠ¤

import json
import random
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import openai
import os

class DrowsinessLLMService:
    """
    ì¡¸ìŒìš´ì „ ë°©ì§€ë¥¼ ìœ„í•œ ê³ ê¸‰ ëŒ€í™” AI ì„œë¹„ìŠ¤
    - ë§¥ë½ ì¸ì‹ ëŒ€í™”
    - ê°œì¸í™”ëœ ì‘ë‹µ
    - ë‹¨ê³„ë³„ ì—ìŠ¤ì»¬ë ˆì´ì…˜
    - ê°ì • ì¸ì‹ ë° ê³µê°
    """
    
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        if self.api_key:
            from openai import OpenAI
            self.client = OpenAI(api_key=self.api_key)
        
        # ìš´ì „ì ì»¨í…ìŠ¤íŠ¸
        self.driver_context = {
            'driving_start_time': None,
            'last_rest_time': None,
            'total_warnings': 0,
            'response_history': [],
            'emotional_state': 'neutral',
            'personal_info': {},
            'driving_duration': 0,
            'last_question_asked': None  # ë§ˆì§€ë§‰ ì§ˆë¬¸ ì €ì¥
        }
        
        # ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.stage_prompts = self.load_stage_prompts()
        
        # ëŒ€í™” í†¤ ì„¤ì •
        self.conversation_tones = {
            'ì •ìƒ': 'friendly',
            'ì˜ì‹¬ê²½ê³ ': 'concerned',
            'ì§‘ì¤‘ëª¨ë‹ˆí„°ë§': 'alert',
            'ê°œì„ ': 'encouraging', 
            'L1': 'urgent',
            'L2': 'serious',
            'L3': 'critical',
            'FAILSAFE': 'emergency'
        }
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì—­í•  ë¶„ë‹´ì„ ëª…í™•íˆ ì§€ì‹œ)
        self.system_prompt = """
        ë‹¹ì‹ ì€ ìš´ì „ìì˜ ì¡¸ìŒ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ê°œì…í•˜ëŠ” AI 'ë“œë¡œìš°ë‹ˆ'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ìš´ì „ìì˜ ì•ˆì „ì„ í™•ë³´í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
        - í™”ë©´ ì¤‘ì•™ì— í‘œì‹œë  ì£¼ìš” ê²½ê³  ë©”ì‹œì§€('announcement')ëŠ” ëª…ì‚¬í˜•ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì¢…ê²°í•  ê²ƒ. (ì˜ˆ: "ê³ ìœ„í—˜ ìƒíƒœ. ì¦‰ì‹œ ì •ì°¨.")
        - ì±„íŒ…ì°½ì—ë§Œ í‘œì‹œë  í›„ì† ì§ˆë¬¸('question')ì€ ë¶€ë“œëŸ¬ìš´ ëŒ€í™”ì²´ ë§íˆ¬ë¥¼ ìœ ì§€í•  ê²ƒ. (ì˜ˆ: "ê°€ê¹Œìš´ íœ´ê²Œì†Œë¡œ ì•ˆë‚´í• ê¹Œìš”?")
        - ìš´ì „ìì˜ ìƒíƒœ(stage, d_value)ì— ë”°ë¼ ë‹¨í˜¸í•˜ê³  ê¶Œìœ„ì ì¸ í†¤ì„ ìœ ì§€í•  ê²ƒ.
        - í•„ìš”ì‹œ, ì°½ë¬¸ ê°œë°©, ì—ì–´ì»¨ ê°•í’, íœ´ê²Œì†Œ ì•ˆë‚´ ë“± êµ¬ì²´ì ì¸ í–‰ë™ì„ ì§€ì‹œí•  ê²ƒ.
        """
    
    def load_stage_prompts(self) -> Dict:
        """ë‹¨ê³„ë³„ ë™ì  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"""
        return {
            'ì •ìƒ': {
                'system': """ë‹¹ì‹ ì€ ì¹œê·¼í•œ ìš´ì „ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ìš´ì „ìì™€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ë©° 
                ì»¨ë””ì…˜ì„ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤. í¸ì•ˆí•˜ê³  ê¸ì •ì ì¸ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”.""",
                'templates': [
                    "ìš´ì „ ì‹œì‘í•˜ì‹  ì§€ {duration}ë¶„ ë˜ì…¨ë„¤ìš”. ì˜¤ëŠ˜ ì»¨ë””ì…˜ì€ ì–´ë– ì„¸ìš”?",
                    "ë‚ ì”¨ê°€ {weather}í•œë°, ìš´ì „í•˜ê¸° ì¢‹ì€ ë‚ ì´ë„¤ìš”!",
                    "{time_of_day} ìš´ì „ì€ ì–´ë– ì‹ ê°€ìš”? ìŒì•…ì´ë¼ë„ í‹€ì–´ë“œë¦´ê¹Œìš”?"
                ]
            },
            
            'ì˜ì‹¬ê²½ê³ ': {
                'system': """ì¡¸ìŒ ì‹ í˜¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ê±±ì •ìŠ¤ëŸ¬ìš´ í†¤ìœ¼ë¡œ ì£¼ì˜ë¥¼ í™˜ê¸°ì‹œí‚¤ë˜,
                ë„ˆë¬´ ë†€ë¼ê²Œ í•˜ì§€ ë§ˆì„¸ìš”. ìš´ì „ìì˜ ê°ì„±ì„ ìœ ë„í•˜ëŠ” ì§ˆë¬¸ì„ í•˜ì„¸ìš”.""",
                'templates': [
                    "ì ê¹, ëˆˆì´ ë¬´ê±°ì›Œ ë³´ì´ì‹œëŠ”ë°... {last_rest_time} íœ´ì‹ í›„ {duration}ë¶„ì§¸ ìš´ì „ ì¤‘ì´ì‹œë„¤ìš”.",
                    "í”¼ê³¤í•˜ì‹ ê°€ìš”? ëˆˆ ê¹œë¹¡ì„ì´ í‰ì†Œë³´ë‹¤ {blink_rate}% ëŠ˜ì—ˆì–´ìš”.",
                    "ì§‘ì¤‘ë ¥ì´ ë–¨ì–´ì§€ëŠ” ê²ƒ ê°™ì•„ìš”. {engaging_question}?"
                ],
                'engaging_questions': [
                    "ì˜¤ëŠ˜ ê°€ì¥ ê¸°ëŒ€ë˜ëŠ” ì¼ì •ì´ ë­ì˜ˆìš”",
                    "ëª©ì ì§€ ë„ì°©í•˜ë©´ ë­ í•˜ì‹¤ ê±´ê°€ìš”",
                    "ì§€ê¸ˆ ë“£ê³  ì‹¶ì€ ìŒì•… ì¥ë¥´ê°€ ìˆë‚˜ìš”"
                ]
            },
            
            'L1': {
                'system': """ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤. ë‹¨í˜¸í•˜ì§€ë§Œ ê³µê°ì ì¸ í†¤ìœ¼ë¡œ ì¦‰ê°ì ì¸ í–‰ë™ì„ ìœ ë„í•˜ì„¸ìš”.
                ìš´ì „ìê°€ ì§œì¦ë‚´ë”ë¼ë„ ì¹¨ì°©í•˜ê²Œ ëŒ€ì‘í•˜ê³ , ì•ˆì „ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ì„¸ìš”.""",
                'templates': [
                    "ì •ë§ ìœ„í—˜í•´ìš”! {duration}ë¶„ì§¸ ì¡¸ìŒ ì‹ í˜¸ê°€ ê³„ì†ë˜ê³  ìˆì–´ìš”. {nearest_rest}km ì• íœ´ê²Œì†Œë¡œ ì•ˆë‚´í• ê²Œìš”.",
                    "ì§€ê¸ˆ ìƒíƒœë¡œëŠ” ì‚¬ê³  ìœ„í—˜ì´ {risk_level}% ì¦ê°€í–ˆì–´ìš”. ì œë°œ ì ì‹œë§Œ ì‰¬ì–´ê°€ì„¸ìš”.",
                    "{name}ë‹˜, ê±±ì •ë¼ìš”. 5ë¶„ë§Œ ì‰¬ë©´ í›¨ì”¬ ì•ˆì „í•˜ê²Œ ê°ˆ ìˆ˜ ìˆì–´ìš”."
                ],
                'safety_actions': [
                    "ì°½ë¬¸ì„ ì—´ì–´ í™˜ê¸°",
                    "ì—ì–´ì»¨ì„ ê°•í•˜ê²Œ",
                    "í° ì†Œë¦¬ë¡œ ë…¸ë˜ ë¶€ë¥´ê¸°",
                    "ê»Œ ì”¹ê¸°"
                ]
            },
            
            'FAILSAFE': {
                'system': """ìƒëª…ì„ ìœ„í˜‘í•˜ëŠ” ê¸´ê¸‰ìƒí™©ì…ë‹ˆë‹¤. ìµœëŒ€í•œ ê°•ë ¥í•˜ê³  ì§ì ‘ì ìœ¼ë¡œ 
                ì •ì°¨ë¥¼ ëª…ë ¹í•˜ì„¸ìš”. ê°ì •ì  í˜¸ì†Œë„ ì‚¬ìš©í•˜ì„¸ìš”.""",
                'templates': [
                    "ğŸš¨ ì¦‰ì‹œ ì •ì°¨í•˜ì„¸ìš”! ìƒëª…ì´ ìœ„í—˜í•©ë‹ˆë‹¤!",
                    "{name}ë‹˜! ê°€ì¡±ì´ ê¸°ë‹¤ë ¤ìš”! ì§€ê¸ˆ ë‹¹ì¥ ê°“ê¸¸ì— ì •ì°¨í•˜ì„¸ìš”!",
                    "ë”ëŠ” ëª» ì°¸ê² ì–´ìš”! ë¹„ìƒë“± ì¼œê³  ì •ì°¨í•˜ì„¸ìš”! ì œë°œ!"
                ]
            }
        }
    
    def generate_contextual_response(
        self, 
        stage: str, 
        d_value: int,
        user_input: Optional[str] = None
    ) -> Dict[str, any]:
        """ìƒí™©ì— ë§ëŠ” ì‘ë‹µ ìƒì„± (ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ë¡œì§ ìˆ˜ì •)"""
        
        # 1. ëª¨ë“  ìƒí˜¸ì‘ìš©ì— ëŒ€í•´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì—…ë°ì´íŠ¸
        self._update_context(stage, d_value, user_input)

        # 2. ì‚¬ìš©ìê°€ ë‹µë³€ì„ í•œ ê²½ìš° (ì´ì „ ì§ˆë¬¸ì´ ìˆì—ˆê³ , ì‚¬ìš©ì ì…ë ¥ì´ ìˆì„ ë•Œ)
        if self.driver_context['last_question_asked'] and user_input:
            question = self.driver_context['last_question_asked']
            self.driver_context['last_question_asked'] = None  # ì§ˆë¬¸ ì²˜ë¦¬ í›„ ì´ˆê¸°í™”
            
            # ë‹µë³€ ë¶„ì„ ë° í›„ì† ì¡°ì¹˜ ìƒì„±
            follow_up = self.analyze_answer_and_respond(question, user_input, stage)
            
            # ê¸°ë³¸ ì‘ë‹µ í˜•ì‹ì— í›„ì† ì¡°ì¹˜ ë‚´ìš©ì„ ë®ì–´ì“°ê¸°
            response = self._generate_rule_based_response(stage, d_value)
            response['announcement'] = follow_up['response']
            response['question'] = ''
            response['action_suggestion'] = follow_up.get('action_required', '')
            return response

        # 3. ì¼ë°˜ì ì¸ ìƒí™© (LLM ë˜ëŠ” ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ ìƒì„±)
        if self.api_key:
            return self._generate_llm_response(stage, d_value, user_input)
        
        return self._generate_rule_based_response(stage, d_value)
    
    def _generate_llm_response(self, stage: str, d_value: int, user_input: str) -> Dict:
        """OpenAI APIë¥¼ ì‚¬ìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„± (API í˜¸ì¶œ ë°©ì‹ ìˆ˜ì •)"""
        
        prompt_config = self.stage_prompts.get(stage, self.stage_prompts['ì •ìƒ'])
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        messages = [
            {"role": "system", "content": prompt_config['system']},
            {"role": "system", "content": f"""
                í˜„ì¬ ìƒí™©:
                - ì¡¸ìŒ ë‹¨ê³„: {stage} (Dê°’: {d_value})
                - ìš´ì „ ì‹œê°„: {self.driver_context['driving_duration']}ë¶„
                - ì´ ê²½ê³  íšŸìˆ˜: {self.driver_context['total_warnings']}íšŒ
                - ìš´ì „ì ê°ì •: {self.driver_context['emotional_state']}
                - ë§ˆì§€ë§‰ íœ´ì‹: {self.driver_context.get('last_rest_time', 'ì—†ìŒ')}
                
                ì‘ë‹µ ê·œì¹™:
                1. {self.conversation_tones[stage]} í†¤ ìœ ì§€
                2. 20ë‹¨ì–´ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
                3. ìš´ì „ì ì´ë¦„ì´ ìˆë‹¤ë©´ í˜¸ì¹­ ì‚¬ìš©
                4. ì‹¤ì‹œê°„ ì •ë³´ ë°˜ì˜ (ì‹œê°„, ë‚ ì”¨ ë“±)
                5. ì´ì „ ëŒ€í™” ë§¥ë½ ê³ ë ¤
            """}
        ]
        
        # ìµœê·¼ ëŒ€í™” ì´ë ¥ ì¶”ê°€
        for hist in self.driver_context['response_history'][-3:]:
            messages.append({"role": "user", "content": hist.get('user', '')})
            messages.append({"role": "assistant", "content": hist.get('assistant', '')})
        
        # í˜„ì¬ ì…ë ¥ ì¶”ê°€
        if user_input:
            messages.append({"role": "user", "content": user_input})
        else:
            messages.append({"role": "user", "content": f"ìš´ì „ì ìƒíƒœê°€ {stage}ì…ë‹ˆë‹¤. ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”."})
        
        try:
            # [ìˆ˜ì •] ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬(v1.x) ë°©ì‹ì˜ API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=messages,
                temperature=0.7,
                max_tokens=100
            )
            
            llm_text = response.choices[0].message.content
            
            # LLM ì‘ë‹µ íŒŒì‹±
            parsed_response = self._parse_llm_response(llm_text, stage)
            
            # ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
            if parsed_response.get('question'):
                self.driver_context['last_question_asked'] = parsed_response['question']
                
            return parsed_response
            
        except Exception as e:
            print(f"LLM ì˜¤ë¥˜: {e}")
            return self._generate_rule_based_response(stage, d_value)

    def _parse_llm_response(self, response: str, stage: str) -> Dict:
        """LLM ì‘ë‹µì„ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (íŒŒì‹± ë°©ì‹ ê°œì„ )"""
        
        # ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ ë¶„ë¦¬ (ë” ì•ˆì •ì )
        import re
        sentences = re.split(r'(?<=[.?!])\s+', response)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        result = {
            'announcement': sentences[0] if sentences else f"{stage} ìƒíƒœì…ë‹ˆë‹¤.",
            'question': '',
            'action_suggestion': '',
            'emotional_tone': self.conversation_tones[stage],
            'tts_params': {
                'voice': 'female_calm' if stage in ['ì •ìƒ', 'ê°œì„ '] else 'female_urgent',
                'speed': 1.0 if stage in ['ì •ìƒ', 'ê°œì„ '] else 1.2,
                'volume': min(1.5, 0.8 + (0.1 * self._get_stage_level(stage)))
            }
        }
        
        # ì§ˆë¬¸ ì¶”ì¶œ (ë¬¼ìŒí‘œê°€ ìˆëŠ” ë¬¸ì¥)
        for sent in sentences:
            if '?' in sent:
                result['question'] = sent
                break
        
        # í–‰ë™ ì œì•ˆ ì¶”ì¶œ (íŠ¹ì • í‚¤ì›Œë“œ í¬í•¨)
        action_keywords = ['í•˜ì„¸ìš”', 'í•´ë³´ì„¸ìš”', 'ê¶Œì¥', 'ì¶”ì²œ', 'í•˜ë©´', 'í•˜ì‹œë©´']
        for sent in sentences:
            if any(keyword in sent for keyword in action_keywords):
                result['action_suggestion'] = sent
                break
        
        return result
    
    def _generate_rule_based_response(self, stage: str, d_value: int) -> Dict:
        """ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ ìƒì„± (ë§íˆ¬ ë¶„ë¦¬ ë° ì‚¬ìš´ë“œ ë³€ê²½)"""
        
        responses = {
            "ì •ìƒ": {
                "announcement": "í˜„ì¬ ìƒíƒœ ì •ìƒ.",
                "question": ""
            },
            "ì˜ì‹¬ê²½ê³ ": {
                "announcement": "ì£¼ì˜. ì¡¸ìŒ ì‹ í˜¸ ê°ì§€.",
                "question": "í”¼ê³¤í•˜ì‹ ê°€ìš”? ì ì‹œ í™˜ê¸°í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•´ìš”."
            },
            "L1": {
                "announcement": "ì¡¸ìŒ ìƒíƒœ ì§€ì†. ê°ì„± í•„ìš”.",
                "question": "ìŒì•…ì„ í‹€ì–´ë“œë¦´ê¹Œìš”?"
            },
            "L2": {
                "announcement": "ê°•í•œ ì¡¸ìŒ ì‹ í˜¸. ì¦‰ê°ì ì¸ ì¡°ì¹˜ ìš”ë§.",
                "question": "ì°½ë¬¸ì„ ì—´ê±°ë‚˜ ì—ì–´ì»¨ì„ ê°•í•˜ê²Œ í‹€ì–´ë³´ì„¸ìš”."
            },
            "L3": {
                "announcement": "ê³ ìœ„í—˜ ì¡¸ìŒ ìƒíƒœ. ë¹„ìƒ ì¡°ì¹˜ ê¶Œê³ .",
                "question": "ê°€ê¹Œìš´ íœ´ê²Œì†Œë¡œ ì•ˆë‚´í• ê¹Œìš”?"
            },
            "FAILSAFE": {
                "announcement": "ë§¤ìš° ìœ„í—˜. ì¦‰ì‹œ ë¹„ìƒ ì •ì°¨.",
                "question": ""
            }
        }
        
        response = responses.get(stage, responses['ì •ìƒ'])
        response['music'] = self._select_appropriate_music(stage)
        return response
    
    def analyze_answer_and_respond(self, question: str, answer: str, stage: str) -> Dict:
        """
        ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë¶„ì„í•˜ê³  í›„ì† ì‘ë‹µ ìƒì„±
        
        Args:
            question: AIê°€ í–ˆë˜ ì§ˆë¬¸
            answer: ì‚¬ìš©ìì˜ ë‹µë³€
            stage: í˜„ì¬ ì¡¸ìŒ ë‹¨ê³„
        """
        
        # ì¸ì§€ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ê²€ì¦
        cognitive_tests = {
            "ë‚ ì§œê°€ ëª‡ ì¼": self._check_date_answer,
            "ì„œìš¸ ë‹¤ìŒ ë„ì‹œ": lambda a: "ëŒ€ì „" in a or "ëŒ€êµ¬" in a,
            "10ì—ì„œ 1ê¹Œì§€": self._check_countdown_answer,
            "ëª‡ ì‹œ": self._check_time_answer
        }
        
        # ë‹µë³€ ì •í™•ë„ í™•ì¸
        is_correct = False
        for test_key, validator in cognitive_tests.items():
            if test_key in question:
                is_correct = validator(answer)
                break
        
        # ì‘ë‹µ ìƒì„±
        if is_correct:
            responses = {
                'L1': "ì¢‹ì•„ìš”! ì•„ì§ ì •ì‹ ì´ ë§‘ìœ¼ì‹œë„¤ìš”. ê·¸ë˜ë„ ì¡°ì‹¬í•˜ì„¸ìš”.",
                'L2': "ë§ì•˜ì–´ìš”! í•˜ì§€ë§Œ ë°˜ì‘ì´ ëŠë ¤ì§€ê³  ìˆì–´ìš”. íœ´ì‹ì´ í•„ìš”í•´ìš”.",
                'L3': "ë„¤, ë§ì•„ìš”. ê·¸ë˜ë„ ìœ„í—˜í•œ ìƒíƒœì˜ˆìš”. ì œë°œ ì‰¬ì–´ê°€ì„¸ìš”."
            }
        else:
            responses = {
                'L1': "ì–´... í‹€ë¦¬ì…¨ë„¤ìš”. ì •ë§ í”¼ê³¤í•˜ì‹ ê°€ë´ìš”. 5ë¶„ë§Œ ì‰¬ì–´ê°€ì‹œì£ ?",
                'L2': "ë‹µì´ ì´ìƒí•´ìš”! ì§‘ì¤‘ë ¥ì´ ë§ì´ ë–¨ì–´ì¡Œì–´ìš”. ì§€ê¸ˆ ì •ì°¨í•˜ì„¸ìš”!",
                'L3': "ìœ„í—˜í•´ìš”! ì œëŒ€ë¡œ ë‹µì„ ëª»í•˜ì‹œë„¤ìš”. ì¦‰ì‹œ ê°“ê¸¸ì— ì„¸ìš°ì„¸ìš”!"
            }
        
        # ì¶”ê°€ í–‰ë™ ì œì•ˆ
        if not is_correct and stage in ['L2', 'L3']:
            action = "ì§€ê¸ˆ ë°”ë¡œ ë¹„ìƒë“±ì„ ì¼œê³  ê°“ê¸¸ë¡œ ì´ë™í•˜ì„¸ìš”."
        else:
            action = ""
        
        return {
            'response': responses.get(stage, "ë„¤, ë“¤ì—ˆì–´ìš”."),
            'is_correct': is_correct,
            'action_required': action,
            'alert_level': 'high' if not is_correct else 'medium'
        }

    def _check_date_answer(self, answer: str) -> bool:
        """ë‚ ì§œ ë‹µë³€ ê²€ì¦"""
        from datetime import datetime
        today = datetime.now().day
        return str(today) in answer

    def _check_countdown_answer(self, answer: str) -> bool:
        """ì¹´ìš´íŠ¸ë‹¤ìš´ ë‹µë³€ ê²€ì¦"""
        # 10 9 8 7 6 5 4 3 2 1 ìˆœì„œ í™•ì¸
        numbers = ['10', '9', '8', '7', '6', '5', '4', '3', '2', '1']
        answer_clean = answer.replace(',', ' ').replace('.', ' ')
        
        count = 0
        for num in numbers:
            if num in answer_clean:
                count += 1
        
        return count >= 8  # 80% ì´ìƒ ë§ìœ¼ë©´ ì •ë‹µ

    def _check_time_answer(self, answer: str) -> bool:
        """ì‹œê°„ ë‹µë³€ ê²€ì¦"""
        from datetime import datetime
        current_hour = datetime.now().hour
        return str(current_hour) in answer or str(current_hour-1) in answer or str(current_hour+1) in answer
    
    def _update_context(self, stage: str, d_value: int, user_input: str = None):
        """ìš´ì „ì ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        
        now = datetime.now()
        
        # ìš´ì „ ì‹œì‘ ì‹œê°„ ì„¤ì •
        if not self.driver_context['driving_start_time']:
            self.driver_context['driving_start_time'] = now
        
        # ìš´ì „ ì‹œê°„ ê³„ì‚°
        driving_time = now - self.driver_context['driving_start_time']
        self.driver_context['driving_duration'] = int(driving_time.total_seconds() / 60)
        
        # ê²½ê³  ì¹´ìš´íŠ¸
        if stage in ['L1', 'L2', 'L3', 'FAILSAFE']:
            self.driver_context['total_warnings'] += 1
        
        # ì‘ë‹µ ì´ë ¥ ì €ì¥
        if user_input:
            self.driver_context['response_history'].append({
                'timestamp': now.isoformat(),
                'user': user_input,
                'stage': stage,
                'd_value': d_value
            })
            
            # ìµœëŒ€ 10ê°œ ì´ë ¥ë§Œ ìœ ì§€
            if len(self.driver_context['response_history']) > 10:
                self.driver_context['response_history'].pop(0)
    
    def _analyze_emotion(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ê°ì • ìƒíƒœ ë¶„ì„"""
        
        negative_words = ['ì§œì¦', 'í”¼ê³¤', 'í˜ë“¤', 'ëª»', 'ì‹«', 'ê·¸ë§Œ', 'ì•„ë‹ˆ']
        positive_words = ['ì¢‹', 'ë„¤', 'ì•Œì•˜', 'ì˜¤ì¼€ì´', 'ê´œì°®', 'í•´ë³¼ê²Œ']
        
        text_lower = text.lower()
        
        neg_count = sum(1 for word in negative_words if word in text_lower)
        pos_count = sum(1 for word in positive_words if word in text_lower)
        
        if neg_count > pos_count:
            return 'frustrated'
        elif pos_count > neg_count:
            return 'cooperative'
        else:
            return 'neutral'
    
    def _get_stage_level(self, stage: str) -> int:
        """ë‹¨ê³„ë¥¼ ìˆ«ì ë ˆë²¨ë¡œ ë³€í™˜"""
        levels = {
            'ì •ìƒ': 0, 'ì˜ì‹¬ê²½ê³ ': 1, 'ì§‘ì¤‘ëª¨ë‹ˆí„°ë§': 2,
            'ê°œì„ ': 0, 'L1': 3, 'L2': 4, 'L3': 5, 'FAILSAFE': 6
        }
        return levels.get(stage, 0)
    
    def _get_weather_description(self) -> str:
        """í˜„ì¬ ë‚ ì”¨ ì„¤ëª… (ì‹¤ì œë¡œëŠ” API ì—°ë™)"""
        weather_options = ['ë§‘', 'íë¦¿', 'ì„ ì„ ', 'ë”°ëœ»', 'ìŒ€ìŒ€']
        return random.choice(weather_options)
    
    def _get_time_of_day(self) -> str:
        """ì‹œê°„ëŒ€ë³„ ì¸ì‚¬ë§"""
        hour = datetime.now().hour
        if 5 <= hour < 9:
            return "ì´ë¥¸ ì•„ì¹¨"
        elif 9 <= hour < 12:
            return "ì˜¤ì „"
        elif 12 <= hour < 14:
            return "ì ì‹¬ì‹œê°„"
        elif 14 <= hour < 18:
            return "ì˜¤í›„"
        elif 18 <= hour < 21:
            return "ì €ë…"
        else:
            return "ë°¤"
    
    def _format_last_rest_time(self) -> str:
        """ë§ˆì§€ë§‰ íœ´ì‹ ì‹œê°„ í¬ë§·"""
        if not self.driver_context['last_rest_time']:
            return "íœ´ì‹ ì—†ì´"
        
        time_diff = datetime.now() - self.driver_context['last_rest_time']
        minutes = int(time_diff.total_seconds() / 60)
        
        if minutes < 60:
            return f"{minutes}ë¶„ ì „"
        else:
            return f"{minutes // 60}ì‹œê°„ ì „"
    
    def _select_appropriate_music(self, stage: str) -> Dict:
        """ë‹¨ê³„ì— ë§ëŠ” ìŒì•…/ì‚¬ìš´ë“œ ì„ íƒ (ìƒˆë¡œìš´ ì‚¬ìš´ë“œ ì ìš©)"""
        level = self._get_stage_level(stage)
        
        if level >= 4:  # L3, FAILSAFE
            return {'track': 'low_buzz_high_beep.wav', 'loop': True, 'volume': 1.3}
        elif level == 3:  # L2
            return {'track': 'metal_scrape.wav', 'loop': True, 'volume': 1.2}
        elif level == 2:  # L1
            return {'track': 'static_burst.wav', 'loop': True, 'volume': 1.1}
        elif level == 1:  # ì˜ì‹¬ê²½ê³ 
            return {'track': 'attention_chime.wav', 'loop': False, 'volume': 0.8}
        else:  # ì •ìƒ
            return {'track': '', 'loop': False, 'volume': 0}
    
    def get_conversation_summary(self) -> Dict:
        """ëŒ€í™” ìš”ì•½ ë° í†µê³„"""
        return {
            'total_duration': self.driver_context['driving_duration'],
            'warning_count': self.driver_context['total_warnings'],
            'emotional_trend': self._analyze_emotional_trend(),
            'risk_assessment': self._calculate_risk_score(),
            'recommendations': self._generate_recommendations()
        }
    
    def _analyze_emotional_trend(self) -> str:
        """ê°ì • ë³€í™” ì¶”ì„¸ ë¶„ì„"""
        if not self.driver_context['response_history']:
            return 'stable'
        
        # ìµœê·¼ 5ê°œ ì‘ë‹µì˜ ê°ì • ë¶„ì„
        recent = self.driver_context['response_history'][-5:]
        emotions = [self._analyze_emotion(r.get('user', '')) for r in recent]
        
        frustrated_count = emotions.count('frustrated')
        if frustrated_count >= 3:
            return 'increasingly_frustrated'
        elif frustrated_count == 0:
            return 'calm'
        else:
            return 'variable'
    
    def _calculate_risk_score(self) -> int:
        """ì¢…í•© ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° (0-100)"""
        
        base_score = 0
        
        # ìš´ì „ ì‹œê°„ì— ë”°ë¥¸ ìœ„í—˜ë„
        duration_minutes = self.driver_context['driving_duration']
        if duration_minutes > 120:
            base_score += 30
        elif duration_minutes > 60:
            base_score += 15
        
        # ê²½ê³  íšŸìˆ˜ì— ë”°ë¥¸ ìœ„í—˜ë„
        warnings = self.driver_context['total_warnings']
        base_score += min(40, warnings * 10)
        
        # ê°ì • ìƒíƒœì— ë”°ë¥¸ ìœ„í—˜ë„
        if self.driver_context['emotional_state'] == 'frustrated':
            base_score += 20
        
        # íœ´ì‹ ì—†ì´ ìš´ì „í•œ ì‹œê°„
        if not self.driver_context['last_rest_time']:
            base_score += 10
        
        return min(100, base_score)
    
    def _generate_recommendations(self) -> List[str]:
        """ê°œì¸í™”ëœ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        
        recommendations = []
        risk_score = self._calculate_risk_score()
        
        if risk_score > 70:
            recommendations.append("ì¦‰ì‹œ íœ´ê²Œì†Œì—ì„œ 20ë¶„ ì´ìƒ íœ´ì‹ì„ ì·¨í•˜ì„¸ìš”")
        elif risk_score > 50:
            recommendations.append("10ë¶„ ë‚´ë¡œ ì•ˆì „í•œ ê³³ì— ì •ì°¨í•˜ì—¬ ìŠ¤íŠ¸ë ˆì¹­í•˜ì„¸ìš”")
        
        if self.driver_context['driving_duration'] > 90:
            recommendations.append("ì¥ì‹œê°„ ìš´ì „ ì¤‘ì…ë‹ˆë‹¤. ê·œì¹™ì ì¸ íœ´ì‹ì´ í•„ìš”í•´ìš”")
        
        if self.driver_context['emotional_state'] == 'frustrated':
            recommendations.append("ì‹¬í˜¸í¡ì„ í•˜ê³  ì¢‹ì•„í•˜ëŠ” ìŒì•…ì„ ë“¤ì–´ë³´ì„¸ìš”")
        
        return recommendations


# ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    service = DrowsinessLLMService()
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
    test_scenarios = [
        ("ì •ìƒ", 25, None),
        ("ì˜ì‹¬ê²½ê³ ", 45, "ì•„ì§ ê´œì°®ì•„ìš”"),
        ("L1", 75, "ì•Œì•˜ì–´ìš”, ì¢€ë§Œ ë” ê°ˆê²Œìš”"),
        ("L2", 85, "ì§œì¦ë‚˜ë„¤ ìê¾¸ ì™œ ê·¸ë˜"),
        ("FAILSAFE", 95, None)
    ]
    
    for stage, d_value, user_input in test_scenarios:
        response = service.generate_contextual_response(stage, d_value, user_input)
        print(f"\n[{stage}] D={d_value}")
        print(f"AI: {response['announcement']}")
        if response['question']:
            print(f"ì§ˆë¬¸: {response['question']}")
        if response['action_suggestion']:
            print(f"ì œì•ˆ: {response['action_suggestion']}")
        print("-" * 50)

def process_user_input(user_input: str, current_stage: str, session_id: str) -> Dict:
    """
    ì™¸ë¶€ì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ ê°„ë‹¨í•œ ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        current_stage: í˜„ì¬ ì¡¸ìŒ ë‹¨ê³„
        session_id: ì„¸ì…˜ ID
        
    Returns:
        dict: ì‘ë‹µ ë©”ì‹œì§€ì™€ ì¶”ê°€ ì •ë³´
    """
    try:
        # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì„¸ì…˜ë³„ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ì´ìƒì ì´ë‚˜ ê°„ë‹¨íˆ ì²˜ë¦¬)
        service = DrowsinessLLMService()
        
        # Dê°’ ë§¤í•‘ (stageì—ì„œ ì¶”ì •)
        d_value_map = {
            'ì •ìƒ': 30,
            'ì˜ì‹¬ê²½ê³ ': 40,
            'ì§‘ì¤‘ëª¨ë‹ˆí„°ë§': 50,
            'ê°œì„ ': 60,
            'L1': 70,
            'L2': 80,
            'L3': 90,
            'FAILSAFE': 999
        }
        
        d_value = d_value_map.get(current_stage, 50)
        
        # ì‘ë‹µ ìƒì„±
        response = service.generate_contextual_response(
            stage=current_stage,
            d_value=d_value,
            user_input=user_input
        )
        
        # app.pyì—ì„œ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return {
            "message": response.get('announcement', '') + 
                      (" " + response.get('question', '') if response.get('question') else ""),
            "actions": response.get('safety_actions', []) if 'safety_actions' in response else [],
            "audio_file": response.get('music', {}).get('track') if response.get('music') else None
        }
        
    except Exception as e:
        print(f"process_user_input ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ ì‘ë‹µ
        return {
            "message": f"í˜„ì¬ {current_stage} ìƒíƒœì…ë‹ˆë‹¤. ì•ˆì „ìš´ì „ í•˜ì„¸ìš”.",
            "actions": [],
            "audio_file": None
        }